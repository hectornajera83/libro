[
["presentacion.html", "Medición de pobreza multidimensional: Una aproximación estadística con aplicaciones Presentación", " Medición de pobreza multidimensional: Una aproximación estadística con aplicaciones Héctor Nájera con ayuda de mucha gente (favor de citar este borrador) Presentación ¿Cuál es la prevalencia de pobreza en una sociedad en cierto momento en el tiempo? ¿Por qué observamos tal nivel de pobreza? ¿Por qué algunos grupos de población o regiones son más pobres que otras? Las respuestas a estas preguntas son decisivas para cuestionar nuestro orden institucional puesto que dan pistas sobre el estado y las tendencias de cuestiones capitales como la justicia social. Una condición fundamental para responder estas preguntas es la producción de buenas medidas de pobreza. De otra manera, se genera incertidumbre en torno al dato, lo cual nubla y desvía nuestra atención, acción y juicios sobre el objetivo principal que es la erradicación de la pobreza. El consenso internacional es que la pobreza es multidimensional y que debería medirse considerando los aspectos sustantivos de las necesidades para la vida. Sin embargo, la respuesta sobre la prevalencia y naturaleza de la pobreza multidimensional es aún debatida e insatisfactoria. Existen varias propuestas en la literatura para el mismo problema y no es claro si hay alguna que sea superior al resto o si todas son igual de malas. Peor aún, en medición multidimensional no hay criterios estandarizados para distinguir una buena de una mala medida. Y, sin embargo, la literatura continúa produciendo medidas a gran escala. Los peligros de una mala medida son muchos. Las sociedades pueden desperdiciar recursos y tiempo cuando se basan en evidencia y datos pobres. La academia y el gobierno tienen la responsabilidad de producir medidas que sean replicables y robustas a fin de que sean útiles para el diseño e instrumentación de políticas. Hay varias razones teóricas y metodológicas que han impedido la producción masiva de medidas de pobreza que sean incuestionables en tanto llevan a poco incertidumbre respecto al dato que proporcionan. Primero, la existencia de varios cuerpos teóricos sobre necesidades humanas que debaten cuáles son los aspectos sustantivos para que los humanos vivan con dignidad. Segundo, aún si las discusiones teóricas tuvieran una solución satisfactoria, en la práctica hay varios obstáculos que necesitan resolverse para el desarrollo exitoso de escalas de pobreza. Este reto se manifiesta en las distintas etapas de la producción de un Índice. Para empezar, la pobreza es una invención humana, una abstracción, que requiere rastrearse usando datos multivariados para poder capturar sus aspectos sustantivos. Inevitablemente, esto resulta en un proceso de magnificación de ruido debido a que las y los investigadores tienen que levantar diversos supuestos sobre cuáles son los conjuntos relevantes de necesidades a incluir en un Índice, los umbrales para identificar privación material, los pesos que se asignan a estos indicadores para reflejar o no la importancia diferenciada de las distintas necesidades y sobre la forma en la que el grupo pobre y no pobre son identificados. Además, todos estos supuestos se ubican en el contexto de los datos disponibles, los cuáles raramente se recolectan con la idea a priori de medir pobreza. Invariablemente, estas decisiones están basadas en nuestros propios prejuicios, más o menos informados por alguna teoría. No existe la medición perfecta. Nuestros prejuicios y datos producen imperfección, es decir, error. La medición multidimensional de pobreza al fin es un ejercicio basado en supuestos y nuestra proximidad a una buena medida dependerá de que tan adecuados son nuestras suposiciones y de si se sostienen para los datos que estamos analizando. Pero ¿Cómo sabemos el tamaño de nuestro error? Uno de los retos principales en medición de pobreza multidimensional es cómo enfrentar el problema de error en medición: cómo definirlo y cómo cuantificarlo. El error es un aspecto decisivo en medición porque la incertidumbre es función del error. Nada peor que un dato que no puede replicarse porque entonces tendremos por lo menos dos datos para un mismo fenómeno. No por nada, una de las crisis actuales en ciencias sociales es la de la poca replicabilidad de resultados. Queremos cuantificar el error porque añade ruido a nuestros modelos predictivos y aumenta la incertidumbre en la estimación de la prevalencia y severidad de pobreza. En otras palabras, el ruido es variación aleatoria que nos distancia de lo que estamos interesados. En estos casos nuestra medida no es confiable. Además, hay otro tipo error, el sistemático. El cuál se origina por nuestros prejuicios y sesgos. Es decir, es todo aquello en lo que no estamos interesados cuando medimos pobreza, pero no nos damos cuenta porque tenemos fe en nuestros supuestos. En estos casos, nuestra medida no es válida. La medición de la pobreza multidimensional requiere un marco coherente y sólido para mitigar los sesgos de confirmación -leer la evidencia de forma tal que confirme nuestros prejuicios- a través del escrutinio empírico de nuestros supuestos y nuestros errores. El objetivo de este libro es proveer de un marco que ayude a investigar sistemáticamente al error en medición mediante el análisis de preguntas como: *¿Es sensible agregar nuestra lista ex ante de indicadores en un índice? ¿Hay algunos indicadores que no funcionan como se esperaba? ¿La escala ordena adecuadamente a nuestra población, es decir, de bajo a niveles altos de vida? ¿Es nuestro ordenamiento de la población consistente en distintas muestras y grupos? ¿Ayuda incluir pesos diferenciados o introduce más ruido? ¿Las dimensiones que proponemos parecen existir en los datos? ¿La división que usamos -pobre vs no pobre- lleva a grupos que tienen un perfil y significado teóricamente válido? Es decir, ¿Es nuestro índice multidimensional una medida válida y confiable? Este libro se enfoca en uno de los principales problemas en medición contemporánea de pobreza: la falta de un marco sólido para examinar los supuestos en los que se basa una medida multidimensional de pobreza. El libro propone una serie de herramientas para mitigar contra nuestros prejuicios y error en medición de pobreza. Esto no significa que el libro parte de que los investigadores están activamente tratando de producir malas escalas, es sólo un reconocimiento explícito de que siempre trabajamos con supuestos influenciados por nuestros juicios, los cuales pueden o no ser sensibles para los datos que tenemos. El libro se basa en la teoría de la medición que tiene más de 100 años de desarrollo continuo y que busca ayudar a que los investigadores no produzcan escalas que simplemente magnifican ruido. El libro trata de brindar algunos principios falsables, criterios y métodos para examinar si nuestras medidas de pobreza resultan de un minado de ruido y son irreplicables. Desafortunadamente, la investigación de pobreza ha ignorado los desarrollos en otros campos que enfrentan problemas similares y aunque en ocasiones la teoría de la medición se ha usado, su implementación es parcial, imprecisa y poco sistemática. En 2016, la Comisión del Banco Mundial (2017), encabezada por Anthony Atkinson, puso en perspectiva los diferentes retos en medición multidimensional de pobreza y propuso 21 recomendaciones. La recomendación 4, reconoce la necesidad de validar los índices de pobreza. Sin embargo, no propone cómo hacerlo. Esto es entendible porque una de las principales dificultades en la medición contemporánea de pobreza es la ausencia de una discusión explícita sobre como checar nuestros supuestos. La práctica más común continúa siendo el uso de métodos ad hoc para examinar algunas propiedades (arbitrariamente definidas) de una medida. Hasta la fecha, hay pocos ejercicios en medición multidimensional que parten de un marco estadístico claro para poner en escrutinio los supuestos de un índice. El trabajo de Guio, Gordon, &amp; Marlier (2012) and Guio, Gordon, Marlier, Najera, &amp; Pomati (2017), basado en el trabajo del grupo de Pobreza y Exclusión Social y en la obra monumental de Townsend (1979), es tal vez la implementación más amplia de la teoría de la medida en medición multidimensional de pobreza. Sin embargo, los métodos y su aplicación no se han hecho accesibles a la comunidad interesada en medir pobreza. Uno de los problemas es que hay varios libros en medición de pobreza, pero no hay ninguno que se haya enfocado en el tema de evaluación empírica. La mayoría de los libros se enfocan en la producción de un índice, pero dedican pocas páginas al tema de validación. Esto, de hecho, refleja el hecho de que la medición de pobreza no ha seguido el camino de otras disciplinas que han enfrenado problemas similares. La medición en educación, psicometría, sociología y ciencias naturales siempre enfrentan retos de medición. A diferencia de los estudios de pobreza, estas disciplinas han tomado muy en serio el ejercicio de producción de escalas y han adoptado una serie de prácticas y principios que reducen incertidumbre sobre el atributo que buscan medir. Estas áreas se basan en el trabajo seminal de Spearman (1904) sobre correlación y variables latentes que resulto en el desarrollo de la teoría de la medida y métodos con más de 100 años de historia reflejados en: los trabajos clásicos de análisis factorial (Cudeck &amp; MacCallum, 2012; Lazardfeld &amp; Henry, 1968; Thorndike &amp; Hagen, 1969; Thurstone, 1947), el desarrollo de los principios de validez y confiabilidad (Guttman, 1945, pp. Novick1967, Novick1967, Brennan2006), el marco moderno de variables latentes (Bartholomew, 1987; Kvalheim, 2012; Muthén, 2007; Skrondal &amp; Rabe-Hesketh, 2007), y los manuales que muestran como estos principios y métodos constituyen en un marco robusto de medición (Allen &amp; Yen, 2001; Brennan, 2006; McDonald, 2013; Michell, 2015; Streiner, Norman, &amp; Cairney, 2015). La teoría de la medida ha sido tan ampliamente aceptada que hay llevado a la adopción de sus estándares en algunas revistas académicas para que los autores den evidencia de la calidad de sus mediciones. Este libro se basa en la teoría de la medida y sus métodos para ilustrar cómo bajo un marco unificado puede utilizarse para el escrutinio empírico de índices multidimensionales de pobreza. Esto es, el libro traduce en conceptos clave y principios de la teoría de la medida e ilustra su implementación usando tanto datos simulados como datos reales. Este libro está pensado para investigadores con conocimiento avanzado de pobreza y para estudiantes de posgrado. La mayoría de los ejemplos se basan en R-software y Mplus (Muthén &amp; Muthén, 2012; R Core Team, 2018). El objetivo principal del libro es ayudar a investigadores, estudiantes y técnicos en el gobierno a entender la importancia de los principios de la teoría de la medida en medición multidimensional e incrementar sus habilidades técnicas para análisis empíricos de índices de pobreza. Después de estudiar el libro, los lectores podrán: Encender por qué es importante trabajar con medidas falsables en la investigación de pobreza Identificar la diferencia entre un método de agregación y una metodología de escrutinio empírico Apreciar la relevancia de la teoría de la medida para examinar índices de pobreza pero también entender sus limitaciones Entender por qué los principios de confiabilidad y validez son una necesidad necesaria para una calidad mínima de medición Implementar análisis de confiabilidad y validez usando R-software y Mplus Interpretar los resultados de los análisis de una forma crítica Apreciar la importancia del principio de medición invariante y la equivalización de escalas para producir medidas comparables Implementar análisis básico de medición invariante y equivalización Identificar los usos apropiados e inapropiados de los métodos de la teoría de la medida El libro se organiza de la siguiente manera. El segundo capítulo introduce los vínculos entre los problemas en medición de pobreza y los principios de la teoría de la medida. El capítulo comienza con una revisión de algunos de los debates y consensos en la literatura. Después pone énfasis en los retos y supuestos que tienen lugar en la medición de pobreza y los vincula con la respuesta que la teoría de la medida a ellos. El tercer capítulo introduce, discute y traduce el concepto de confiabilidad a la medición multidimensional de pobreza. El capítulo usa datos simulados y reales para ilustrar las consecuencias de violar confiabilidad y muestra como este concepto se conecta con los axiomas en medición multidimensional. El cuarto capítulo presenta el concepto de validez y relaciones los diferentes tipos de validez con el tipo de prácticas que se hacen en medición de pobreza. El capítulo cinco se concentra en el tema de comparabilidad de medidas de pobreza. Muestra cómo el principio de medición invariante es central para hacer comparaciones válidas de grupos o periodos en el tiempo. El capítulo seis también es sobre comparabilidad, pero se enfoca en una técnica para hacer medidas comparables cuando hay discrepancias en los indicadores: equivalización de escalas. El capítulo siete se enfoca en cómo hallar la línea de pobreza usando el Método Óptimo de Bristol, el cual hace uso de modelos Lineales Generalizados. Este libro hubiera sido imposible sin el apoyo de… "],
["Chapter-1.html", "Capítulo 1 Pobreza y principios de la teoría de medición 1.1 El Concepto de Pobreza 1.2 Las dimensiones de la pobreza 1.3 La medición de la pobreza y sus retos 1.4 Una breve revisión de la historia de la medición de la pobreza 1.5 Estado del escrutinio empírico en la práctica de la medición de pobreza", " Capítulo 1 Pobreza y principios de la teoría de medición Resumen El presente capítulo introduce el concepto de pobreza, subraya algunos retos en su medición y enmarca ciertas soluciones potenciales -desde el punto de vista estadístico- a algunos de los problemas en la producción y escrutinio empírico de un índice multidimensional. El capítulo describe el rol que juegan la definición de pobreza, los juicios de valor del investigador, propiedades deseables de un índice, datos provenientes de encuestas y error de medición en la producción de un índice de pobreza. 1.1 El Concepto de Pobreza Pobreza es uno de los conceptos capitales de las ciencias sociales. En economía, sociología, psicología, política, entre otras disciplinas se trabaja con conceptos. En el reino de las ciencias sociales -aunque también de las ciencias físicas o naturales- los conceptos no son atributos directamente observables mediante datos univariados. La pobreza es una abstracción producto de la mente humana para definir un estado de niveles de vida que son inaceptablemente bajos. Ciertamente, la pobreza no elude porque es un concepto bastante intuitivo, pero, al mismo tiempo, es un constructo con muchas interpretaciones. Nosotros, por tanto, tenemos juicios y prejuicios sobre qué es pobreza y aspiramos a medirla haciendo uso de aproximaciones indirectas basadas en conjuntos de datos. El término pobreza tiene distintos significados y parte de la dificultad para medirla tiene que ver con la existencia de diversas definiciones. Spicker, Alvarez, &amp; Gordon (2006) sugieren que las definiciones que se proponen en la literatura pueden clasificarse en tres grandes grupos: material (necesidades, recursos y privación), economía (niveles de vida, desigualdad y posición económica) y condiciones sociales (titularidades, seguridad social, exclusión, dependencia y clase social). Spicker et al. (2006), sin embargo, subrayan la importancia de trabajar con definiciones científicas de pobreza que cumplan con los estándares de la filosofía de la ciencia: Las definiciones deben ser verificables empíricamente de manera tal que podamos falsearlas de forma clara. En la literatura contemporánea, la pobreza se define en términos de ambos bajos niveles de vida y recursos (Gordon (2018); Gordon (2006)). Estos dominios sugieren que existen, por lo menos, dos grupos poblacionales con un significado asociado a una teoría y cuya existencia es falsable en el sentido que su perfil debería predecir fenómenos que, en teoría, son causados por pobreza- mortalidad, pobre salud, estrés económico, etc. Townsend (1979), consistente con los estándares de la filosofía de la ciencia, argumentaba que la pobreza debería y puede ser tratada científicamente en tanto que puede ser objetivamente definida y medida. Este autor propuso la teoría de pobreza y privación relativa y sostenía que el concepto de privación es central para la definición de pobreza puesto que conecta los recursos de los cuales dispone un hogar o una persona con bajos niveles de vida (Townsend, 1987). El vínculo entre carecer algo socialmente considerado como mínimo para vivir dignamente y la noción de recursos nos lleva a la siguiente definición simple de pobreza (Gordon, 2006): Pobreza puede definirse como la falta de recursos en el tiempo y la privación material y social son sus consecuencias. Esta definición, por supuesto, abre varias preguntas porque no aclara cuál es el conjunto de privaciones y recursos que importa y en qué sentido la carencia de algo es un estándar para clasificar a la población como pobre y no pobre. Además, no es la única definición de pobreza y hay otras que utilizan diferentes conceptos -bienes básicos, necesidades básicas, capacidades, logros- y parecen construidas de forma muy distinta (ver abajo). Sin embargo, muchas de estas discrepancias son semánticas (Gordon, 2006) y la definición arriba propuesta es útil porque es simple, puede debatirse más transparentemente y permite ver las similitudes y discrepancias con otras definiciones y conceptos como: privación, recursos, estándares de vida, capacidades, consumo, etc. Varias de las confusiones en la definición de pobreza se originan por falta de claridad sobre la relación entre conceptos y teorías. Un concepto es una palabra sin teoría, lo que le da significado al concepto es lo que se establece en el cuerpo teórico que lo origina. Es decir, los debates giran en torno a la teoría que da origen al concepto y no sobre el concepto como tal. En el corazón de varios de los debates conceptuales existe la pregunta sobre el dominio para definir privación, i.e. el conjunto de necesidades que uno necesita tener en consideración para definir pobreza. Una de las disputas más conocidas en la literatura de pobreza es la discusión de los 1980s sobre pobreza relativa y absoluta. Townsend (1987) argumentaba que la pobreza es relativa: que varía en el tiempo y en el espacio. Esto significa que el conjunto de privaciones depende de lo que la sociedad considera como lo mínimo aceptable dados los estándares de vida vigentes. Sen (1983) disputó fuertemente la idea de que la pobreza es relativa. Para él la pobreza es absoluta en el sentido de no tener ciertas oportunidades básicas- falla en capacidades (ver abajo). Los intercambios entre Sen y Townsend quedaron registrados en Oxford Economic Papers en los 1980s. (Gordon, 2006) muestra que varias de las discrepancias eran semánticas y que en realidad ellos coincidían en que la pobreza podría tener dos umbrales. Boltvinik (1998) provee una recapitulación y discusión sobre los intercambios entre ambos autores y él nota que parte del desacuerdo tiene que ver con la falta de claridad del espacio para definir pobreza: satisfactores, necesidades, capacidades. Él nota que mientras que los satisfactores tienden a ser relativos, las necesidades tienden a ser más estables en el tiempo y el espacio. Esto queda registrado por Sen (1983) donde él reconoce que los satisfactores y sus características cambian en el tiempo, pero sostiene que al final se requiere establecer cuándo la gente cae no logra ciertas capacidades mínimas. Hay, sin embargo, dos dificultades para la operacionalización de capacidades. Primero, Thorbecke (2007) señala que observar capacidades requiere medirlas ex ante y que lo único que vemos en la práctica son manifestaciones de éstas -funcionamientos en forma de logro-. Esta reflexión es similar a otra- la pobreza es un concepto y lo que vemos son sus manifestaciones. Segundo, existe el reto de especificar el conjunto mínimo de capacidades. Mientras que algunos autores han propuesto una lista mínima (Nussbaum, 2000); otros como el mismo Sen (2005) Y Alkire (2007) se han manifestado en contra de esta idea. En el centro de este debate parece estar la falta de una clara distinción entre una lista teórica (que puede ser autoritaria) y una lista que tiene sustento empírico o validación basada en el juicio público o ejercicios empíricos. La medición de funcionamientos en forma de logros da una base para resolver la disputa sobre pobreza absoluta y relativa porque abre la posibilidad de que la pobreza pueda definirse vía los satisfactores socialmente definidos (la siguiente sección discute cómo esto encaja con el marco de variables latentes) (Spicker et al., 2006)1. En el espacio de los indicadores de logro/privación (\\(X\\)), hay poca diferencia relevante entre conceptos como funcionamientos y privaciones \\(x\\). Sin embargo, la cuestión sobre cuáles son los contenidos de (\\(X\\)) para definir y medir pobreza permanece sin respuesta consensada. La solución consiste en establecer el espacio de funcionamientos (que vinculan capacidades del marco de Sen) o del espacio de privación relativa basado en los estándares sociales siguiendo la tradición de Townsend. Ambos autores reconocen que este es el espacio clave y que es multidimensional en el sentido de que abarca los diversos aspectos mínimos que permiten que los humanos participen/funciones en una sociedad. 1.2 Las dimensiones de la pobreza Hay distintas teorías sobre las posibles dimensiones de pobreza y bibliografía especializada en el tema [Alkire (2002); Boltvinik &amp; Hernández-Láos (2001); Kakwani2008a]. Repasaremos brevemente las propuestas que han tenido mayor uso en la medición de pobreza: Las teorías de necesidades humanas, el marco de capacidades y privación relativa. Estas tres se han propuesto para enmarcar las (\\(j\\)) dimensiones de pobreza y sus contenidos (\\(x_{ij}\\)). Las teorías de necesidades humanas ha tenido una gran influencia en el enfoque de necesidades básicas insatisfechas (NBI) el cual tiene una larga historia en América Latina. Las teorías de necesidades de Maslow (1943) y Max-Neef, Elizalde, &amp; Hopenhayn (1992) son probablemente las dos con mayor influencia en los teóricos más notables de la región. Altimir (1979) y Boltvinik &amp; Hernández-Láos (2001) tomaron como referente estos marcos (en lugar de capacidades o privación relativa) para definir pobreza en términos de necesidades básicas insatisfechas. Boltvinik &amp; Hernández-Láos (2001), tras un trabajo de décadas, es quién ha desarrollado más el marco de NBI mediante la inclusión de la dimensión de tiempo y la discusión de umbrales adecuados para medir pobreza a finales del Siglo XX y XXI. El enfoque de NBI se ha caracterizad por tener un núcleo básico de necesidades para definir pobreza: acceso al agua, saneamiento, materiales/características de la vivienda, educación, alimentación y salud. En su reflexión histórica de la evolución del NBI y la medición de la pobreza en América Latina, Boltvinik (2014) nota que el NBI ha tenido distintas variantes, tanto en el número y tipo de dimensiones como en los métodos de agregación. Él identifica a la variante mejorada -aquella que incluye tiempo y da origen al Método Integrado de Medición de Pobreza (MIMP)- como el más avanzado en la región puesto que expande las dimensiones existentes y utiliza umbrales mucho más acordes a los estándares de la región [Boltvinik (1992); Boltvinik2001]. Una variante muy popular del NBI son las aproximaciones híbridas que combinan NBI con derechos sociales. Una de las aplicaciones más notables de este marco es la implementación de UNICEF para medir pobreza infantil multidimensional basándose en ocho dimensiones (Gordon, Nandy, Pantazis, Pemberton, &amp; Townsend, 2003). Una variante similar de estas propuestas híbridas es la medida oficial de México. Está medida tiene dos grandes dominios: Ingreso y derechos sociales. El segundo dominio tiene seis dimensiones: Vivienda, seguridad social, salud, educación, servicios esenciales y seguridad alimentaria (Cortés, 2014, p. CONEVAL2011d). Estas dimensiones provienen de la Constitución Mexicana y de la Ley General de Desarrollo Social. Sin embargo, la ley no especifica su contenido y el Consejo de Evaluación de la Política de Desarrollo Social (CONEVAL) tuvo que definir sus contenidos mediante un proceso participativo que incluyó expertos internacionales, al gobierno y una encuesta sobre condiciones de vida que se basa en el método consensual de Bristol (CONEVAL, 2011b). El marco de capacidades ha encontrado en el marco de NBI una forma, no exclusiva, de operacionalizar y definir los logros o indicadores de resultado. Un ejemplo, es el índice de Klasen (2000) que propone un índice de privación cuya estructura es similar a las dimensiones que salen del marco de NBI. Esto es comprensible porque el marco de capacidades puede encontrar indicadores de resultado en las encuestas que históricamente han mirado NBI. Esta conexión entre el marco de capacidades y el NBI es reciente y la estructura de las medidas de esta tradición es muy similar a las medidas que se implementaban en los 1970s y 1980s en América Latina (Capítulo XX discute algunas diferencias y contribuciones de esta escuela al NBI) (Boltvinik, 2014). Para Boltvinik (2014) esta implementación capacidades/NBI no es más que la variante original del método latinoamericano de Beccaria &amp; Minujín (1985) y un caso especial y reducido de la variante mejorada. La implementación más popular actualmente es el índice multidimensional de pobreza de PNUD-OPHI que busca medir pobreza aguda globalmente. Este índice propone tres dimensiones: nivel de vida, educación y salud (UNDP, 2014). Tal y cómo en los índices basados en NBI, este índice global tienen a la vivienda y a los servicios como aspectos clave de la medida. En América Latina ha existido una expansión de las dimensiones y se proponen cinco: Vivienda, servicios básicos, nivel de vida, educación y empleo (Santos &amp; Villatoro, 2016). La adición de empleo es similar a lo que se ha propuesto de Europa para el indicador de exclusión social, el cuál va más allá de la pobreza y ha sido ampliamente cuestionado (EUROSTAT, 2016). El último gran enfoque es el de privación relativa. La tradición iniciada por Townsend (1979) también propone una estructura jerárquica, pero propone distintas dimensiones y subdimensiones. Townsend (1979) sugirió dos dominios principales: privación social y privación material, con cuatro y siete subdimensiones respectivamente. Para privación material: dieta, ropa, combustible, facilidades en el hogar, condiciones de trabajo, salud y educación. Para la social: Ambiente, familia, recreación y social (Townsend, 1979, pp. 1173–1174). Los trabajos de la Encuesta de Pobreza y Exclusión Social (PSE) generalmente encuentran que algunas de los subdominios no funcionan tan bien para medir pobreza, como el de ambiente y condiciones de trabajo. Estos dominios no parecen ser indicadores de pobreza sino de exclusión social. Si bien la estructura de Townsend nunca se ha demostrado, hay propuestas que incluyen algunas de las subdimensiones de privación relativa (Betti, Gagliardi, Lemmi, &amp; Verma, 2015; A.-C. Guio, 2009; Whelan, Nolan, &amp; Maitre, 2006). Estos trabajos proponen modelos que van de tres a cinco dimensiones -aunque con diferentes nombres. A.-C. Guio (2009) propone un modelo que comprende estrés económico, falta de bienes muebles y vivienda; Whelan et al. (2006) proponen cinco dimensiones estrés económico, consumo, vivienda, ambiente en el vecindario y salud; y Betti et al. (2015) propone siete dimensiones que contienen casi todas las de Whelan et al. (2006) (Chapter X discute más las implicaciones de este modelo). Con las diferentes teorías que hemos revisado vale la pena recuperar nuestra definición simple y científica de pobreza de Townsend (1979; Gordon, 2006): Pobreza puede definirse como la falta de recursos en el tiempo y la privación material y social son sus consecuencias. Esta definición es útil porque es simple y no está en tensión con varios de los debates descritos arriba. La definición reconoce que la privación es multidimensional en tanto refiere a necesidades no satisfechas que son considerados como esenciales por la sociedad en algún momento determinado. Además, la definición es útil porque claramente vincula la causa (pobreza) con consecuencias (privación observada). Este aspecto es clave porque desde la perspectiva de filosofía de la ciencia, esta definición nos permite conecta a un constructo o abstracción del mundo con un marco estadístico que trabaja con datos multivariados y aproximaciones indirectas a un fenómeno. Hay otra razón por la cuál a definición de Townsend (1979)’s tiene ventajas sobre otras propuestas. Una de las dificultades en medición de pobreza es que muchas de las medidas actuales de pobreza confunden resultados con predictores de pobreza. Por ejemplo, indicadores como desempleo y discapacidad se incluyen como privación. Esto, por supuesto, añade error porque no estamos interesados en estimar pobreza sino en medir pobreza. Si no tuviéramos datos sobre privación, nuestra única opción sería estimar pobreza con un modelo predictivo. Por ejemplo, una de las áreas de punto en medición de pobreza es la estimación de áreas pequeñas (Rao &amp; Molina (2015)). Un tema central en la definición de pobreza es la definición de recursos. Hasta el momento, hemos hablado del set relevante de privación, pero muy poco de qué significa recursos. En la teoría de Townsend, bajo nivel de recursos significa tener múltiples formas de privación y propone los siguientes componentes (Townsend, 1979, p. 55): 1. Ingreso monetario a. Empleo b. Transferencias de hogares c. Beneficios de seguridad social 2. Activos y capital a. Valor de la vivienda b. Activos y seguros 3. Valor de empleo en especie a. Beneficios en especia del empleo b. Facilidades del empleo 4. Valor de la política social en especie a. Programas sociales y servicios de la política social 5. Ingreso privado en especie a. Autoproducción b. Regalos en especie c. Valor de servicios personales Esta categorización es pensada desde el Reino Unido y no todos estos recursos son importantes o son exclusivos en todos los países. Por ejemplo, Boltvinik &amp; Hernández-Láos (2001) propone que el tiempo es un recurso. Las medidas de NBI normalmente incluyen privación de servicios públicos y capturan el parte de la relación establecida en el componente tres de la definición de Townsend. Es muy importante notar que las similitudes entre la definición de Townsend y la definición de ingreso de Canberra-Group (2012). El traslape es muy alto. Esto ha producido malentendidos sobre la posición de Townsend respecto al ingreso porque se piensa que Townsend (1979) define pobreza como bajo nivel de ingreso en el tiempo. Esto es incorrecto, el problema es que la mayoría de las encuestas se enfocan en recolectar información sobre el ingreso usando la definición del grupo de Canberra y, por tanto, nuestro mejor proxy de recursos es ingreso. Esta es la razón por la que la Encuesta de Pobreza y Exclusión social (PSE) u otras propuestas utilizan ingreso como aproximación a recursos. Hasta ahora hemos discutido algunos de los elementos que se necesitan para definir y medir pobreza, pero no hemos dicho mucho sobre qué pasa una vez que los aspectos sustantivos de la pobreza se han definido. Es decir ¿Cómo se clasifica al grupo pobre y no pobre usando los datos disponibles? Esta nos lleva a la pregunta principal del libro: ¿Qué criterios o principios nos llevan a falsear los contenidos y la identificación del grupo pobre en una escala? Para tener una idea de todo lo que está detrás de esta pregunta es fundamental revisar algunos de los retos en medición de pobreza. 1.3 La medición de la pobreza y sus retos El concepto de pobreza conlleva el supuesto de la existencia de un mínimo nivel de vida que permite separar a la población en dos grupos y que cada uno tendrá un significado consistente con nuestra teoría de pobreza. Las y los investigadores, por tanto, tienen que hacer una serie de decisiones críticas sobre cómo seleccionar las dimensiones y sus indicadores, pero también sobre cuál es la mejor forma de agregar la información para que el grupo pobre pueda identificarse con precisión (Alkire, 2007; Thorbecke, 2007). Este es un proceso que resulta en varias decisiones que demandan justificación teórica y escrutinio empírico: Especificar las dimensiones \\(j\\) Especificar los contenidos (indicadores) de cada dimensión \\(x_{ij}\\) Decidir el umbral \\(x_{ij}&lt;z\\) de los indicadores para identificar privación/logro Establecer un modelo de medición sobre la relación entre indicadores y dimensiones Decidir la contribución relativa de cada indicador (pesos) a cierta dimensión \\(w_{ij}\\) o de cada dimensión \\(w_j\\) Decidir cómo agregar la información para ordenar a la población de bajo a niveles de vida más altos Decidir cómo separar a la población con base en tal ordenamiento en grupos \\(p_k (x_i;z) = 1\\) si \\(c_i\\leq k\\) and \\(p_k (x_i;z) = 0\\) o de otra manera 1.3.1 Retos en la selección de dimensiones, contenidos, umbrales y pesos Respecto a los primeros tres retos, Gordon &amp; Nandy (2012) aclara que, aunque hay consenso sobre que la pobreza es multidimensional, hay desacuerdos sobre el número, contenidos y naturaleza de las dimensiones de pobreza. Los marcos teóricos que repasamos en la sección anterior difícilmente proponen con claridad un número de dimensiones y, aunque algunos muestran cierto traslape respecto a las dimensiones que proponen, no hay acuerdo sobre el contenido y características de las interacciones al interior y al exterior de cada dimensión. Alkire (2007) repasa algunos de los diferentes métodos para establecer las dimensiones, sus indicadores y sus interacciones (consenso público, datos existentes, convenciones, procesos participativos, datos sobre lo que valora la población). El conjunto típico de dimensiones propuestas desde el enfoque de capacidades, NBI y privación relativa se revisaron en la sección previa. Un ejemplo clave en la medición moderna de la pobreza, en tanto está anclado en una teoría e incluye un componente democrático, es el método consensual de privación. Mack &amp; Lansley (1985) crearon un parteaguas en la medición de pobreza puesto que vincularon la teoría de privación relativa con una evidencia empírica sobre las necesidades socialmente percibidas por la población. Más recientemente otros autores, desde el tradición de capacidades, han intentado encontrar con estudios participativos las necesidades para la vida (Clark &amp; Qizilbash, 2005; Narayan, 2001). Aunque la especificación teórica o mediante datos empíricos ayuda a delimitar el espacio relevante de las necesidades para definir y medir pobreza, no resuelve los problemas de la interacción sobre los indicadores y sus dimensiones. Tampoco garantiza que la lista que obtenemos resulte en una versión precisa de las dimensiones de la pobreza. Hay varias razones. Primero, estos métodos necesitan distinguir entre necesidades y preferencias (Es decir, sobre cómo separar los deseos de la incapacidad de tener o hacer) (McKay, 2004). Otra crítica es sobre la cómo decidir cuando algo es necesario cuando no hay acuerdo del 100% sobre las necesidades que se preguntan (Bradshaw, Holmes, &amp; Hallerod, 1995). Finalmente, existe la crítica sobre cómo es posible hacer trabajo comparativo, es decir, cómo comparar sociedades con diferentes necesidades. Hay, sin embargo, desde el punto de vista estadístico -el objetivo de este libro-, una respuesta satisfactoria a todas estas preocupaciones. Recuperaremos estas críticas a lo largo del libro y mostraremos que una vez que se cumplen ciertos principios de la teoría de la medida, estas críticas pierden relevancia. La determinación de los umbrales para los indicadores y sus dimensiones es central puesto que es una de las mayores fuentes de variación en un índice de pobreza. Thorbecke (2007) señala que esto generalmente se hace de manera subjetiva o normativa y que esto puede llevar a importantes discrepancias y afectar la reproducibilidad de una medida. Dejando de lado las propuestas que se basan en teoría para fijar umbrales para variables nominales, el método consensual podría también utilizarse para hallar el mejor umbral. El mejor ejemplo es lo que hizo el CONEVAL para la producción de su índice en dónde los umbrales se decidieron con base en el método consensual, criterios de expertos y una revisión de las normas para México (CONEVAL, 2011a). Thorbecke (2007) indica que la clave, al fin, es encontrar una serie de umbrales que lleven a una ordenación consistente de la población dadas las medidas observadas de privación. 1.3.2 Retos en la agregación e identificación del grupo pobre Encontrar el espacio para la definición de necesidades, dimensiones y umbrales es sólo una etapa de dos en medición de pobreza multidimensional. (Thorbecke, 2007, p. 7) señala lo siguiente: Asumamos que, a pesar de las dificultades discutidas arriba, hay acuerdo sobre la lista de los atributos relacionados con pobreza y sus respectivos umbrales ¿Cómo esta información puede utilizarse para producir medidas de pobreza multidimensional y cómo hacer comparaciones de pobreza? En el caso más simple, por ejemplo, en el que un individuo está por debajo del umbral de todos los atributos. Esta persona debería ser sin duda pobre. Análogamente, comparando dos individuos con perfiles (A y B) donde los scores de privación para todas las n dimensiones en el perfil de A están por encima del perfil B, se podría decir que A tiene una mejor posición (es menos pobre) que el perfil B. La cuestión sobre cómo agregar los indicadores y cómo dividir a la población en dos grupos ha estado presente desde los estudios clásicos de pobreza. Desde una perspectiva teórica, hay tres propuestas para establecer la línea de pobreza. Townsend (1979) propuso una teoría que predice que debe haber un nivel de recursos (causa) a partir del cual la privación múltiple aumenta sustancialmente (consecuencia) (Esta teoría se conoce como el punto de quiebre de Townsend). Este punto de inflexión debería servir para identificar la línea de pobreza puesto que lleva a una división conceptualmente válida de la población: la población cuyos niveles de vida son tan bajos que están efectivamente excluidos de los patrones comunes y esperados de vida en su sociedad. Dentro de esta propuesta, la agregación consiste en contar el número de privación (score de privación) y encontrar la separación óptima con base en la relación entre recursos y privación. P. Townsend &amp; Gordon (1993), además, argumenta que cuando usamos datos de corte transversal, la mejor forma de separar a la población es usando la intersección de recursos y privación (ver (Gordon, 2010)). Esto se debe a que con este tipo de datos no podemos ver si la gente está saliendo o entrando a pobreza y que es mejor identificar como “verdaderamente” pobres a aquellos que cumplen ambos criterios. Este es el tipo de aproximación utilizado por CONEVAL para identificar pobreza en México (CONEVAL, 2011a). Un aspecto distintivo de la predicción de Townsend es que las dimensiones no figuran en la identificación, aunque se sigue considerando la multiplicidad de atributos que caracterizan a la pobreza multidimensional. El criterio de intersección ha sido ampliamente criticado porque existe el riesgo de minimizar la prevalencia de pobreza. Una segunda propuesta se basa en el criterio de unión (basta tener privación en recursos o en necesidades básicas). Esta forma de identificar pobreza es parte del método integrado de Boltvinik (Boltvinik &amp; Hernández-Láos, 2001). Este método busca minimizar la exclusión del grupo pobreza y parte de la visión de que el ingreso, la privación material y de tiempo son tres atributos que caracterizan distintos aspectos del ser humano. Por tanto, la carencia de uno basta para caracterizar a una persona como pobre. Esto es distinto a lo que propone Townsend, donde privación es una manifestación de bajos recursos en el tiempo (Ver (Gordon, 2010, p. @Cortes2014) para una discusión desde la perspectiva de las dinámicas de pobreza y derechos humanos). El tercer marco carece de teoría sobre el significado de la línea de pobreza y se enfoca más en la agregación de los indicadores y no tanto en la identificación del grupo pobre (Foster, Greer, &amp; Thorbecke, 2010). Para comprender lo que está detrás de este tercer marco es importante revisar sus fundamentos. Sen (1976) fue el pionero del marco axiomático y lo propuso pensando en medidas univariadas de ingreso o gasto. Sen (1976) puso énfasis en la importancia de la agregación ya que tiene importantes consecuencias para la descomposición y análisis que van más allá de la prevalencia de pobreza. Hay dos axiomas que son críticos en esta propuesta: monotonicidad (la pobreza debe caer si hay una mejora en logros) y transferencia (la pobreza aumenta si hay una transferencia de los pobres a los no pobres). Posteriormente, Foster, Greer, &amp; Thorbecke (1984) extendió los axiomas de Sen y propuso una familia de medidas de pobreza. Esta propuesta se ha extendido para medidas multidimensionales (S. Alkire &amp; Foster, 2011; Alkire et al., 2015; Tsui, 2002). El índice axiomático más popular es el Alkire-Foster (AF) y respeta varios axiomas como monotonicidad, simetría, replicación invariante, escala invariante, foco en pobreza y descomposición para subgrupos (Alkire et al., 2015, se recomienda para una descripción completa). Este índice resulta en una fórmula de agregación que produce un índice que tiene una conducta predecible en el sentido de los axiomas: \\[ P_{AF}(X;z)= \\frac{1}{n}\\sum _{i=1}^{n}\\sum _{j=1}^{d}w_{j}g^{\\alpha }_{jk}(k);\\alpha\\geq0 \\] La formulación del método AF \\(x\\) son los logros/carencias en forma de indicadores o dimensiones de una matriz \\(X\\) y \\(z\\) son los umbrales de privación \\(x_{ij}&lt;z_j\\), \\(i\\), son los individuos u hogares y \\(j\\) las dimensiones. Una persona tiene privación en la dimensión si \\(g^{0}_{ij}=1\\). Los pesos son incluidos con \\(w_j\\) y \\(\\alpha=0\\) cuando se busca estimar la prevalencia de pobreza y \\(\\alpha=1\\) para la brecha de pobreza ajustada. Un aspecto crucial que regularmente es incorrectamente ignorado cuando se considera la fórmula AF es que hay una diferencia decisiva entre un método de agregación (fórmula) y una metodología de medición (serie de pasos). La familia AF de midas impone una serie de axiomas para que la fórmula de agregación se comporte de manera predecible. Sin embargo, el hecho de que esté basada en axiomas no hace que la medición sea precisa o correcta. Una condición necesaria para que la fórmula produzca resultados robustos es que los supuestos sobre la selección de indicadores, dimensiones y pesos sea adecuada y se mida pobreza. A diferencia de la agregación simple que se usa en el enfoque de privación relativa (score de privación), la formulación axiomática si considera explícitamente los pesos (S. Alkire &amp; Foster, 2011). Esto puede o no ser una ventaja, en el Capítulo 3 se discute con mayor profundidad las ventajas y desventajas de usar pesos y trataremos este tema dentro de un marco más claro de medición que puede falsear si los pesos son necesarios o no. Uno de los objetivos de este libro es aclarar por qué los principios de la teoría de la medida son una condición necesaria para que la formulación AF funcione, el método AF no es una condición necesaria para la medición de la pobreza. ## Los grupos pobre y no pobre: La línea de pobreza Desde un punto de vista conceptual, la línea de pobreza puede definirse como el nivel mínimo de vida que es aceptable en una sociedad en un punto en el tiempo. La línea de pobreza se expresa en términos monetarios o no monetarios (un nivel de ingreso o un valor del score ponderado o no de privación). Este no es un libro sobre medición de pobreza por ingreso pero cuando se utiliza el método de ingreso, Van den Bosch (2001) identifica los siguientes métodos2. Peter Townsend (1993) discute algunos problemas con la aproximación exclusiva a pobreza basada en ingreso: Canasta básica/Presupuesto: El precio de una canasta de bienes y servicios básicos. Una variante de este método fue utilizada por Rowntree (1901) y más recientemente ha sido utilizado por Bradshaw (1993) and Bradshaw et al. (2008). Estándares oficiales: Un costo arbitrario es fijado por una oficina de estadística para dividir a la población. Esto puede basarse en algún estándar de ingreso mínimo o en el sistema de seguridad social. Razón basada en alimentación: Asume que los estándares de vida pueden juzgarse mediante la comparación de la proporción del gasto que destina un hogar a alimentos. Método relativo: El umbral de ingreso se fija para cierto porcentaje (mediana o media) del ingreso. Algunos países europeos utilizan el 60% de la mediana, por ejemplo. La introducción de los métodos directos (en el sentido que usan observación de privación, no es que midan pobreza directamente) ha abierto la discusión sobre cómo ingreso y privación deberían combinarse para identificar al grupo pobre (Boltvinik, 1998, 2014; Boltvinik &amp; Hernández-Láos, 2001; Gordon, 2010). Este debate lo repasamos anteriormente y es sobre los criterios de unión e intersección. Mencionamos que el criterio de unión ve al ingreso y a la privación como dos medidas del mismo fenómeno y, por tanto, estar por debajo de cierto umbral en alguno de los dos es la forma de identificar pobreza. En contraste, el criterio de intersección propone que ambos deben utilizarse para identificar al grupo pobre: la carencia de ambos. Mientras que el criterio de unión da el tope más alto de la prevalencia de pobreza el de intersección da el tope más bajo. Una tercera opción es un punto medio entre ambos métodos (S. Alkire &amp; Roche, 2011; Santos &amp; Villatoro, 2016). El ingreso se dicotomiza usando un umbral \\((x;z)\\), después se pondera este indicador y se incluye en el score de privación. La inclusión parcial del ingreso entonces se obtiene mediante el uso de pesos diferenciales. La línea de pobreza se fija respecto a algún porcentaje del score total de privación (Típicamente 25% o 33%). Un argumento desde el punto de vista práctico a favor del método de intersección parte de las dinámicas de pobreza. Cuando se utilizan datos de corte transversal no es posible ver la trayectoria que siguen los individuos, si mejora, empeora o permanece constante su nivel de vida. Algunos hogares pueden tener alto ingreso, pero sus efectos tal vez no se vean reflejados en las carencias que presentan. Esto los pondría directamente como pobres bajo el método de unión. Sin embargo, en el mediano plazo podrían presentar una situación muy distinta. Para Katzman (2000) estas dinámicas dan origen a grupos vulnerables por ingreso o por carencia a la pobreza. Se requerirían datos panel de alta calidad para identificar a los verdaderamente pobres bajo el criterio de unión (Gordon, 2006; Halleröd, 1995). Cuando se discuten las líneas de pobreza es importante preguntarse cuál es la teoría que está detrás de cada método. Desafortunadamente, las teorías de pobreza son raramente explícitas y definen con imprecisión la línea de pobreza. Podemos resumir las propuestas principales de la siguiente manera: Punto de quiebre de Townsend (Townsend, 1979; Peter Townsend, 1993): Quizá el marco teórico más explícito respecto a la relación recursos, pobreza y privación. Este marco predice que hay una relación negativa no lineal entre recursos y privación y que existe un punto de inflexión en la relación a partir del cual la privación múltiple aumenta considerablemente. Método normativo basado en derechos sociales: Los derechos sociales son indivisibles y están interrelacionados. Por tanto, tener una carencia en un derecho captura una situación general de violación de derechos. CONEVAL (2011a) utiliza el criterio de una o más privaciones y un ingreso menor a la línea de bienestar (método de canasta básica) para identificar a la población pobre (Cortés, 2014). Método normativo del método integrado: Boltvinik &amp; Hernández-Láos (2001) propone que la pobreza tiene tres dimensiones: tiempo, recursos y NBI. La gente se encuentra en pobreza si falla en alguna de las tres. Criterio arbitrario: Sin una justificación teórica clara, algunos investigadores fijan la línea de pobreza a algún valor del score de privación. Por ejemplo, el 50% de la suma ponderada de carencias. Por ejemplo, si hay 10 privaciones y el umbral es 30%, la gente con 3 o más privaciones será clasificada como pobre. Estos criterios, por supuesto, producen importantes discrepancias en las tasas de prevalencia de la pobreza. Esto ocurre incluso cuando se utilizan los mismos indicadores, pero se usan estrategias distintas para fijar la línea de pobreza. La pregunta entones es cómo resolver este reto desde una perspectiva empírica. Este aspecto se cubre en el siguiente capítulo y concretamente en el capítulo 8. 1.4 Una breve revisión de la historia de la medición de la pobreza Los debates que hemos revisado sobre que es pobreza, cuáles son sus dimensiones, qué supuestos usualmente se levantan para producir una medida y cómo fijar la línea de pobreza han influenciado las distintas formas de capturar este fenómeno. Así, las diversas formas para producir una medida de pobreza han dado forma a la historia y escuelas de medición de pobreza. La investigación y medición de la pobreza tienen más de 100 años de historia. El trabajo monumental y ahora clásico de Rowntree (1901) ‘Poverty: A study of Town Life’; el de Booth (1903) ‘Life and Labour of the People in London’ y el de Townsend (1979)‘s `Poverty in the UK’ fueron posibles después de años, incluso décadas, de trabajo continuo que apuntaba a entender el tamaño, distribución y naturaleza de la pobreza. Un denominador común de estos estudios es que todos utilizaron un cuestionario explícitamente diseñado para medir pobreza. Esto contrasta dramáticamente con la mayoría de las prácticas actuales de medición de pobreza en las que este fenómeno es raramente medido con un cuestionario expresamente formulado para medirlo. Hay diferencias fundamentales entre los tres estudios arriba mencionados. Quizá, la más fundamental es que el trabajo de Townsend (1979) estaba completamente enmarcado por una teoría tanto de medición como de explicación de pobreza y usó por primera vez para el Reino Unido indicadores directos de privación y no sólo ingreso. El legado de estos estudios ha sido tal que la agenda de investigación de pobreza se expandió aceleradamente en el Siglo XX y ha continuado en el siglo XXI. La Figura 1.1 sintetiza crudamente la historia reciente de la medición multidimensional de pobreza. Los orígenes de la pobreza multidimensional pueden rastrearse a Europa y América Latina en los 1960s y 1970s. Los países latinoamericanos estuvieron a la vanguardia en medición multidimensional gracias al enfoque de necesidades básicas insatisfechas (NBI), el cuál utilizaba indicadores directos de carencia para capturar pobreza [Altimir (1979); Beccaria1985;Boltvinik1992;Boltvinik2001]. En la Sección XX se mencionaba que este enfoque tiene en el corazón a la vivienda, educación y a los servicios básicos como dimensiones fundamentales. Esto en parte por las limitaciones de la información disponible. Boltvinik &amp; Hernández-Láos (2001) ha sido quién más ha ajustado, expandido y enriquecido el enfoque de NBI. Su variante mejorada es la que teóricamente se encuentra a la punta con la innovación de pobreza de tiempo principalmente. Este enfoque de medición se ha adoptado ampliamente no sólo en la región, sino que ha influenciado propuestas contemporáneas para la medición global como la del Índice Multidimensional de Pobreza (IMP) del Programa de Naciones Unidas para el Desarrollo (PNUD) y ha sido la base de medidas oficiales como la Mexicana (CONEVAL, 2011b). En el mundo desarrollado, la teoría de Townsend (1979) de privación relativa no sólo produjo el primer cuestionario explícitamente diseñado para medir pobreza multidimensional sino que también propuso un modelo de medición multidimensional. En los 1980s, el uso de indicadores de privación fue ampliamente reconocido como la mejor aproximación al fenómeno de la pobreza. Esto quedó plasmado en la serie de intercambios entre Townsend (1985), Sen (1983) y Sen (1985) sobre los conceptos de pobreza absoluta y relativa. Este no es un libro sobre medición monetaria de la pobreza pero es importante mencionar la contribución del marco axiomático de Sen para el futuro desarrollo de axiomas para medidas multidimensionales Sen (1976) y Foster et al. (1984). En los años tardíos de la década de los 1980s y entrados a los 1990s, la propuesta de Townsend fue mejorada con el desarrollo el método consensual de privación propuesto por Mack &amp; Lansley (1985) puesto que añadió un componente vital empírico al marco de privación relativa. Esta aportación consistió en el desarrollo de un flujo de cuestionario que permite distinguir entre privación por pobreza y privación por otro fenómeno. Es decir, mediante una distinción entre la causa de carecer de ciertos bienes, servicios o actividades. En los 1990s, Europa continuó incorporando y desarrollando el método basado en la teoría de privación relativa pero Latinoamérica abandonó la medición multidimensional -aunque en el círculo académico seguía el desarrollo del NBI- y se enfocó en la monetaria, la cual se convirtió en el método más adoptado en países en desarrollo, condujo al método de Banco Mundial y llevo al inevitable pero rico debate sobre este tipo de medición (Pogge, 2005; Ravallion, 2010; Reddy &amp; Pogge, 2010). Figure 1.1: A brief summary of the history of poverty measurement El Siglo XXI ha sido testigo del retorno de la medición multidimensional a nivel global. En Europa, el trabajo de Bristol con la encuesta de Pobreza y Exclusión Social (PSE) ha continuado con la tradición de Townsend. Junto con el NBI esta es la tradición que tiene mayor historia y desarrollo. Los trabajos de Townsend &amp; Gordon (2000), Pantazis, Gordon, &amp; Levitas (2006) y Mack &amp; Lansley (1985) han tenido gran resonancia en Europa (Atkinson, Guio, &amp; Marlier, 2017; Whelan et al., 2006). Esto ha culminado en lo que tal vez es la medida, basada en privación relativa, más sofisticada y robusta producida hasta ahora en el mundo: El índice de privación de EUROSTAT [Guio et al. (2012); Guio2017]. Esta medida es la única que ha pasado convincentemente varios criterios estadísticos fundamentales y que ha resultado en una escala completamente comparable a lo largo de 27 países (ver abajo). De manera paralela, el marco axiomático, que viene de la economía, fue extendido para medidas multidimensionales (Foster et al., 2010; Tsui, 2002). Estas contribuciones y el marco de capacidades han sido muy influyentes en algunos ejercicios de pobreza recientes (S. Alkire &amp; Foster, 2011; Alkire et al., 2015; Kakwani &amp; Silber, 2008). Sin embargo, el marco axiomático, en tanto es un método sin metodología clara, se ha resguardado en el enfoque de NBI. Como atinadamente apunta Boltvinik (2014), este marco axiomático depende más del NBI que el NBI de éste. Más allá del cálculo de las medidas de severidad e intensidad, es poco claro cuál es la contribución concreta de este marco a la medición de la pobreza puesto que no facilita la selección de indicadores desde un punto de vista teórica ni tampoco tiene una contraparte empírica clara. Quizá esto se debe a que al final ambos utilizan la información estadística que está a su disposición y terminan utilizando indicadores similares. De la misma manera, el surgimiento del enfoque de derechos humanos a inicios del Siglo XXI ha ido bastante de la mano de los indicadores clásicos del NBI. Un aspecto decisivo es que la articulación de pobreza con derechos humanos ha permitido la institucionalización progresiva a nivel nacional e internacional de medidas multidimensionales de pobreza (Boltvinik, 2014; CONEVAL, 2011a). El trabajo, por ejemplo, de Gordon et al. (2003) sobre pobreza infantil fue pionero en el uso de datos internacionales harmonizados para medir pobreza multidimensional haciendo uso del marco de derechos de la infancia y el enfoque de NBI. La medida de pobreza aguda de PNUD en colaboración con la Iniciativa de Pobreza y Desarrollo Humano (OPHI) es otro gran ejemplo de uso de datos harmonizados que recaen en las dimensiones del NBI. Una diferencia puntual es que la medida de PNUD-OPHI utiliza el método de agregación AF para producir prevalencia y severidad de pobreza (Alkire &amp; Santos, 2010; UNDP, 2014). 1.5 Estado del escrutinio empírico en la práctica de la medición de pobreza La medición multidimensional de pobreza se encuentra en un momento decisivo en el que hay una búsqueda de respuesta a la siguiente pregunta: ¿Qué caracteriza a una medida robusta de pobreza desde el punto de vista empírico? Las comparaciones entre medidas se han dado normalmente en términos teóricos o discursivos. Sin embargo, en la producción ciencia de índices y escalas, una medida requiere escrutinio empírico. Hemos mencionado que todas las medidas se basan en supuestos y que estos demandan una contraparte empírica. Esto ha quedado plasmado en el Principio 4 reporte de Banco Mundial sobre medición de pobreza (World-Bank, 2017) Validación de la robustez de los resultados de los indicadores seleccionados. ¿Qué medidas hasta ahora han incorporado escrutinio empírico? El Proyecto de Pobreza y Exclusión Social (PSE) fue criticado porque en la medición se incluían indicadores que no tenían una relación muy fuerte con recursos en el tiempo y producirán resultados inesperados cuando se comparaban grupos. En particular, McKay (2004) mostró que algunos de los indicadores derivados del método consensual sufrían de preferencias adaptativas. Gordon (2006) consideró que los principios científicos de validez y confiabilidad (Ver Capítulo @ref()) deberían ser útiles para hacer escrutinio de medidas de pobreza. Desde entonces el Proyecto de Pobreza y Exclusión Social ha incorporado la teoría y métodos de escrutinio de índices que se utilizan desde hace más de 100 años en otras disciplinas. La ventaja de esta propuesta de revisión es que se basa en conceptos y métodos ampliamente utilizados en ciencias y se conocen bien sus propiedades, ventajas y desventajas. Además de las medidas del proyecto de la PSE, sólo dos medidas oficiales han sido puestas a escrutinio estadístico basado en la teoría de la medida: EUROSTAT and CONEVAL. La mediad de EUROSTAT fue producida por Guio et al. (2012) y se mostró un conjunto de indicadores que llevaban a una medida válida y confiable. Después, Guio et al. (2017) rehízo el análisis para ver si la validez y confiabilidad de la medida se mantenían y también para verificar si la medida era comparable a nivel país en Europa. Esta medida se basa en el método consensual de privación y es la única medida en el mundo que cumple lo siguiente: Tiene teoría Una definición clara de pobreza Usa datos específicamente recolectados para medir pobreza Es confiable Es válida Es comparable Como veremos estos seis puntos son fundamentales porque separan a una medida ideal de lo que en la práctica normalmente se hace para medir pobreza. En la Figura 1.1 se muestra que hay varias flechas apuntando a la medida del CONEVAL (medida oficial mexicana). Esto se debe a que es la primera medida oficial en el mundo que tuvo un proceso deseable para su producción. Desde un cambio clave a la Ley General de Desarrollo Social en 2004, México adquirió la obligación de medir pobreza desde una perspectiva multidimensional conforme a lo establecido en la constitución. Esto resulto en un proceso internacional de consulta. Mora (2010) compiló las distintas contribuciones de los autores y CONEVAL (2011b) resume las aportaciones finales de cada autor. La medida resultante es una medida híbrida que se beneficia de la colaboración internacional y ha sido la primera en validarse estadísticamente antes de ser producida. Un aspecto distintivo de esta medida es que, CONEVAL se basó en Townsend (1979) y el método consensual para valorar los contenidos de las dimensiones y sus umbrales desde el punto de vista social. Gordon (2010) hizo una evaluación preliminar de la validez y confiabilidad de los indicadores y sugirió el método de la línea óptima (Punto de Quiebre de Townsend) para identificar a la población pobre. El método AF ha sido utilizado para calcular la profundidad e intensidad del dominio de ingreso y privación. Ambos organismos EUROSTAT Y CONEVAL han sido casos exitosos en la producción de medidas de pobreza que no solamente tienen una teoría clara, sino que además tienen una validación empírica estándar. Esto es, sin embargo, una excepción relativo a otros enfoques en medición de pobreza que se encuentran bastante rezagados respecto a la teoría de la medida en tanto usan métodos que no son estándar y miran a los síntomas y no a las causas de poco confiabilidad e invalidez. Un ejemplo, de un desarrollo en ciernes es la propuesta de OPHI y de Alkire et al. (2015). Esta propuesta se basa en análisis de sensibilidad de una medida a cambios en indicadores, pesos y umbrales. Si bien esto puede resultar útil, esta propuesta carece de principios de análisis anclados en una teoría de medición y no se tiene una hipótesis clara de lo que se pretende encontrar. Entonces, los análisis de sensibilidad son útiles en la medida en la que el investigador esté despuesto a ser sensible y cuidadoso con la interpretación, pero aunque lo sea es muy probable que sus resultados no sean reproducibles porque hay demasiados grados de libertad en su aplicación. Para cerrar este capítulo es importante mencionar que varias revistas científicas están abogando por el uso de medidas válidas y confiables. Como mencionamos, medidas con ruido llevan a resultados irreplicables y por tanto son de poca utilidad. El resto del libro elabora un marco completo de medición que apunta a reducir la producción de escalas que magnifican ruido. "],
["Chapter-2.html", "Capítulo 2 Pobreza y teoría de la medida: Un marco estadístico 2.1 Ruta crítica para medición multidimensional de pobreza 2.2 La teoría de la medida como marco estadístico para la medición 2.3 Modelo latente de medición de pobreza 2.4 Esquemas y modelos de medición de pobreza 2.5 Principios de la teoría de la medida", " Capítulo 2 Pobreza y teoría de la medida: Un marco estadístico Resumen Este capítulo propone un marco estadístico para enfrentar algunos de los retos actuales en la medición multidimensional de la pobreza. El marco se basa en la teoría de la medida y se propone para el diseño y escrutinio empírico de los supuestos clave en la producción de medidas multidimensionales de pobreza. El capítulo parte de la ruta crítica para producir medidas científicas y posteriormente introduce los principios de confiabilidad, validez, medición invariante y equivalización de escalas, mismos que serán definidos y desarrollados en el resto del libro. 2.1 Ruta crítica para medición multidimensional de pobreza El capítulo 1 esbozó algunas de las tareas fundamentales en el desarrollo y producción de índices multidimensionales de pobreza y subrayó el tipo de supuestos que los investigadores tienen que levantar en cada etapa: número de dimensiones, indicadores y umbrales, pesos de indicadores y dimensiones, agregación y producción del score de privación y la especificación de la línea de pobreza (Alkire (2007); Thorbecke (2007) y Gordon &amp; Nandy (2012)). La Figura 2.1 ilustra la estrategia que regularmente, en la práctica, siguen los investigadores para producir un índice de pobreza. Esta estrategia no es idea porque generalmente la medición precede a los datos (la información está dada). Por tanto, los investigadores tienen poca influencia sobre el proceso de recolección de datos y, por tanto, tienen que adaptarse a la información existente sobre privación observada y reformular su definición de pobreza -incluso en los peores casos, ellos tienen que adaptar la definición a los datos-. En una siguiente etapa se levantan una serie de supuestos sobre los contenidos de la medida -dimensiones, indicadores, pesos y línea de pobreza- (ver Capitulo 1. Idealmente, estos supuestos deberían examinarse usando un marco claro de medición, pero en la práctica los investigadores evaden o ignoran esta etapa. En otros casos, realizan una serie de análisis ad hoc de sensibilidad. La limitación es que este tipo de escrutinio no parte de una hipótesis clara y los investigadores corren el riesgo de confirmar sus prejuicios por falta de una estrategia clara de falseo. El sesgo de confirmación, por tanto, tiene mayor probabilidad de permanecer, así como la validación empírica a desdibujarse. Los investigadores, por tanto, pueden dar un salto de la medida propuesta desde la teoría al proceso de agregación. Figure 2.1: Flujo de trabajo que regularmente se sigue en la medición de pobreza La medición científica demanda una relación clara entre teoría, conceptos, datos y un marco claro para falsear los supuestos del investigador. La Figura 2.2 muestra la ruta crítica para que los investigadores puedan reducir el riesgo de sesgos de confirmación y error en la medición. Primero, los conceptos adquieren significado a través del marco teórico utilizado para su definición. Es decir, el concepto debe estar anclado en una teoría clara de pobreza. Segundo, la definición de pobreza debe ser científica en el sentido de que sus contenidos sean verificables de alguna manera Capítulo 1. Posteriormente, la definición y teoría en cuestión debe utilizarse para diseñar un cuestionario para colectar datos que están pensados para medir pobreza. Los investigadores pueden entonces especificar el tipo de modelo o estructura de la medida de pobreza. Es decir, el número de dimensiones, indicadores, etc. Una vez que se tengan tanto los datos como la especificación, se pueden falsear los supuestos usando un marco estadístico adecuado. Los resultados de este proceso pueden utilizarse para pulir la medida en un proceso iterativo -apegado a la teoría-. Una vez que la medida sea robusta (usando como criterios los del marco de medición adoptado), los investigadores pueden agregar los indicadores y a identificar al grupo pobre y no pobre. Figure 2.2: Flujo de trabajo que debería seguirse en la medición de pobreza Esta ruta crítica para producir medidas de pobreza permite identificar la relación entre teoría, datos y métodos de evaluación. Estos tres aspectos, al final, son esenciales en cualquier programa de investigación científico. Una forma útil y factible de avanzar de forma ordenada en el análisis empírico de medidas de pobreza consiste en detectar los supuestos que levantamos y reconocer sus implicaciones. Una vez hecho esto es posible pasar a un marco falsable de medición. Esto significa, levantar preguntas sobre todos los supuestos y proponer un método que busque responder si las ideas del investigador se sostienen dados los datos. Los retos de la medición multidimensional de pobreza pueden ponerse en términos de etapas secuenciales. De hecho, estos elementos son parte de un esfuerzo que busca aproximar la prevalencia e identificación de pobreza y pueden escribirse en términos de un modelo estadístico. Es decir, vamos a comenzar a poner los supuestos y reto de la medición en términos de un modelo que tenga una contraparte estadística. Este modelo no es más que una versión más simple e imperfecta de la pobreza que tiene reflejo en los datos observados. Como plantea McCullagh (2002), la idea de un modelo estadístico parte del reconocimiento de que la caracterización de un fenómeno es simplemente una aproximación. Como tal, un modelo para medir pobreza es una opción que puede y necesitar evaluarse y mejorarse. Antes de decir cómo un modelo de pobreza puede examinarse y mejorarse, es importante presentar un marco explícito que permita posicionar nuestros supuestos de forma falsable. 2.1.1 Identifiación del espacio de muestreo Es un poco extraño pensar en muestreo en medición porque lo relacionamos con encuestas y recolección de datos en campo. Sin embargo, en medición el concepto de muestreo de información es muy importante. Uno de los aspectos ignorados en medición de pobreza es que los investigadores nunca trabajan con información completa. Esto no se refiere a uso de datos censales sino a la información perfecta para producir un índice. La razón principal es que el conjunto de indicadores perfectos para medir pobreza se desconoce o no está disponible. Dada una definición de pobreza, hay diferentes dimensiones, indicadores y parámetros para producir un modelo que aproxime vía datos el nivel individual de severidad de pobreza. Las opciones de dimensiones, indicadores, pesos y umbrales pertenecen a un espacio desconocido pero ideal que incluye todas las opciones. Este es un aspecto crucial en medición de pobreza y subraya el hecho de que hay un supuesto general en medición (basado en teoría o datos) sobre qué subconjuntos tienen mayor probabilidad de medir con poco error pobreza. Espacio de muestreo de todos las dimensiones posibles \\(\\mathscr J\\) Espacio de muestreo de todos las variables \\(\\mathscr X\\) Espacio de muestreo de todos los parámetros posibles (e.g. pesos) \\(\\Theta\\) Estos espacios entonces nos llevan a imaginar el modelo ideal para medir pobreza y que puede escribirse de manera compacta como: \\[\\begin{equation} \\tag{2.1} \\mathscr F = \\{\\mathscr X, F_{\\theta} : \\theta \\in \\Theta\\} \\end{equation}\\] donde las variables \\(x_1,...,x_n\\) siguen cierta distribución \\(F_{\\theta}\\), la cual se indexa a un parámetro \\(\\theta\\) definido en el espacio de los parámetros \\(\\Theta\\). \\(\\mathscr F\\) es una familia de distribución de probabilidad, del conjunto completo de datos \\(\\mathscr X\\). Con las muestras que obtenemos de cada espacio aspiramos a tener una probabilidad \\(\\approx1\\) de identificar al grupo pobre. 2.1.2 Selección de indicadores y dimensiones La medición de la pobreza es un ejercicio de muestreo de diferentes espacios- conjunto de opciones. Por ejemplo, se ponen por delante algunas dimensiones, indicadores y pesos que se piensa provienen del espacio de pobreza. Esta selección es el primer reto en medición de pobreza donde los investigadores eligen las dimensiones \\(j\\) de \\(\\mathscr J\\), indicadores \\(x_{ij}\\) de \\(\\mathscr X\\), de manera que si la medida tiene 30 indicadores \\(\\mathscr X={1,2,...,30}\\) donde \\(x_{ij}=1\\) cuando hay privación y \\(x_{ij}=0\\) cuando no la hay (y \\(z&gt;0\\) para variables binarias). Para variables nominales, hay un espacio de umbrales posibles \\(\\mathscr Z\\). La selección de dimensiones, indicadores y umbrales implica asumir que el muestreo que hacemos es el mejor posible, es decir, es aquel que nos lleva a una buena medida de pobreza. Esto lleva a preguntarse lo siguiente: ¿Cómo sabe el investigador que su muestreo está equivocado? Esta interrogante pude separarse en dos preguntas: Es el subconjunto de dimensiones \\(j\\) de \\(\\mathscr J\\) una carecterización adecuada de pobreza? Es el subconjunto de indicadores, dado un umbral \\((X;z)\\) de \\(\\mathscr X\\) una caracterización adecuada de pobreza? La palabra adecuada es un término vago en este punto. Necesitamos una teoría clara o estándar para definirla. Esto se cubre en la siguiente sección, pero en este momento nos enfocaremos en traducir con mayor precisión los retos de la medición de pobreza en supuesto dentro de un modelo estadístico, que después pueda testearse de alguna manera. 2.1.3 Agregación de indicadores y estructura de pesos Los primeros supuestos se enfocan en la selección de indicadores y dimensiones. Como se discutirá más adelante, en esta etapa un marco falsable es muy útil pero extrañamente ha estado ausente en la investigación de pobreza. En la ruta crítica real de la medición de pobreza es común observar un salto de lis indicadores seleccionados a la agregación. El uso que normalmente se le da al método AF de agregación ilustra el problema de la falta de escrutinio. Una vez que se han seleccionado los indicadores y dimensiones, el método AF se utiliza para agregarlos. Este método producirá buenos resultados si los indicadores seleccionados resultan en una caracterización adecuada de pobreza. Sin embargo, no hay nada dentro del método AF que nos asegura que este es el caso. Esto no es una deficiencia del método, sino de la ausencia de un escrutinio empírico claro. En cambio, lo que tiende a pasar es que se asignan pesos \\(w \\in \\mathscr W\\), donde \\(w_{ij}=1\\) para medidas con pesos no diferenciales y \\(w_{ij}\\ne 1\\) para medidas con pesos diferenciales. Una vez asignados los pesos, se procede con la agregación La secuencia, un tanto extraña, de redacción del párrafo anterior es totalmente intencional. Uno de los problemas actuales en medición de pobreza es la sobre preocupación con los pesos y la despreocupación que hay por las propiedades de los indicadores y dimensiones que se incluyen en una medida. Por teoría de la medida (ver Capitulo 3), se sabe que los pesos diferenciales son solamente útiles cuando se tiene una medida que tiene mucho ruido puesto que ayudan a corregir los problemas de ordenamiento de la población. Evidentemente, lo que está perdido en esta etapa es el escrutinio del supuesto que levantamos sobre los pesos, llevando a la siguiente pregunta: Los pesos seleccionados llevan a ordenamientos consistentes de la población? Esta pregunta debe plantease en términos de ordenamiento porque, al final, lo que hacen los pesos es afectar el valor del score observado de privación y esta medida nos indica la severidad de privación de cada persona. Por tanto, nos gustaría saber si los pesos están o no afectando ese ordenamiento. Como veremos en el Capitulo 3 esto tiene que ver con el principio de confiabilidad de la teoría de la medición. 2.1.4 División de la población en los grupos pobre y no pobre La teoría fundamental de pobreza predice que cuando menos existen dos grupos de población: el grupo pobre y no pobre. En el Capítulo Capitulo 1 se discute el significado que se le da a este grupo. La expectativa que se tiene en medición es que una vez que hemos hecho el muestreo de dimensiones, indicadores, umbrales y pesos -y que tal selección es adecuada- se tenga un ordenamiento claro de la población de manera que podamos separarla usando algún criterio para fijar la línea de pobreza. Una vez que el modelo de pobreza se ha completado \\(\\mathscr F\\) y validado, la agregación produce un score de privación para cada persona en la muestra. En el Capitulo 1 discutimos las propuestas que existen para fijar la línea de pobreza, pero fundamentalmente estas alternativas buscan producir la mejor separación posible de la población de acuerdo a los dos grupos de interés. Desde el punto de vista estadístico esto significa que, en la mayoría de los casos, los investigadores no hacen más que levantar un supuesto de la mejor separación posible. Cómo saber que nuestro criterio de línea de pobreza es adecuado? En el Capitulo 8 se revisa este tema, pero en este punto el énfasis es sobre la necesidad de validar de alguna manera que empíricamente la línea de pobreza que se propone es consistente con la expectativa teórica. Con este tercer gran supuesto en medición multidimensional de pobreza, es posible entonces lanzar la siguiente pregunta decisiva: Qué marco nos permite definir si nuestras decisiones son adecuadas y qué significa o implica que lo sean? A continuación, revisaremos la relación que tienen todos estos supuestos con la teoría de la medida. 2.2 La teoría de la medida como marco estadístico para la medición 2.2.1 Pobreza y error en medición En el Capítulo se subrayó que la pobreza, al igual que otros conceptos en ciencias sociales, es una abstracción. El concepto de pobreza emerge de la idea de que existe un subgrupo de población que tiene un nivel de vida por debajo de lo que la sociedad, en un momento dado, considera como esencial o fundamental para vivir con dignidad. La pobreza, en teoría, impide la participación efectiva en la sociedad e incrementa el riesgo de morir joven, interactúa con varios riesgos sociales, etc. Pero la pobreza es difícil de medir porque no podemos observarla directamente y no podemos describirla con precisión absoluta con una variable. En cambio, la investigación de la pobreza tiene que confiar en datos imperfectos multivariados para ordenar a la población de acuerdo a su nivel de vida. Para hacer las cosas más complicadas, hay varias formas de hacer esta operación puesto que la gente utiliza distintos espacios de muestreo de dimensiones, indicadores, umbrales y pesos. El término estadístico de un concepto es variable latente. Las variables latentes son constructos que por teoría deberían tener una serie de manifestaciones en el mundo real3. En ciencias sociales trabajamos con variables latentes y pobreza es sólo otro caso en el que los investigadores trabajan con un grupo teóricamente construido (no directamente observable) (la gente con depresión, clase social alta, gente inteligente, gente feliz, etc.). Cómo podemos detectar a un grupo de población que proviene de un constructo? Spearman (1904) puso al frente una idea capital para la medición en ciencias sociales y que tiene que ver con el muestreo de distintos atributos para caracterizar un fenómeno. La teoría de Spearman (1904) señala que la correlación* que dos o más indicadores de resultado es un síntoma de que ambos probablemente son causados por el mismo fenómeno. Esta es una primera condición para causalidad. Esto ajusta perfectamente con la teoría que hemos manejado de pobreza Capítulo]: La pobreza es falta de recursos en el tiempo y la privación observada es su consecuencia. El supuesto básico en medición de pobreza es entonces que el conjunto de indicadores de privación (\\(X \\in \\mathscr X\\)) constituye una serie de manifestaciones relevantes/adecuadas de la variable latente pobreza. Este tipo de tratamiento del concepto de pobreza es poderoso porque permite vincular de manera natural la teoría de pobreza con su medición. Si juntamos a Spearman (1904) con una teoría de pobreza como la de Townsend (1979) tenemos que: Los indicadores de privación están correlacionados porque tienen la misma causa: pobreza. Desde el punto de vista conceptual esto significa que, si el efecto de la pobreza es eliminado, la correlación de las variables sería muy débil o incluso cero. Spearman (1904), padre de la teoría de la medida, postula entonces que el problema del conjunto relevante de indicadores de privación puede enmarcarse desde la perspectiva del modelo factorial común. Thurstone (1947), otro de los fundadores de la teoría contemporánea de la medición, propone que este modelo común postula que un indicador observado es función de un factor único, aunque también puede asociarse a otros factores anidados en ese gran factor, es decir, dimensiones. La postulación de Thurstone (1947) es fundamental en pobreza porque su idea del factor común resuelve un problema fundamental. En medición de pobreza se toman muestras de lo que pensamos es el espacio de medición ideal. Thurstone (1947) propone que puede haber varias medidas de pobreza que usan distintas muestras. No es un problema usar muestras distintas sino usar muestras del espacio relevante. La implicación es que uno puede tener \\(n\\) índices adecuados de pobreza, aunque sus contenidos sean distintos. Esto se debe a que cada privación observada tiene dos fuentes de variación: (1) varianza común y (2) varianza única. El primer tipo es la que determina el factor común. El segundo es la varianza dada por otros factores -que no son pobreza o sus dimensiones- o por error aleatorio. 2.3 Modelo latente de medición de pobreza Las raíces del marco de variables latentes se originan en Spearman (1904), Thurstone (1947) y otros (???). El modelo estadístico que se propone desde la teoría de la medida consiste en un modelo factorial común donde cada variables observadas (\\(x_{ij}\\)) es producto de una dimensión latente (\\(\\eta_j\\)) y de un factor de alto orden (\\(\\zeta_h\\)). Es decir, la pobreza multidimensional tiene una jerarquía, el factor de alto orden es pobreza y los factores anidados son las dimensiones. Uno de los aspectos interesantes de esta formulación es que reconoce explícitamente que no toda la variabilidad de los indicadores observados puede deberse a las variables latentes. Esto es, la teoría de la medida reconoce explícitamente que el error es parte de la medición y puede calcularse. \\[\\begin{equation} \\tag{2.2} x_{ij} = \\lambda_{ij} \\eta_j + \\varepsilon_ij \\end{equation}\\] \\[\\begin{equation} \\tag{2.3} \\eta_j = \\gamma_{j} \\zeta + \\xi \\end{equation}\\] En este caso \\(\\lambda_{ij}\\) y \\(\\gamma_{j}\\) se conocen como cargas factoriales y capturan la relación entre las variables latentes y los indicadores de resultado, y entre las dimensiones y pobreza, respectivamente. Por supuesto, es posible tener más \\(\\zeta\\)’s pero en investigación de pobreza el supuesto es que las dimensiones están anidadas en un factor general (algunos casos especiales se muestran en la Sección @ref() donde hay un modelo tiene tres niveles): Pobreza → Dimensiones → Sub-dimensiones → indicadores de resultado. Este modelo es una forma de capturar estadísticamente la forma en la que la medición multidimensional de la pobreza se lleva a cabo en la literatura contemporánea. Los investigadores proponen una serie de dimensiones y clasifican los indicadores que proponen de acuerdo con una estructura que puede esquematizarse en un modelo estadístico. El aspecto crucial es que dicha especificación es solo una idea =basada en teoría o datos- sobre cómo pobreza puede medirse mejor desde un punto de vista multidimensional. Esto es, la propuesta es un modelo por validar que demanda algún tipo de escrutinio empírico. Cuando lo ponemos en términos de una ecuación como (2.2) y (2.3), los investigadores se mueven de la especulación teórica hacia falsación empírica. 2.4 Esquemas y modelos de medición de pobreza Los modelos son sólo un esquema de un índice de pobreza que resumen cómo una escala puede construirse. Poner una propuesta teórica en términos de un diagrama ayuda a visualizar y contrastar los distintos planteamientos que se tienen para medir pobreza. La ventaja de la teoría de la medida es que todo puede ponerse en términos de un esquema. Los modelos multidimensionales pueden fácilmente presentarse como un diagrama o esquema, el cuál es una representación gráfica de un modelo. Otra forma de pensar al respecto, es ver a los diferentes esquemas de medición de pobreza como diversas maneras en las que un investigador hace muestrero de \\(\\mathscr J\\) y \\(\\mathscr X\\). Estos muestreos llevan a diferentes estructuras, es decir, modelos. La ecuación (2.2) simplemente resume un modelo en el que una variable latente produce distintos indicadores de resultados (\\(x_{ij}\\)). Este modelo es unidimensional porque sólo hay un factor \\(\\eta_j\\) como causa de las privaciones observadas. Podemos pensar en este modelo como el modelo nulo de medición de pobreza donde los indicadores no pueden ser claramente agrupados en dimensiones. Puede ser el caso de que los indicadores en cuestión midan diversos aspectos de pobreza pero que sean insuficientes para caracterizar a una dimensión. En la práctica, hay pocos modelos teóricos que proponen tal estructura. Empíricamente, sin embargo, es probable que tengamos una medida cuasi-unidimensional por las limitaciones en la recolección de datos y porque raramente ésta viene después de una propuesta teórica (Ver 1). La figure 2.3 traduce la ecuación (2.2) en el esquema de una medida unidimensional de pobreza. En la figura podemos ver que la variable latente se representa en círculos y las variables de manifiesto en cuadrados. Esta es la forma convencional de presentar modelos factoriales confirmatorios o, en términos más generales, ecuaciones estructurales. Las flechas apuntan de la variable latente a los indicadores porque se asume que el factor es el fenómeno que causa a las variables observadas. Finalmente, los parámetros que figuran a un lado de cada flecha corresponden a las cargas factoriales. Hemos hablado de que estos parámetros son fundamentales porque son una estimación de la variabilidad explicada por pobreza de cada indicador. Figure 2.3: Representación visual de un modelo unidimensional La Figura 2.4 muestra más variables latentes. En este caso el factor de alto orden tiene tres dimensiones (tres círculos). Este esquema es la propuesta de A Guio et al. (2009) de pobreza multidimensional y representa lo que generalmente tienen los investigadores en mente cuando piensan en una medida multidimensional. Es decir, un agrupamiento en el que los indicadores pertenecen a ciertas dimensiones y las dimensiones son producto del fenómeno pobreza. En este ejemplo, hay 9 indicadores de resultado clasificadas en tres dimensiones (\\(\\eta_j\\)) (Durables, Housing and Economic strain). Las cargas factoriales (\\(\\lambda_{ij}\\)) representan la relación de cada indicador con las dimensiones en cuestión. Las flechas del factor de alto orden (pobreza general/Overall Poverty) a cada dimensión son las cargas factoriales (\\(\\gamma_{j}\\)) que capturan la relación entre pobreza y cada dimensión. Ambos parámetros (\\(\\lambda_{ij}\\)) y (\\(\\gamma_{j}\\)) muestran la fuerza de la relación entre las variables latentes y los indicadores de resultado (Ver 3 sobre el vínculo entre las cargas factoriales, confiabilidad y pesos diferenciales). En este ejemplo hay sólo tres indicadores por dimensión y ninguno de los indicadores pertenece a más de una dimensión. Las medidas de pobreza asumen casi siempre exclusividad, es decir, que los indicadores son manifestaciones de una dimensión. Figure 2.4: Representación visual del modelo de Guio et al. (2009). Factor de segundo orden El modelo de Guio et al. (2009) es una de varias interpretaciones que hay sobre la estructura de una medida de pobreza. Alkire &amp; Santos (2010) proponen algo muy distinto para el cálculo de la medida multidimensional de PNUD-OPHI. La estructura es similar a la de Guio et al. (2009) en el sentido de que las dos son tienen un factor de alto orden- estructura de segundo orden. En este caso, se presume que la pobreza tiene tres dimensiones sustantivas: Educación salud y nivel de vida. Estas son diferentes dimensiones respecto a las que propone Guio et al. (2009) o Townsend (1979). La figura 2.5 muestra la propuesta de Alkire &amp; Santos (2010), sin embargo, este índice no tiene tres indicadores para cada dimensión. Tiene solamente dos para salud y educación. Esto tiene implicaciones negativas en dos sentidos. Primero, desde el punto de vista conceptual, es cuestionable pensar que una dimensión puede medirse con dos indicadores. Si pensamos que una dimensión es algo complejo, es bastante limitado pensar que bastan dos indicadores para capturar la dimensión educativa, por ejemplo. Segundo, desde el punto de vista estadístico, se trata de una medida que no está identificada porque tiene más parámetros que variables (grados de libertad negativos). Veremos que en modelación de variables latentes es necesario usar modelos identificados y que hay una conexión directa entre el argumento conceptual y el escrutinio empírico: una pobre especificación resultara en un mal modelo. Figure 2.5: Representación visual del modelo de Alkire &amp; Santos (2010)’s. Factor de segundo orden El modelo de Townsend (1979) fue el primer modelo teórico de medición multidimensional de pobreza en el mundo. Su propuesta tiene más dimensiones anidadas (por ejemplo ver 2.4 y 2.5, En este caso, los indicadores están agrupados en 11 dimensiones y cada una puede agruparse en dos grandes dominios: material y social. La Figura (2.6 muestra entonces un esquema factorial de tercer orden. Guio et al. (2017), por ejemplo, propone una versión reducida de este modelo, el cual no considera las 11 dimensiones y los indicadores se clasifican de acuerdo a privación material y social. Las cargas factoriales de los indicadores se omiten. \\(\\kappa_1\\) y \\(\\kappa_2\\) son las cargas factoriales del fenómeno pobreza, en este caso. Este modelo podría especificarse usando la ecuación (2.3) como referencia- ahora con \\(\\zeta\\) para dos factores. Figure 2.6: Representación visual del modelo de Townsend (1979)’s. Factor de tercer orden Otra forma de pensar sobre estos esquemas para la medición de pobreza es verlos como las diversas formas en la que los investigadores muestrean y agruman los espacios \\(\\mathscr J\\) y \\(\\mathscr X\\). Estos esquemas tienen la ventaja de son universales y cualquier medida de pobreza puede plantearse en un diagrama. Esto nos lleva de nuevo a la pregunta central del libro: Cómo sabemos si nuestras muestras de \\(\\mathscr J\\) y \\(\\mathscr X\\) son una representación adecuada de pobreza en una sociedad dada en un momento determinado del tiempo? 2.5 Principios de la teoría de la medida Hasta ahora el término adecuada se ha usado vagamente para referir a una situación en la que una medida de pobreza se comporta de manera robusta. La teoría de la medida es un marco de medición que precisamente da significado al término adecuado. Uno de los debates centrales en medición es sobre las dimensiones de pobreza. Esta discusión gira en torno a preguntas como: ¿Cuantas dimensiones hay? ¿Cuáles son los contenidos (indicadores) de cada dimensión? ¿Cómo se relacionan estas dimensiones y cómo se diferencian una de la otra? La sección previa tradujo estas cuestiones en retos concretos y avanzó un marco general de medición que explícitamente reconoce el error de medición. Sin embargo, el marco está incompleto y requiere algunos principios gobernantes que efectivamente nos lleven a un marco falsable de medición. Unas preguntas cruciales que se hicieron en la Sección son las siguientes: Es el subconjunto de dimensiones j de \\(\\mathscr J\\) una representación adecuada de pobreza? Es el subconjunto de indicadores, dado un umbral \\((X;z)\\), de \\(\\mathscr X\\) una representación adecuada de la dimensión \\(j\\) y pobreza? El esquema de pesos nos lleva a una agregación consistente de la población? 2.5.1 Orígenes de la teoría de la medida Medir consiste en asignar una serie de números a una población de manera tal que éstos representan ciertas cantidades y atributos (Nunnally &amp; Bernstein, 1994). La teoría de la medida es un marco que postula que una serie de variables de resultados son manifestaciones de un fenómeno latente dato. Esto es, un marco que convierte una serie de indicadores de privación en números para cuantificar el nivel latente de pobreza de cada persona. Por tanto, la teoría de la medida propone una serie de reglas para distinguir la señal del ruido y permitir que las variable de manifiesto sean una buena aproximación de la variable latente en cuestión. Los orígenes de la teoría de la medida tienen sus raíces en la teoría clásica del test (Lord, 1952; Novick, 1966). Esta teoría postula que el verdadero score es una función linear de una combinación de scores observados y error. La idea de que medimos con error es retomada dentro del marco de variables latentes a través de una serie de avances teóricos, conceptuales y computo (Cudeck &amp; MacCallum, 2012; Rusch, Lowry, Mair, &amp; Treiblmaier, 2017). La consolidación de este marco fue posible a desarrollos en otros campos de la medición como análisis factorial y teoría de respuesta al ítem (TRI). Después de la contribución seminal de Spearman (1904) y del trabajo para múltiples factores de Thurstone (1947), se realizaron una serie de trabajo en los sesentas que proponían formular análisis factorial no en términos de una matriz de correlación pero en términos de un modelo (Lawley &amp; Maxwell, 1971; Lazardfeld &amp; Henry, 1968). Posteriormente, y aparentemente de manera independiente al análisis factorial, en la medición educativa y psicometría, se propusieron una serie de trabajos por Stocking &amp; Lord (1983) y Bock &amp; Aitkin (1981) en los que se sentaron las bases de teoría de respuesta al ítem, la cual postula que la probabilidad de tener cierto score en un indicador dato (como privación o no privación) es producto de un factor latente (Reise, 2014). El nacimiento de TRI fue casi contemporáneo a las contribuciones de Jöreskog (1970) y Joreskog, Sorbom, &amp; Magidson (1979) sobre análisis factorial confirmatorio y ecuaciones estructurales. Estos modelos factoriales pueden ser como un caso general de TRI para variables categóricas (Muthén, 1984). El marco moderno de la teoría de la medida unifica varias de estas postulaciones (Cudeck &amp; MacCallum, 2012): Los indicadores son manifestaciones un fenómeno subyacente. Las manifestaciones pueden agruparse en ciertas subdimensiones -subcausas producen ciertas manifestaciones-. La medición siempre tendrá algún tipo de error sistemático y no sistemático. Es posible proponer un modelo bajo el cual el investigador puede examinar si sus supuestos se sostienen o no, dada la evidencia existente. La teoría de la medida, desde el trabajo de Spearman (1904) ha continuamente desarrollado un marco consistente que aspira a producir medidas que: Consistentemente ordenen a la población dado un grupo de indicadores. Es decir, que dadas ciertas medidas de privación podemos ordenar a la gente con muy bajo y bajo nivel de vida. Este ordenamiento debe tener relación con el fenómeno que aspira a medir. O sea, que las privaciones sean efectivamente manifestaciones de pobreza. Estos dos principios están detrás de dos de los conceptos más importantes en medición científica: Confiabilidad y Validez. Además, estos dos conceptos tienen importantes consecuencias para la asignación de pesos, comparabilidad e identificación de grupos de población, en este caso, el pobre y no pobre. Los siguientes capítulos del libro abordan estos conceptos con detalle. "],
["Chapter-3.html", "Capítulo 3 Confiabilidad en medición de pobreza 3.1 Explicación intuitiva del concepto de confiabilidad 3.2 Teoría de la confiabilidad 3.3 Estimadores de confiabilidad 3.4 Confiabilidad por ítem y pesos diferenciales 3.5 Confiabilidad de ítem: Pesos, discriminación y axiomas 3.6 Estimación de confiabilidad: Global y de ítem 3.7 Ejemplo con datos reales 3.8 Temas avananzados: Clasificación poblacional y pesos 3.9 Comentarios finales", " Capítulo 3 Confiabilidad en medición de pobreza Resumen Este capítulo introduce la teoría del concepto y principio estadístico de confiabilidad. Para introducir el tema, en la primera sección se plantean algunas nociones básicas para entender la importancia de la confiabilidad en medición y se subrayan las implicaciones de su (in)cumplimiento en la práctica. Después, se introduce formalmente la teoría de la confiabilidad. Desde el punto de vista aplicado, hay distintas formas de estimar el nivel de confiabilidad de una escala, el capítulo presenta y discute sus limitaciones y sus ventajas. A partir de la seccion 3.6 se ilustra cómo se implementan los análisis de confiabilidad usando R y Mplus usando datos simulados. Posteriormente, se utilizan datos reales para ilustrar algunos de los problemas que pueden surgir en la práctica cuando se hacen análisis de este tipo. El capítulo cierra con la presentación y discusión de temas avanzados de confiabilidad que son relevantes para la medición de pobreza. 3.1 Explicación intuitiva del concepto de confiabilidad ¿Cómo el principio de confiabilidad nos lleva a producir cifras de las que podemos fiarnos? Los analistas de la pobreza y los hacedores de política requieren creer en la evidencia que utilizan para poderse enfocar en el estudio y desarrollo de estrategias para la erradicación de la pobreza. No hay nada peor en medición que una escala que causa dudas puesto que el debate tiende a concentrarse en qué tan mala o inútil es la medida que utilizamos y no sobre qué tan buena o mala es la política en cuestión. La confianza se construye a partir de estimaciones que tienen sentido para quienes las utilizan y que son consistentes en diversas aplicaciones. Por ejemplo, consideremos el caso hipotético en el que podamos realizar dos encuestas con la misma población. Idealmente, lo que esperaríamos encontrar es que los patrones de respuesta no cambien de \\(t_1\\) a \\(t_2\\). Esto nos estaría diciendo que la información que utilizamos para nuestro índice es estable o invariante. Si usamos esa información para un índice de pobreza, lo que encontraríamos es que la clasificación de nuestra población sería la misma. Por el contrario, patrones de respuesta distintos entre \\(t_1\\) y \\(t_2\\) llevarían a clasificaciones inconsistentes y sería imposible distinguir la fuente de la variación en las cifras obtenidas. Es decir, no podríamos saber si nuestra medida de pobreza caputra buena parte de la señal en la que estamos interesados o si, en realidad, caputura mayormente ruido (todo aquello que no nos interesa). Si la fuente de variación de indicadores observados es distinta, estaremos capturando variabilidad que no nos interesa. Esto tiene una serie de implicaciones importantes porque la confiabilidad implicaría que la gente que tiene bajo nivel de vida -latente- debería siempre permanecer en la parte baja de la distribución ceteris paribus a lo largo de diferentes mediciones4. Otra consecuencia fundamental del principio de confiabilidad puede ilustrarse pensando en otro caso hipotético, aunque muy común, en el que perdemos o ganamos información. Es decir, dejamos fuera buenos indicadores e incluimos buenos indicadores. Imaginemos un mal indicador de pobreza como tener una bicicleta plegable o un indicador que se levantó mal en campo y la gente no entendió la pregunta. Esta variable tendrá baja correlación con el resto de los indicadores de privación. La teoría de Spearman (1904), fundamento del principio de confiabilidad, nos dice que el principio de confiabilidad nos empujaría a sospechar de este comportamiento. Esto se debe a que la baja correlación (o incluso negativa) sugiere que el indicador en cuestión no es una consecuencia del fenómeno en cuestión, i.e. pobreza (Falta de recursos en el tiempo 1). ¿Por qué? Bajo la teoría de Spearman -e incluso un razonamiento lógico sobre causalidad-, la correlación es una condición necesaria para causalidad. Si partimos de que los indicadores de privación deben ser causados por el mismo fenómeno (pobreza) deberíamos observar que están relacionados. ¿Cuál es entonces el efecto de indicadores con ruido sobre la confiabilidad? Primero, por indicador con ruido nos referimos a aquellos indicadores cuya variabilidad no tiene correspondencia con la variabilidad de los otros indicadores, i.e. bicicleta plegable guarda poca relación con indicadores de pobreza. Aunque es posible ignorar el consejo de Spearman sobre la búsqueda de correlación, esto no significa que las consecuencias negativas de un mal indicador van a desaparecer. Si incluimos un indicador que no guarda correlación con el resto (si nos quedamos con la bicicleta plegable para identificar pobreza) lo que va a ocurrir es que el ordenamiento de nuestra población va a ser condicional al ruido de este indicador. Es decir, va a depender de información -variabilidad- que no nos interesa. ¿Qué tan diferente va a ser el orden de la población con y sin este indicador? Dependerá de dos cosas: de que tan baja o negativa es la correlación de este indicador con el resto y de cuál es la correlación del resto de los indicadores como grupo, i.e. la matriz de correlación del resto. Este segundo punto es de fundamental importancia. La razón es que, si partimos de que correlación es fundamental para causalidad, la correlación de cada indicador con el resto nos da una estimación de que tan homogénea es la escala. Para entender el significado de homogeneidad -no confundir con unidimensionalidad- podemos pensar en otro caso. Si tenemos una medida con muy buenos indicadores, una preocupación perder información importante si omitimos un indicador. Este escenario parece un poco ingenuo. Sin embargo, si lo pensamos dos veces nos daremos cuenta de que todo el tiempo perdemos información. En el segundo capítulo mencionamos que trabajos con muestras de los conjuntos relevantes -dimensiones, indicadores y pesos-. Por tanto, siempre omitiremos algún tipo de información. Imagine el caso de que no incluimos un indicador razonable como: carencia de agua dentro de la vivienda (asumiendo que este es un país en desarrollo donde probablemente este indicador funcione para medir pobreza). Si no incluimos este indicador, haríamos la señal más débil. Dado que este es un problema común, quisiéramos tener cierta protección respecto a las pérdidas de información. Es decir, tener un índice que es menos sensible a la pérdida de variables. Confiabilidad precisamente aspira a tal tipo de escala. Esto es, a ponernos en una posición en la que obtengamos medidas que podemos confiar. Alta confiabilidad/homogeneidad es una propiedad que, de hecho, garantiza que un índice sea sensible a pérdidas de señal. Intuitivamente, esto significa que si tenemos indicadores altamente correlacionados entre sí tendremos una medida con mucha información, es decir, con señal suficiente para darnos el lujo de tener pérdidas. La información es intercambiable con buenos indicadores. El ordenamiento de la población se mantiene bajo alta confiabilidad. El resto del capítulo es sobre las bases y el cálculo de la homogeneidad de una escala. Veremos que la confiabilidad se preocupa principalente por discernir la parte de la variación de los indicadores que se debe a ruido o error aleatorio. De manera tal que si nuestra medida tiene mucho ruido aleatorio, los valores de carencia o privación resultantes de un índice son no confiables. La estimación del tamaño del ruido es un tema central en el análisis de confiabilidad y dedicaremos varias secciones al cálculo en R y Mplus. 3.2 Teoría de la confiabilidad Confiabilidad es un concepto central de la teoría de la medición y puede simplemente definirse como la homogeneidad de un índice (Revelle &amp; Zinbarg, 2009). Un índice homogéneo es una escala cuyos indicadores son manifestaciones del mismo fenómeno. La teoría de Spearman (1904) es fundamental para entender el principio de confiabilidad. Su proposición original fue que una condición necesaria en medición multivariada es que los indicadores estén correlacionados puesto que tienen una causa común5. En la literatura, varios autores se refieren a la confiabilidad como la consistencia interna ¿De qué manera consistencia y homogeneidad están relacionadas? En el ejemplo de la introducción mencionamos que un indicador que no es una buena medida de pobreza tiene poca, nula o correlación negativa con el resto de indicadores. Esto fundamentalmente significa que el indicador es causado por otro fenómeno. Si incluimos indicadores que provienen de distintos fenómenos tendríamos una medida heterogénea -no confundir con multidimensional-. La consecuencia de heterogenidad es que el ordenamiento de la población no va a ser consistente -va a cambiar bastante dependiendo de si dejamos o no el indicador que produce heterogeneidad-. De ahí la relación entre heterogeneidad e inconsistencia. Por tanto, en el corazón del principio de confiabilidad se encuentra la idea de que tener una serie de indicadores con un comportamiento predecible cuando se agregan, i.e. si un índice es confiable deberíamos esperar tener ordenamientos similares en diferentes muestras y con distintos subconjuntos de indicadores -confiables-6. La historia de la teoría del concepto de confiabilidad está inextricablemente conectada con el nacimiento y evolución de la teoría de la medición en ciencias. El origen de la teoría de la confiabilidad puede rastrearse a Spearman (1904), quien propuso el concepto de atenuación (ver abajo) y los fundamentos de la teoría clásica del test. A partir de entonces la teoría de la confiabilidad ha estado en constante desarrollo, principalmente gracias a los avances de modelación de variables latentes. El principio de confiabilidad tiene sus raíces en el reconocimiento explícito de que todas las medidas tienen una mezcla de señal (la variabilidad que nos interesa) y el ruido (variabilidad que no es deseable porque no es de nuestro interés). Spearman (1904) formalizó el tratamiento del ruido en medición al proponer que todo valor perfecto/verdadero (score verdadero) en el mundo real tiene una equivalencia que comprende el score observado y el error (Ver (3.1)). Esta diferencia es lo que llevó a Spearman a proponer el concepto de atenuación. Para él, debería ser posible evaluar qué tanto la asociación entre el score verdadero y el observado se atenúa por el ruido. Esto tiene una analogía en la estadística clásica (de frecuencia). El score verdadero, como el valor de la media poblacional, lo es en el sentido de que hay un valor esperado después de varias replicaciones del mejor experimento posible. Es decir, no se plantea que es verdadero porque la naturaleza así lo demanda sino es el valor esperado después de varias replicaciones. La relación entre observación, error y valor verdadero puede formalizarse de la siguiente manera. Si planteamos que \\(\\theta\\) es el valor verdadero, en la teoría clásica del test se propone que: \\[\\begin{equation} \\tag{3.1} x = \\theta + \\varepsilon \\end{equation}\\] Con varianzas se define como: \\[\\begin{equation} \\tag{3.1} \\sigma^{2}_{x} = \\sigma^{2}_{\\theta + \\varepsilon} \\end{equation}\\] Definimos al ruido como toda la variabilidad que no nos interesa. Esto significa que si observamos un score (por ejemplo, la privación por agua entubada dentro de la vivienda) idealmente esperaríamos que el 100% de quien tiene privación estuviera en esa situación por falta de recursos en el tiempo. Esto significaría que la variación se explica perfectamente por pobreza. Intuitivamente esto nos dice que si los cambios no se explican por pobreza podríamos afirmar que los cambios de estado de privación a no privación tienen que ver con otro fenómeno. Así, la variabilidad es clave para estimar la confiabilidad y de hecho la confiabilidad puede planearse en términos de descomposición de varianza ((3.1)), i.e. la razón que nos dice qué proporción de la variabilidad se debe a la señal y que tanto se debe al ruido. La teoría clásica del test asume que los errores ocurren aleatoriamente, i.e. misma probabilidad de que el error infle o desinfle el valor observado. Esto significa que el error es independiente de pobreza, por ejemplo. Este supuesto, es similar al que se hace en estadística o econometría, el promedio del error es igual a cero y los errores no están correlacionados con el valor verdadero. En el ideal, lo que nos interesa es tener medidas de pobreza cuya variación se deba a pobreza y no a otra cosa. Si la variación de las privaciones se debe a puro ruido, tendermos poco qué decir sobre la relación entre la variación real o verdadera y la variación observada. Así, en la teoría clásica del test la relación entre la varianza observada y la verdadera es fundamental. Se propone entonces que la varianza del score observado “x” \\(\\sigma^{2}_{x}\\) es entonces igual a la varianza del score verdadero más la varianza del error. La discrepancia entre el score verdadero y el observado es un estimado de la confiabilidad (veremos que hay varias aproximaciones puntuales para este cálculo): \\[\\begin{equation} \\tag{3.2} \\rho^{2}_{\\theta x} = \\frac{\\sigma^{2}_{\\theta}} {\\sigma^{2}_{x}} \\end{equation}\\] En este caso \\(\\rho\\) es la confiabilidad total, \\(\\sigma^{2}_{x}\\) es la variabilidad observada y \\(\\sigma^{2}_{\\theta}\\) la variabilidad del score verdadero. Dado que esto es una simple proporción, el valor estimado de la confiabilidad oscilará entre 0 y 17. Para aquellos lectores interesados en el tratamiento formal, se recomienda ampliamente el texto de William Revelle en línea: knitr::include_url(https://personality-project.org/revelle/publications/reliability-final.pdf). La ecuación (3.2) es útil para formalizar la definición de confiabilidad pero bajo una segunda lectura podemos pensar que tiene algo sospechoso. Si quisiéramos usar esta ecuación para estimar confiabilidad no sabríamos por dónde empezar. El problema fundamental es que no conocemos los valores verdaderos y, por tanto, no podemos calcular \\(\\sigma^{2}_{\\theta}\\). No solo eso, sino que no es claro qué valores podría asumir ¿Cómo solucionar este problema? Spearman (1904) propuso un método para aproximar el cálculo de \\(\\rho\\). Lo que él estableció fue una forma indirecta de resolver el problema. Él asumió que uno puede aproximar los parámetros de esta ecuación artificialmente (x y x’). La idea detrás de su cálculo es el siguiente: Para saber el valor verdadero de una correlación necesitamos el valor real o, por lo menos, muchos experimentos ¿Qué tal y si asumo que dos indicadores son expresiones del constructo que quiero medir? Esto significa que si las dos x’s tienen los mismos valores verdaderos en común, pero con errores independientes y varianzas iguales, entonces la correlación de estos es un estimador directo de \\(\\sigma^2_\\theta\\) Es decir: \\[\\begin{equation} \\tag{3.3} \\sigma^{2}_{e} = \\sigma^{2}_{e&#39;} \\end{equation}\\] Entonces: \\[\\begin{equation} \\tag{3.4} r_{xx´} = \\frac{\\sigma_{\\theta x}\\sigma_{\\theta x&#39;}} {\\sigma_x \\sigma_x&#39;} = \\frac {\\sigma^2_{\\theta x}} {\\sigma_x \\sigma_x&#39;} \\end{equation}\\] Como x y x’ son medidas del mismo valor verdadero, entonces sus varianzas de error son iguales. La correlación de estos tests paralelos es igual a la correlación del score verdadero con el valor observado: \\[\\begin{equation} \\tag{3.4} r_{xx´} = \\frac {\\sigma^2_{\\theta x}} {\\sigma^2_x} = \\frac {\\sigma^2_{\\theta}} {\\sigma^2_x} = \\rho^2_{x\\theta} \\end{equation}\\] Confiabilidad, bajo el enfoque de Spearman (1904), entonces es la correlación de dos tests paralelos (o medidas del mismo constructo) correjidas por atenuación de los errores. También se define como la correlación entre el verdadero score elevado al cuadrado (esto porque es igual a la razón de la varianza del error sobre la observada). ¿Es satisfactoria la solución vía tests paralelos? El problema con esta estrategia es que en el fondo estamos asumiendo que: Los valores verdaderos de x y x’ son iguales (esto se conoce como equivalencia de \\(\\tau\\). Volveremos a este punto cuando hablemos de variables latentes) Las varianzas del error de x y x’ son iguales. Estos supuestos son muy fuertes y deberíamos pensar que raramente se sostienen en la práctica. Sin embargo, son útiles para formalizar y contextualizar los desarrollos más recientes en la teoría de confiabilidad. Es decir, esta definición clásica de la confiabilidad se ha modernizado por parte del tratamiento moderno de la teoría de la medida: enfoque de variables latentes (Kvalheim, 2012; Raykov, Dimitrov, &amp; Asparouhov, 2010; Rusch et al., 2017; Skrondal &amp; Rabe-Hesketh, 2007). Aunque ha cambiado el cálculo y tratamiento formal de la confiabilidad, hay varios aspectos en común entre la teoría clásica y el enfoque moderno de medición (Petrillo, Cano, McLeod, &amp; Coon, 2015; Raykov et al., 2010; Rusch et al., 2017). El enfoque de variables latentes no se preocupa mucho por usar la idea del score verdadero -aunque puede estimarse- sino parte del grado en el que los indicadores reflejan el constructo en cuestión. Esto es un reconocimiento explícito a que en las ciencias sociales trabajamos con datos discretos y no es necesario asumir aproximaciones continuas, i.e. altísima precisión en medición (Raykov et al., 2010). La pregunta entonces es ¿Cómo se enmarca el concepto de confiabilidad en el marco de variables latentes? Un aspecto central entre la teoría clásica del test y el enfoque de variables latentes es que ambos marcos asumen que los indicadores observados con realizaciones de un fenómeno subyacente, i.e. su causa es el fenómeno. Una diferencia importante es que el enfoque de variables latentes no utiliza la idea del valor verdadero. En realidad, este marco parte de que los indicadores observados tienen como causa un factor congénere (compartido). Esta pequeña diferencia es fundamental porque entonces el supuesto clave es que los indicadores son medidas imperfectas del factor subyacente. Esto nos lleva a plantear la confiabilidad desde la perspectiva de los modelos de pobreza que enseñamos en el Capítulo 2 con las ecuaciones (2.2) and (2.3). \\[\\begin{equation} x_{ij} = \\lambda_{ij} \\eta_j + \\varepsilon_ij \\end{equation}\\] \\[\\begin{equation} \\eta_j = \\gamma_{j} \\zeta + \\xi \\end{equation}\\] De acuerdo con nuestro modelo multidimensional \\(\\lambda_{ij}\\) representan la relación (imperfecta) de cada indicador con el factor, i.e. su causa común. Como puede observarse, _ij son los errores de cada indicador. Es decir, en nuestro modelo convertimos a los errores un parámetro y no lo dejamos como supuesto. Esta es otra de las grandes ventajas respecto a la teoría clásica del test. A continuación, formulamos una equivalencia entre la confiabilidad de la teoría clásica del test y el enfoque de variables latentes. En este caso utilizaremos la expresión de un modelo unidimensional. \\[\\begin{equation} \\tag{3.5} \\rho_{x_{i}\\theta} = \\frac{\\lambda^2_{i}} {\\sigma^{2}_{xi}} \\end{equation}\\] Las cargas factoriales \\(\\lambda_i\\)’s (aquí las i’s son los indicadores o ítems que usamos en el test x, como en la teoría clásica del test) son clave puesto que reflejan la asociación entre el indicador observado y el constructo/factor (esto veremos es la varianza de nuestro indicador que explica la causa común). Por tanto, el enfoque de variables latentes naturalmente encaja el concepto de variabilidad observada. Si el factor explica en mayor medida la variabilidad del indicador observado -i.e. en la medida en la que la privación sea resultado de pobreza- el error será menor y el indicador tendrá una contribución mayor a la confiabilidad total. El uso de está ´potente infraestructura estadística permite que el enfoque de variables latentes vaya más allá de las capacidades de la teoría del test clásico. Este es un punto importante porque ilustra el poder que tiene usar modelos (en el sentido teórico y empírico) en la inspección de nuestras medidas de pobreza. La modelación de variables latentes es mucho más potente y flexible que la teoría del test clásico. Incluso, algunas extensiones permiten caminar hacia relaciones no lineales (teoría de respuesta al ítem); es posible estimar el valor del factor; los parámetros son menos sensibles al tamaño de muestra; los indicadores se seleccionan conforme a un modelo deseable; parámetros clave como \\(\\sigma^{2}_{x}\\) and \\(\\sigma^{2}_{e}\\) pueden estimarse y no suponerse (Raykov et al., 2010; Rusch et al., 2017). 3.3 Estimadores de confiabilidad Hay diferentes formas de estimar la confiabilidad de una escala, cada una con sus ventajas y desventajas. Estos estimadores lo que buscan es formular un procedimiento aplicable de cálculo de confiabilidad. Como discutíamos en la sección anterior, en problema en la teoría clásica del test es que el valor verdadero no se conoce y, por tanto, fue necesario proponer algún tipo de aproximación al cómputo de confiabilidad. 3.3.1 Estimadores: teoría clásica del test El estimador más famoso de confiabilidad es \\(\\alpha\\) o también conocido como \\(\\lambda_3\\) (Guttman, 1945) (no confundir con cargas factoriales) (Cronbach, 1951; Guttman, 1945). Este estimador tiene sus raíces en la TCT y se basa en la propuesta de Spearman (1904) para estimar la varianza observada a partir del supuesto de tests paralelos y, más importantemente, en la idea de que corregir el valor de una correlación por atenuación llevaría al mejor estimado de confiabilidad. Es decir ¿Qué tan parecidas son las correlaciones observadas a las correlaciones verdaderas? ¿Cómo está relación se atenúa por el ruido? La propuesta de Spearman es bastante astuta porque permite estimar confiabilidad usando una sola medición (i.e. no requiere varias repeticiones para comparar resultados entre distintos ejercicios) e incluir una estimación del efecto del error sobre las correlaciones entre ítems. Idealmente, nos gustaría tener mediciones repetidas para la misma muestra porque de esta manera podríamos comparar si los resultados de nuestro ejercicio de medición cambian a fin de tener una idea de que tan inestables son los resultados de nuestro instrumento. Además, nos gustaría contar con una aproximación a la varianza verdadera \\(\\sigma^{2}_{\\theta}\\) haciendo uso de la información disponible, en este caso la varianza observada \\(\\sigma^{2}_{x}\\). Partiendo de Spearman (1904) y de la propuesta de Kuder &amp; Richardson (1937), Guttman (1945) (variables continuas) y Cronbach (1951) (variables categóricas) propusieron la siguiente forma general, en versión moderna, para calcular confiabilidad: \\[\\begin{equation} \\tag{3.6} \\alpha = \\lambda_3 = \\frac{\\sigma^{2}_{x} - \\sum\\sigma^{2}_{xi}} {\\sigma^{2}_{x}} \\frac{n} {n-1} \\end{equation}\\] O en la formulación original: \\[\\begin{equation} \\tag{3.7} \\alpha = \\frac{k^2 \\bar{\\sigma_{ij}}} {\\sigma^{2}_{X}} \\end{equation}\\] Donde \\(k^2\\) es el número total de ítems y \\(\\sigma^{2}_{X}\\) es la varianza total de la escala en cuestión. El coeficiente \\(\\alpha\\) puede utilizarse para ítems binarios, ordinales o continuos (con \\(\\lambda_3\\)). La ecuación (3.6) esconde varios supuestos (Kuder &amp; Richardson, 1937). Parte de que la covarianza promedio entre ítems es un estimador de la varianza de cada ítem (\\(\\sigma^{2}_{ei} = \\sigma^{2}_{xi} - \\bar\\sigma^{2}_{ij}\\). Por tanto, la varianza del error de cada ítem \\(\\sigma^{2}_{ei}\\) es simplemente la diferencia de la varianza del ítem menos la covarianza promedio. El \\(\\alpha\\) de Cronbach es, sin embargo, un estimador de confiabilidad bastante limitado (Revelle &amp; Zinbarg, 2009; Zinbarg, Revelle, Yovel, &amp; Li, 2005). Primero, \\(\\alpha\\) y \\(\\lambda_3\\) son función del número de ítems de una escala, i.e. más ítems eventualmente producen estiman alta confiabilidad. Segundo, es función de la correlación entre ítems. Entonces al añadir algunos ítems que correlacionen alto es posible manipular estos estimadores. Tercero, este estimador funciona bien bajo supuestos bastante restrictivos: la asociación entre cada indicador y la variable latente es igual. Por ejemplo, una medida con tres indicadores asume que las cargas factoriales son \\(\\lambda_1=\\lambda_2=\\lambda_3\\); y asume que las varianzas de los indicadores son iguales. Estos supuestos son más endebles cuando se trata de medidas multidimensionales porque la relación de los indicadores está mediada por el número de dimensiones. Por ejemplo, falta de agua y saneamiento probablemente tengan la misma relación con la dimensión de acceso a servicios básicos pero probablemente no tengan la misma relación con pobreza. Estos dos supuestos son, sin embargo, necesarios porque de otra manera no podríamos estimar \\(\\sigma^{2}_{\\theta}\\) y \\(\\sigma^{2}_{x}\\). El problema es que estos supuestos raramente se sostienen en la práctica (La tabla ?? resume la relación entre distintos estimadores de confiabilidad y dimensionalidad). Dado que \\(\\alpha\\) o \\(\\lambda_3\\) se basan en supuestos que difícilmente se sostienen, hay distintas propuestas para estimar confiabilidad bajo condiciones más generales. Revelle (1979) propone el estadístico \\(\\beta\\). Este coeficiente, más que se un sustituto de \\(\\alpha\\), es una medida que informa sobre qué tan baja es la confiabilidad de una escala. Es decir, nos da una estimación pesimista de confiabilidad. Decimos baja definida a partir de la heterogeneidad de la escala en cuestión, i.e. examina el efecto que tiene el indicador con la correlación más baja sobre la confiabilidad. Formalmente, \\(\\beta\\) considera la peor correlación entre dos mitades. Es decir, minimiza la covarianza promedio a partir de la correlación entre ítems más baja (\\(\\bar{\\sigma_{ij}}\\)). Por tanto, \\(\\beta\\) es una medida del más bajo nivel de confiabilidad partiendo de que nuestra preocupación principal es qué tan heterogénea es nuestra escala en el límite. Siempre, por tanto, \\(\\beta &lt; \\alpha\\). Se estima de la siguiente manera: \\[\\begin{equation} \\tag{3.8} \\beta = \\frac{k^2 \\bar{\\sigma_{ij}}} {\\sigma^{2}_{X}} \\end{equation}\\] Donde en la ecuación (3.8), {{ij}} es la covarianza de los ítems (de distintas particiones) considerando la combinación más baja de ítems, \\(k^2\\) es el número de ítems al cuadrado. Esta expresión es similar a la que propone Cronbach pero {{ij}} es distinto, i.e. es el que minimiza la covarianza. Como bien afirma Cronbach (1951) [H]igh or low coefficient depends on whether the high interitem covariances are place in the between halves covariance (p. 304). Computacionalmente, lo que hace que hace \\(\\beta\\) es lo siguiente: Estima la matriz de correlaciones, combina los dos ítems más similares en un ítem compuesto, encuentra la correlación de este nuevo ítem con el resto, repite estos pasos hasta que encuentra la correlación más baja. 3.3.2 Estimadores: variables latentes Una de las ventajas del marco de variables latentes es que directamente trabaja con parámetros para la estimación de confiabilidad. McDonald (1999) propuso dos medidas alternativas de confiabilidad: \\(\\omega\\) y \\(\\omega_h\\). Estos estadísticos pueden enmarcarse mejor dentro del marco de variables latentes porque se estiman a partir de análisis factorial -preferentemente análisis confirmatorio (Brown (2006)), ver sección 3.6-. Ambos estimadores se basan en la idea expresada en la ecuación (3.3), i.e. la varianza de un indicador depende de su relación con el factor y la suma de éstas relaciones para todos los indicadores de la escala. El primer estadístico, (\\(\\omega\\)) también se conoce como la medida que maximiza la estimación de confiabilidad, i.e. se conoce como el estimador del techo de confiabilidad (Zinbarg et al., 2005). La ecuación (3.9) muestra la fórmula de cálculo de \\(\\omega\\). Esta ecuación representa la proporción de la varianza que explica el factor. En otras palabras, si tenemos varios buenos indicadores de privación que son causados por pobreza, esperaríamos que el error sea bajo y que las cargas factoriales de cada indicador sean altas. Consecuentemente, \\(\\omega\\) será muy alto, i.e. con valores próximos a 1, que es su valor máximo. \\[\\begin{equation} \\tag{3.9} \\omega = \\frac{ \\sum\\limits_{j=1}^k \\bigg(\\sum\\limits_{i=1}^p \\lambda_{ij}\\bigg)^2 } {\\sum\\limits_{j=1}^k \\bigg(\\sum\\limits_{i=1}^p \\lambda_{ij}\\bigg)^2 + \\sum\\limits_{i=1}^p e_i} \\end{equation}\\] El estadístico \\(\\omega\\) está pensado en calcular el porcentaje de la varianza explicado por el factor general. Sin embargo, no se preocupa por la existencia de dimensiones. En medición de la pobreza, esto no es ideal porque, aunque nos gustaría saber la confiabilidad total, nos interesa saber cuál es la confiabilidad cuando se consideran las dimensiones. Esto se debe a que en medición multidimensional pensamos que existe un factor general con distintos factores anidados (dimensiones de la pobreza). Entonces, existen por lo menos dos tipos de relación: 1) La relación de cada indicador con el factor general (pobreza), y (2) la relación de cada indicador con su respectiva dimensión. De hecho, esto es más complicado que parece, porque la primera relación puede descomponerse y plantearse en términos de la relación del factor general con cada dimensión. La respuesta al problema de dimensiones anidadas para el computo de confiabilidad es \\(\\omega_h\\). La ecuación (3.10) muestra la fórmula para estimar este estadístico. Se trata de una versión jerárquica de \\(\\omega\\) en el sentido de que apunta a estimar los dos tipos de relación mencionados arriba: la varianza de los indicadores que se explica por ambos el factor genera y las dimensiones. La mejor manera de estimar \\(\\omega_h\\) es a partir de la transformación Schmid &amp; Leiman (1957) (ver por ejemplo (Wolff &amp; Preising, 2005) and sección (3.6). Esta transformación es un procedimiento relativamente simple que transforma un modelo factorial jerárquico en un modelo en el que las cargas factoriales de los indicadores se estiman considerando por separado el factor general y las dimensiones. Esto tiene mucho sentido desde la perspectiva de que nos interesa tanto la relación del indicador con pobreza como su relación con alguna dimensión como vivienda digna, por ejemplo. \\[\\begin{equation} \\tag{3.10} \\omega_h = \\frac{ \\bigg(\\sum\\limits_{i=1}^p \\lambda_{ij}\\bigg) ^2 } {\\sum\\limits_{j=1}^k \\bigg(\\sum\\limits_{i=1}^p \\lambda_{ij}\\bigg) ^2 + \\sum\\limits_{i=1}^p e_i} \\end{equation}\\] 3.3.3 Criterios de uso: Estimadores de confiabilidad La existencia de distintos estimadores de confiabilidad abre la pregunta siguiente ¿Cuál debemos usar? Hay dos formas complementarias de responder a esta pregunta. Primero, estas medidas de confiabilidad están basadas en supuesto y su uso depende del grado en el que cada supuesto es adecuado para los datos que utilizamos. \\(\\alpha\\) es un caso muy específico y sus supuestos raramente se cumplirán en la práctica. La recomendación general es evitar utilizar \\(\\alpha\\) y enfocarse en el cálculo de \\(\\omega\\) y \\(\\omega_h\\). \\(\\omega\\) casi siempre funcionará, el único cuidado que debemos tener es utilizar estimadores complementarios cuando la medida es multidimensional. En tal situación, \\(\\omega_h\\) es una medida más adecuada porque siempre nos dirá la varianza debida al factor de alto orden menos la varianza que explican las dimensiones. Zinbarg et al. (2005) realizaron un estudio de Monte Carlo para examinar cómo los distintos indicadores de confiabilidad se comparan entre sí. Estos autores encontraron lo siguiente (ver Tabla 3.1): Table 3.1: Resumen de relación de \\(\\beta\\), \\(\\alpha\\), \\(\\omega\\) y confiabilidad dependiendo de la dimensionalidad del índice. Tomado de (Zinbarg et al., 2005, p. 128) Dimensionality Expected behaviour Multidimensional \\(\\beta&lt;\\alpha&lt;\\omega\\leq\\rho\\) \\(\\omega_h&lt;\\omega\\leq\\rho\\) Unidimensional \\(\\beta&lt;\\alpha&lt;\\omega_h=\\omega\\leq\\rho\\) La segunda manera de contestar a la pregunta de cuándo usar cada estimador tiene que ver con las conclusiones que podemos sacar de cada medida de confiabilidad. Es decir, si los supuestos de violan nuestras conclusiones se verían afectadas. Ahora bien, asumiendo que elegimos el indicador adecuadamente, una pregunta adicional sobre estos estadísticos es ¿Qué valor de confiabilidad es inaceptable? Una de las consecuencias de confiabilidad es que esta propiedad garantiza un ordenamiento adecuado de nuestra población, i.e. de bajo nivel de vida a alto nivel de vida. Nájera (2018) realizó un experimento de Monte Carlo para examinar la relación entre confiabilidad y la clasificación de la población. Este estudio plantea la pregunta sobre el nivel de confiabilidad que garantiza bajo nivel de error. El resultado de este estudio es que hay una relación clara entre confiabilidad y clasificación de la población. El resumen de los resultados de Nájera (2018) se muestra en la Tabla 3.2. La simulación consideró tres posibles estructuras dimensionales: unidimensional, dimensionalidad débil y fuerte. La dimensionalidad débil se definió como el caso en el que las dimensiones tienen relativamente bajas cargas factoriales respecto al factor general. Table 3.2: Resumen de la relación de \\(\\beta\\), \\(\\alpha\\), \\(\\omega\\) y entropía dependiendo de la dimensionalidad del índice. Tomado de Nájera (2018). En este caso, el modelo unidimensional parece cumplir equivalencia de \\(\\tau\\), i.e. cargas factoriales iguales. Estimador de Confiabilidad Lleva a Erro de clasificación (%) Entropía \\(\\alpha&gt;.8\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) \\(\\omega&gt;.8\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) \\(\\omega&gt;.85\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) \\(\\omega_h&gt;.65\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) \\(\\omega&gt;.85\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) \\(\\omega_h&gt;.70\\) \\(\\approx\\) \\(&lt;5\\%\\) \\(&gt;.8\\) 3.4 Confiabilidad por ítem y pesos diferenciales La teoría clásica del test se preocupa por estimar la confiabilidad total de los scores. Asimismo, los estadísticos \\(omega\\) y \\(omega_h\\) son medidas de confiabilidad global Pero ¿Qué hay del aporte de cada indicador a la confiabilidad de los scores? En otras palabras ¿Cuál es la contribución puntual del indicador a la confiabilidad total? La teoría de respuesta al ítem (TRI) se apartó de la idea del valor verdadero y se enfoca en la relación que tiene cada indicador con el fenómeno subyacente (e.g. inteligencia, depresión o pobreza) (Harris, 1989, p. Reise2014). La TRI es una teoría que encaja en el marco unificado de variables latentes porque igualmente busca estimar cierto tipo de relaciones con un constructo. En su origen, la TRI se desarrolló pensando en medidas unidimensionales (i.e. los indicadores son manifestaciones de un sólo fenómeno) y se ha extendido a mediciones multidimensionales -como veremos la diferencia no es tan relevante- [Reise2014]. La relación que busca estimar la TRI es el tipo de información que cada indicador nos brinda sobre el factor. En el modelo más básico la TRI se enfoca en la severidad (dificultad) de cada ítem. Por ejemplo, estima si tener piso de tierra y carecer de agua entubada son manifestaciones igualmente severas de pobreza. Este tipo de modelo se conoce como TRI de un parámetro. Los modelos TRI pueden ser más complicados que eso. Una pregunta importante en medición de pobreza es ¿Qué indicadores son mejores para distinguir quién es pobre de quién no lo es? Los modelos TRI pueden incorporar un segundo parámetro llamado discriminación. Este parámetro nos estima la probabilidad de que una persona sea identificada como pobre dado que observamos privación en cierto indicador. Este modelo se conoce como IRT de dos parámetros. Este tipo de modelo es el que se ha utilizado en trabajos recientes en medición de pobreza como Guio et al. (2016) and Guio et al. (2017), por ejemplo. El modelo general de la teoría de respuesta al ítem de dos parámetros es el siguiente (Ecuación \\tag{3.11}): \\[\\begin{equation} \\tag{3.11} P_i\\theta = \\frac{1} {1+e^{-1.7a_i(\\theta-b_i)}} \\end{equation}\\] La ecuación (3.11), traducida a la medición de pobreza, establece que la probabilidad de observar que alguien tiene privación en el indicador \\(i\\) está dada por la discriminación (a) y la severidad (b) del indicador en cuestión para el nivel de pobreza la persona observada. Pensemos en un indicador confiable y uno no confiable para un país en desarrollo: Agua entubada dentro de la vivienda y bicicleta plegable, respectivamente. El primer indicador debería tener alta discriminación y tener severidad positiva. El segundo, baja discriminación y severidad probablemente negativa. ¿Por qué? Si pensamos en los datos, el patrón de respuesta de la gente con privación múltiple nos va a indicar que efectivamente privación múltiple se asocia con el indicador de agua y no mucho con el de bicicleta plegable. Esto llevará una alta discriminación. Como estamos en pobreza el foco es en los niveles bajos de vida, la severidad -por la métrica del factor- será positiva. Esperaríamos que, si nuestra teoría tiene sentido, que la baja proporción de gente con bicicletas plegables se deba a que es un lujo y no un bien necesario para vivir dignamente. ¿Hay alguna relación entre TRI y análisis factorial? Sí, Muthén (2013) muestra cómo estos dos modelos se relacionan, las ecuaciones 21 and 22 de su texto. Intuitivamente, esta relación se debe a que la severidad es simplemente la ordenada al origen de la carga factorial, i.e. el valor promedio del factor condicionada por el indicador. Las cargas factoriales \\(\\lambda_{i}\\) son equivalentes al parámetro de discriminación. La diferencia decisiva es la parametrización que usa TRI. Cuando las cargas factoriales son más altas, esto significa que hay mayor relación entre el indicador y el factor y, por tanto, existe el indicador discrimina más potentemente. Si consideramos que \\(\\psi\\) es la varianza de la variable latente: \\[\\begin{equation} \\tag{3.12} a_{i}=\\lambda_{i}\\sqrt{\\psi} \\end{equation}\\] La ecuación (3.12) muestra el cálculo de la confiabilidad para un modelo factorial unidimensional pero fácilmente ajustable para modelos multidimensionales. Los modelos TRI fundamentalmente se diseñaron bajo el supuesto de escalas unidimensionales, i.e. un factor con varias variables de manifiesto que pertenece exclusivamente a tal factor. Sin embargo, es posible estimar modelos multidimensionales (Reckase, 2009). Es fácil identificar por qué. Los modelos factoriales confirmatorios pueden ser unidimensionales y multidimensionales y como hay una equivalencia entre estos modelos y TRI es posible estimar severidad y discriminación para modelos con múltiples dimensiones. Sin embargo, es importante volver al concepto de homogeneidad y su rol para la confiabilidad. Gibbons, Immekus, Bock, &amp; Gibbons (2007) ha mostrado que la presencia de un factor de alto orden produce poco sesgo en la estimación de los parámetros de los modelos TRI. En principio, este debería ser el supuesto en medición multidimensional de pobreza porque trabajamos con modelos que -presumimos- tienen tal estructura. En cualquier caso, es posible siempre estimar un modelo factorial confirmatorio. 3.4.1 Criterios de uso: Estimadores de confiabilidad de ítem Los estadísticos \\(\\beta\\), \\(\\alpha\\), \\(\\omega\\) y \\(\\omega_h\\) se enfocan en estimar la confiabilidad global de una escala. Sin embargo, hay aspectos puntuales que conectan con el cálculo de la confiabilidad para cada ítem. El cálculo de \\(\\omega\\) se basa en cargas factoriales. Cargas factoriales con valores bajos nos indican que hay mayor error y si esto ocurre para el resto de los indicadores tendremos confiabilidad global baja. De manera análoga, bajos \\(\\lambda_{i}\\) pueden traducirse en estándares de baja confiabilidad de ítem. La pregunta es entonces ¿Qué tan bajo es bajo? En estudio de pobreza Guio et al. (2016) usa regla de \\(&lt;.4\\) para cargas factoriales estandarizadas como media de baja confiabilidad. Nájera (2018) mostró que efectivamente esos valores tienen una alta probabilidad de resultar en baja confiabilidad global y alto error de clasificación. En la sección anterior se ilustró la conexión entre cargas factoriales y el parámetro de discriminación. Para los parámetros de un modelo TRI, los estándares son \\(\\lesssim.8\\) para discriminación y \\(\\geq 3\\) deviaciones estándar para severidad. En este último caso, cuando la severidad es tan alta, quiere decir que el indicador tiene muy poca información para ser de utilidad es redundante. Estas reglas, sin embargo, son guías para la interpretación. 3.5 Confiabilidad de ítem: Pesos, discriminación y axiomas En esta sección discutiremos la relación entre confiabilidad, confiabilidad de ítem y pesos. Esto se debe a que estos aspectos están íntimamente relacionados y, sin embargo, en medición de pobreza raramente se hace está conexión de manera explícita. Primero hablemos de lo que significan los pesos en medición de pobreza. Uno de los temas más discutidos en medición de pobreza multidimensional gira en torno a la ponderación de los indicadores y las dimensiones (Decancq &amp; Lugo, 2013). Esta discusión se ha dado en dos planos: Uno teórico -¿Son algunas necesidades más importantes o críticas que otras?- y el otro es empírico -¿Cuál es el efecto de los pesos en la identificación del grupo pobre o no pobre?-. Esta sección es sobre el lado empírico de la medición de pobreza así que nos enfocaremos en esta parte de la discusión. Un problema central es que la medición de pobreza a discutido de un marco analítico para analizar el rol que tienen los pesos en medición. ¿Qué significa está afirmación? Pensemos primero en lo que son los pesos. Si hay dos indicadores binarios y a uno se le asigna un peso de \\(w_1=.5\\) y a otro un peso de \\(w_2=2\\), se afirman varias cosas: que un indicador es cuatro veces más importante que otro, que tener privación del segundo indicador lleva a tener mayor severidad de pobreza e, indirectamente, que la probabilidad de ser clasificado como pobre es condicional en los pesos \\(w_i\\). Mencionamos en el Capítulo 2 (2) que lo que se hace en medición es tomar muestras de los indicadores en este caso cuando incorporamos pesos, lo que hacemos es un muestreo informado de los pesos \\(\\Theta\\). La muestra más usada es \\(w_i=1\\), es decir, todos los pesos son iguales. La pregunta en medición multidimensional de pobreza es binaria: Pesos diferenciales o pesos iguales. Si la respuesta es pesos diferenciales, entonces la pregunta es sobre qué conjunto de pesos diferenciales. Mencionamos que hay una carencia de un marco analítico en medición de pobreza cuando se habla de los pesos. Es decir, de un marco que nos diga empíricamente (fundamentado en alguna teoría, no de pobreza sino de medición) cómo evaluar el efecto de los pesos. Esto se debe a que lo que normalmente se hace es algún tipo de análisis de sensibilidad para ver el efecto que tienen los pesos sobre algún tipo de ranking (de población o de países), de manera que, si encontramos altas discrepancias, es probable que nuestros pesos estén introduciendo demasiada variabilidad [Alkire2015]. El problema con este tipo de análisis es que los análisis de sensibilidad llevan a alto sesgo de confirmación porque los investigadores pueden ponerle límites a su análisis discrecionalmente. ¿Qué tienen que ver los pesos con confiabilidad? Si los pesos reflejan la relación entre el nivel de pobreza y el indicador, entonces entramos naturalmente al postulado de variables latentes sobre la relación de la variable observada y el nivel latente de pobreza. Dentro de la teoría de la medición ¿Qué parámetros nos dicen algo sobre esa relación? Dentro de la TRI tanto la severidad como la discriminación nos dan piezas de información puntual sobre la relación del indicador con el atributo que estamos midiendo. En medición de pobreza hay literatura que utiliza pesos de prevalencia, es decir, usa la severidad de la privación para asignar peso a las necesidades humanas (Desai &amp; Shah, 1988; Willitts, 2006). Otro enfoque es usar la discriminación para asignar pesos, en este caso priorizaríamos los indicadores que nos dan mejor información para distinguir entre el grupo pobre y no pobre. Hay una entonces una conexión obvia entre los parámetros de confiabilidad de ítem y pesos en medición multidimensional de pobreza. Esto no es casual, la teoría de la medida tiene décadas preocupándose por este tema (Brennan, 2006). La teoría de la medición propone que una de las consecuencias de confiabilidad es un ordenamiento consistente de la población, i.e. de alta a baja severidad de pobreza condicional en los indicadores. En otras palabras, una medida con alta confiabilidad es una escala autoajustable debido a que garantiza adecuada clasificación de la población (Streiner et al., 2015). ¿Cómo es posible esto? El parámetro de discriminación tiene un rol crucial en la clasificación y ordenamiento de la población. Debido a que las cargas factoriales son la varianza explicada por el factor común (i.e. Comunalidad). Esto significa que las cargas factoriales pueden verse como los pesos óptimos de los indicadores para los datos en cuestión -incluso son generalizables para la población ceteris paribus-. Esto parece sugerir entonces que los pesos diferenciales serían la solución óptima al problema de los pesos. Sin embargo, lo que nos dice la teoría de la confiabilidad es: la confiabilidad de cada ítem es más importante que los pesos y hay que preocuparse por pesos diferenciales para corregir la baja confiabilidad. Nájera (2018) muestra experimentalmente cómo ocurre la relación entre pesos, cargas factoriales y clasificación de la población. A través de un estudio de Monte Carlo se puede apreciar que alta confiabilidad resulta en un índice autoajustable en el sentido de que el ordenamiento de la población es muy poco sensible a cambios en los pesos. Es decir, si se tiene alta confiabilidad y alta confiabilidad de ítem, ya no hay información extra que podamos añadir para mejorar nuestra escala -veremos empíricamente que pasa en la próxima sección-. Con un poco de intuición podemos ver por qué esto es posible. Si las cargas factoriales nos dicen la varianza que se explica por el factor y tenemos indicadores con alta relación con el factor, esto quiere decir que hay poca información que podamos incluir para mejorar nuestro índice. El score de privación es la suma de los indicadores (y estos indicadores discriminan muy bien entre la población pobre y no pobre) y el valor para cada persona estará altamente correlación con cambios por ponderación. La gente con alta severidad permanecerá en esta posición independientemente de los pesos que se usen. El punto crucial es que si se usan pesos diferenciales, el investigador tiene que asumir que son desconocidos, y siempre se introducirá más ruido a la clasificación de la población. Mientras confiabilidad es una condición necesaria para ordenamientos poblacionales consistentes, los pesos diferenciales no lo son. 3.5.1 Confiabilidad y monotonicidad La relación entre confiabilidad y pesos va más allá del ordenamiento poblacional. Mencionamos en el Capítulo 1 (1) que un aspecto decisivo en medición de pobreza es la correspondencia que hay entre supuestos y experimento. Uno de los axiomas más famosos en la medición multidimensional de pobreza es el de Monotonicidad de Sen (1976). Este axioma nos dice que la pobreza ceteris paribus debería disminuir después de una mejora en los logros observados (Alkire et al., 2015; Sen, 1976). Para (???) es fundamental revisar vía del experimento si los axiomas de una medida se sostienen en el mundo real. ¿Qué evidencia tenemos de que el axioma de monotonicidad se cumple? ¿Qué tiene que ver esto con confiabilidad? La teoría de la medición es mucho más madura que los esquemas de medición que se tienen en pobreza. No es casual que desde los orígenes de análisis factorial existiera no solo un axioma sobre la relación del indicador observado y el factor, sino un método de escrutinio sobre tal relación. La teoría de la medida establece que los valores observados de una medida al final reflejan su relación con un factor determinado, i.e. la carencia de agua entubada es causada por pobreza. De esta manera, las cargas factoriales nos dicen no sólo si el indicador es confiable o no sino si respeta el axioma de monotonicidad. Nájera (n.d.) hizo un ejercicio de Monte Carlo para ejemplificar numéricamente esta relación haciendo uso de parámetros reales. El estudio de Monte Carlo muestra que la poca o nula confiabilidad de ítem lleva a una violación del axioma de monotonicidad. La conclusión es que indicadores que tienen baja discriminación (\\(\\lambda_ij&lt;.4\\), cargas estandarizadas) violan el axioma de monotonicidad débil y en algunas circunstancias pueden violar monotonicidad fuerte. Estos indicadores por tanto introducen más ruido que señal en la medición de pobreza. Nájera (n.d.) basó el experimento en parámetros reales provenientes del Índice Multidimensional de Pobreza aguda que proponen Alkire &amp; Santos (2010), el índice para Latinoamérica de Santos2016 y el índice para la Unión Europea Guio et al. (2012). ¿Qué exactamente pasa en la práctica? Considere el indicador de desempleo de la medida que proponen Santos2016. Si uno observa con cuidad las tasas de desempleo en la región se dará cuenta que son muy bajas y que el perfil del desempleado generalmente corresponde a la población joven de clase media. Esta es la población que tiene al desempleo como opción, quienes no lo tienen se dedican a una actividad informal. Por otro lado, el desempleo es un predictor no una manifestación de pobreza. Entonces hay razones para sospechar de este indicador. Los análisis sugieren que efectivamente este indicador no es confiable. La lección del estudio de Monte Carlo es que aumentos de privación en este indicador no están asociados con mayor pobreza. Es decir, se viola el axioma de monotonicidad débil. Lo que concretamente está pasando es que pasar a la categoría de desempleo significa ser clase media y, por tanto, hay una relación baja (a veces inversa) con privación. Puede ilustrarse muy sencillamente el gran riesgo que se corre al dejar indicadores con baja confiabilidad en términos de la violación del axioma de monotonicidad. Considere que tenemos una medida que consta de 10 indicadores con una muestra de 20 personas (O 20 millones). Imagine que la tasa de desempleo es 10% -dos personas desempleadas-. Si comparamos a dos personas con el mismo score de población concluiríamos que su severidad de pobreza es muy parecida, pero ¿Qué si una es desempleada y otra no? Lo que ocurriría es que en realidad tienen niveles latentes de pobreza distintos. Si la desempleada cambia de estado (a empleada), haríamos conclusiones muy distintas de su severidad observada cuando en realidad puede ser que su pobreza no haya cambiado. Esto absolutamente indeseable en medición porque si usamos una línea de referencia para calcular la prevalencia de pobreza, vamos a clasificar equivocadamente a la población (ilustraremos esto en la siguiente sección). 3.6 Estimación de confiabilidad: Global y de ítem 3.6.1 Confiabilidad global Para introducir la idea de confiabilidad usaremos la base de datos “Rel_MD_data_1_1.dat”. Estos son datos simulados para producir una medida de alto orden multidimensional de pobreza (\\(n=5000\\)). La medida tiene nueve indicadores en total distribuidos de manera equivalente en tres dimensiones. Comenzaremos a usar el programa R R-software para la estimación de confiabilidad. Los datos fueron simulados en Mplus 8 (Muthén &amp; Muthén, 2012). Para comenzar leeremos el archivo “Rel_MD_data_1_1.dat” con la función read.table(). Lo siguiente que vamos a hacer es asignarle nombre a nuestras variables usando la función colnames(). Como vamos a usar esta base varias veces, le diremos a R que guarde esto en un objeto llamado Rel_MD_1. Así podremos manipularlo más fácilmente. Una vez con los datos podemos explorarlos usando distintas funciones. Usaremos str() para ver las variables que tenemos. Podemos ver que tenemos 11 variables binarias (indicadores de privación) y tenemos además algunas variables auxiliares que usaremos después para algunos cálculos posteriores. We ask R to store this on Rel_MD_1 for easy access and manipulations. Now we will explore the contents of this data set with str() to see which variables we have. We have 11 binary variables (deprivation indicators) and then we have some ancillary data that we will use later for some computations. We have 11 binary variables but above we said that the index has 9 indicators. We will use x10 and x11 below but for now focus on x1-x9. library(plyr) Rel_MD_1&lt;-read.table(&quot;Rel_MD_data_1_1.dat&quot;) colnames(Rel_MD_1)&lt;-c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;,&quot;x6&quot;, &quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;,&quot;x10&quot;,&quot;x11&quot;, &quot;resources&quot;,&quot;educ_yr&quot;,&quot;occupation&quot;,&quot;hh_members&quot;,&quot;class&quot;) str(Rel_MD_1) ## &#39;data.frame&#39;: 5000 obs. of 16 variables: ## $ x1 : int 1 0 0 1 1 1 0 0 1 0 ... ## $ x2 : int 1 0 0 1 0 0 0 0 0 0 ... ## $ x3 : int 1 0 0 0 0 0 0 0 0 0 ... ## $ x4 : int 1 0 1 0 0 0 1 1 1 0 ... ## $ x5 : int 0 0 0 0 0 0 0 0 1 0 ... ## $ x6 : int 0 0 0 0 0 0 1 0 1 0 ... ## $ x7 : int 0 0 0 1 0 0 0 0 1 0 ... ## $ x8 : int 0 0 0 0 0 0 0 0 1 0 ... ## $ x9 : int 0 0 0 0 0 0 0 0 1 0 ... ## $ x10 : int 0 0 0 0 1 0 0 1 0 1 ... ## $ x11 : int 0 0 0 0 1 0 0 1 0 0 ... ## $ resources : num 3277 7509 7184 1574 2210 ... ## $ educ_yr : int 6 15 8 6 9 13 12 7 7 6 ... ## $ occupation: int 4 2 5 2 5 5 6 7 5 3 ... ## $ hh_members: int 5 1 2 7 4 4 2 4 1 3 ... ## $ class : int 2 1 1 2 2 1 1 2 2 2 ... En esta sección vamos a enfocarnos en los nueve indicadores de privación (mencionamos que nuestra medida tiene 9 indicadores y no 11: variables x10 y x11). Los indicadores de privación de nuestra medida son los primeros nueve x1-x9. Lo primero que vamos a hacer es checar cómo lucen nuestros datos. Le pediremos a R que nos muestre los primeros 10 renglones (personas) de nuestra base de datos. Rel_MD_1[1:10,1:9] ## x1 x2 x3 x4 x5 x6 x7 x8 x9 ## 1 1 1 1 1 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 0 ## 3 0 0 0 1 0 0 0 0 0 ## 4 1 1 0 0 0 0 1 0 0 ## 5 1 0 0 0 0 0 0 0 0 ## 6 1 0 0 0 0 0 0 0 0 ## 7 0 0 0 1 0 1 0 0 0 ## 8 0 0 0 1 0 0 0 0 0 ## 9 1 0 0 1 1 1 1 1 1 ## 10 0 0 0 0 0 0 0 0 0 Una de las primeras cosas que nos interesaría saber es la proporción de personas que tiene privación para cada indicador. Primero, le pediremos a R que estime la media mean() para todos los indicadores y que guarde la información en el objeto dep_prop. Después le pediremos a R que redondee los valores para los nueve indicadores. Después de estas manipulaciones podemos apreciar que el 50% de la población en esta muestra carece del indicador x1, por ejemplo. dep_prop&lt;-unlist(lapply(Rel_MD_1, function(x) mean(x))) dep_prop&lt;-round(dep_prop[1:9]*100,0) dep_prop ## x1 x2 x3 x4 x5 x6 x7 x8 x9 ## 50 29 16 49 29 16 45 26 16 Vamos a asumir por el momento que nuestros datos están listos para el análisis y que provienen de una muestra aleatoria. En el Capítulo 1 (1) se hizo énfasis en la importancia de producir medidas de pobreza que estén basadas en teoría. También mencionamos que este nos siempre es el caso y que en la práctica se trabaja más de manera exploratoria. Por esta razón vamos a mostrar la estimación de confiabilidad desde un punto de vista exploratorio y confirmatorio. Comenzaremos con el primer tipo de análisis de confiabilidad: Exploratoria. 3.6.2 Estimación exploratoria de confiabilidad gloal Ahora que nos hemos familiarizado con los datos podemos proceder a estimar la confiabilidad global de nuestra escala. En esta sección asumiremos el caso donde no tenemos un modelo teórico de pobreza (i.e. tenemos una lista de indicadores candidatos pero no tenemos una estructura predefinida). El principio de confiabilidad se preocupa por la homogeneidad de una escala y su capacidad de producir ordenamientos poblaciones para una población. Comenzaremos por estimar la confiabilidad global de nuestra escala usando el paquete psych del programa R [Revelle2014]. Este paquete contiene una lista bastante completa y útil para calcular diferentes estimadores de confiabilidad (\\(\\alpha\\), \\(\\beta\\), \\(\\omega\\) and \\(\\omega_h\\)) bajo diferentes condiciones. El paquete pscyh puede usarse para análisis confirmatorios y exploratorios tanto para medidas unidimensionales como multidimensionales. En este caso, partimos de que no conocemos la estructura de la escala. En las secciones subsecuentes mostraremos como pscyh interactúa con otros paquetes como lavaan para estimar \\(\\omega\\) y \\(\\omega_h\\) a partir de un modelo confirmatorio (Rosseel, 2012). El paquete pysch permite estimar \\(\\alpha\\) y \\(\\omega\\) usando la misma función (omega()). El paquete tiene diferentes opciones y los parámetros precodificados coinciden con los de nuestra medida8. Es muy importante recalcar que el valor de \\(\\omega\\) de un modelo exploratorio (Modelo Factorial Exploratorio, MFE) es una aproximación al valor óptimo proveniente de un modelo confirmatorio. En la siguiente sección ilustramos cómo se calcula \\(\\omega\\) para un modelo confirmatorio. Lo único que tenemos que hacer es aplicar la función omega() a los nueve indicadores en cuestión. En este caso corresponden a las primeras nueve columnas de nuestra base. Recomendamos usar el comando ?omega() para inspeccionar las opciones de estimación. Le solicitaremos a R que guarde los resultados en el objeto omega_exp1 porque lo utilizaremos más adelante. En este objeto se guardan los resultados del análisis como las cargas factoriales de cada indicador a cada subdimensión -del modelo bi-factorial basado en Schmid Leiman-, valores del ajuste del modelo, la información de distintos estadísticos de confiabilidad, ajuste global del modelo exploratorio, la estimación de \\(\\alpha\\) y \\(\\omega\\), así como la estimación de omega total para cada dimensión (str(omega_exp1) nos muestra los objetos que contiene la estimación). Después de aplicar la función omega() a nuestros nueve indicadores, observaremos que hay distintos objetos si ejecutamos: omega_exp1 o str(omega_exp1). En este caso nos enfocaremos en la estimación de \\(\\alpha\\) y \\(\\omega\\) porque estamos interesados en explorar cuál es la confiabilidad global de esos nueve indicadores con una solución para tres dimensiones. Para extraer los dos estimadores de interés crearemos un data.frame que contenga la extracción del objeto omega_exp1. # install.packages(&quot;psych&quot;) require(psych) omega_exp1&lt;-omega(Rel_MD_1[,c(1:9)]) rel_uni_exp&lt;-data.frame(omega_exp1=omega_exp1$omega.tot, alpha=omega_exp1$alpha) rel_uni_exp ## omega_exp1 alpha ## 1 0.883968 0.8476526 Podemos apreciar que ambos valores son bastante altos (\\(\\geq.8\\)) (Ver sección 3.3 para una explicación) y esto nos sugiere que la escala es altamente confiable. En este caso \\(\\alpha&lt;\\omega\\) indicando que la escala viola el supuesto de equivalencia \\(\\tau\\) (igualdad de cargas factoriales). A estas alturas de nuestro ejercicio esto puede generarnos la falsa sensación de que estimar \\(\\alpha\\) y \\(\\omega\\) es trivial. Efectivamente, tanto la ejecución de la función y como la obtención de valores altos de confiabilidad fue producto de pasos muy sencillos. Sin embargo, este ejemplo es fácil porque todos los indicadores tienen buen comportamiento- esto proviene de datos perfectos. Por tanto, para ganar un mejor entendimiento de confiabilidad y sus efectos sobre la clasificación de poblaciones mostraremos que pasa cuando se incluyen indicadores que reducen la confiabilidad. Esto puede hacerse si añadimos indicadores ruidosos a nuestra medida, i.e. indicadores que añaden heterogeneidad. Lo que haremos a continuación es sustituir los indicadores x1 y x2 por los indicadores x10 y x11. Ahora aplicamos la función omega() a la nueva matriz de datos que incluye los indicadores x10 y x11 y excluye los indicadores x1 y x2. Vemos que la confiabilidad cae lo suficiente para preocuparnos porque ambos \\(\\omega\\) y \\(\\alpha\\) están por debajo de las reglas sugeridas que se derivan de la experimentación de Monte Carlo. En este caso guardamos los resultados de la implementación de \\(\\omega\\) en el objeto omega_unr_exp y extraemos los valores de \\(\\omega\\) y \\(\\alpha\\). omega_unr_exp&lt;-omega(Rel_MD_1[,c(3:11)]) unrel_uni_exp&lt;-data.frame(omega_exp=omega_unr_exp$omega.tot, alpha=omega_unr_exp$alpha) unrel_uni_exp ## omega_exp alpha ## 1 0.799405 0.738685 ¿Cuál es el impacto del uso de estos dos nuevos indicadores? Para este experimento, primero, estimaremos los valores de omega usando diferentes combinaciones de ítems. Es decir, estamos simulando que la medida perfecta es la de los ítems x1-x9 y que las otras son casos especiales con combinaciones de indicadores buenos y malos. Esto no es muy distinto a lo que pasa en la práctica puesto que siempre trabajos con muestras del conjunto perfecto. En todos estos casos especiales dejaremos por lo menos siete indicadores de la medida perfecta. Lo que haremos es calcular cinco casos especiales y guardarlos en los objetos omega_exp2-5. Todas estas medidas son parte del conjunto de indicadores confiables y deberíamos esperar pérdidas bajas de confiabilidad. Al extraer los valores de \\(\\omega\\) de las cinco medidas y de la medida que incorpora los indicadores x10 y x11 podemos ver la diferencia entre las medidas confiables y la no confiables. omega_exp2&lt;-omega(Rel_MD_1[,c(3:9)]) omega_exp3&lt;-omega(Rel_MD_1[,c(1,2,4,5,7,8)]) omega_exp4&lt;-omega(Rel_MD_1[,c(2,3,5,6,8,9)]) omega_exp5&lt;-omega(Rel_MD_1[,c(1,3,4,6,7,9)]) omegas_exp&lt;-data.frame(omega_exp1=omega_exp1$omega.tot, omega_exp2=omega_exp2$omega.tot, omega_exp3=omega_exp3$omega.tot, omega_exp4=omega_exp4$omega.tot, omega_exp5=omega_exp5$omega.tot, omega_unrel=omega_unr_exp$omega.tot) Una vez que estimamos los cinco modelos exploratorios con la función omega(), podemos comparar los valores de confiabilidad guardados en el objeto omegas_exp. Vemos que la teoría se sostiene para este ejemplo. Vemos que la escala con menor confiabilidad es la que incorpora a los indicadores x10 y x11. Las medidas con siete ítems tienen mayor confiabilidad. Esta es una lección muy importante para la gente interesada en medir pobreza porque en algunos casos se preservan malos indicadores en los índices y la consecuencia casi siempre será una pérdida importante de confiabilidad. t(omegas_exp) ## [,1] ## omega_exp1 0.8839680 ## omega_exp2 0.8599319 ## omega_exp3 0.8779016 ## omega_exp4 0.8543497 ## omega_exp5 0.8441886 ## omega_unrel 0.7994050 3.6.3 Análisis confirmatorio de confiabilidad La producción ideal de una medida de pobreza debe incluir una clara especificación del modelo de medición que asume nuestro índice. Tanto en la literatura teórica como en la aplicada, distintos autores proponen que la pobreza es multidimensional y tiene una estructura jerárquica ??). Por tanto, en la medición multidimensional de la pobreza casi siempre estaremos interesados en examinar la confiabilidad de nuestro índice haciendo uso de un modelo a priori y requeriremos estimar tanto el omega global \\(\\omega\\) como el omega jerárquico \\(\\omega_h\\). Estos dos estimadores pueden estimarse a partir de un modelo exploratorio con el paquete pysch. Sin embargo, este libro busca alentar a los investigadores en el uso y escrutinio de modelos teóricos y no alentar enfoques puramente exploratorios. Esta sección se enfoca en el análisis de confiabilidad para modelos teóricos (a priori) de pobreza. A diferencia de la sección previa, los siguientes ejemplos utilizan análisis factorial confirmatorio (AFC) (Brown, 2006). La diferencia clave entre análisis exploratorio y confirmatorios es precisamente que el segundo tipo se basa en un modelo teórico que establece la estructura de la medida en cuestión, i.e. un plano/diagrama para medir pobreza ??). El AFC es una forma de examinar el grado en el que el modelo teórico (i.e. número de dimensiones, contenidos de las dimensiones-indicadores, e independencia de las dimensiones) es capaz de reproducir los datos observados. En términos estadísticos, los investigadores establecen un patrón de relaciones entre dimensiones e indicadores (cargas factoriales) y se estima el grado en el que tales relaciones existen. Esto se especifica en las ecuaciones (2.2) y (2.3). Esto es simplemente la formulación matemática de los diagramas presentados en las sección ??. \\[\\begin{equation} x_{ij} = \\lambda_{ij} \\eta_j + \\varepsilon_ij \\end{equation}\\] \\[\\begin{equation} \\eta_j = \\gamma_{j} \\zeta + \\xi \\end{equation}\\] La confiabilidad se estima después de que hayamos estimado nuestro modelo confirmatorio porque ambos \\(\\omega\\) and \\(\\omega_h\\) se calculan a partir de piezas clave de información del AFC: Las cargas factoriales y los errores. Esto es, las cargas factoriales de cada indicador y los residuales del modelo son los parámetros necesarios para calcular ambos estadísticos de confiabilidad (Ver ecuación (3.9)). En lo siguiente mostraremos como calcular \\(\\omega\\) and \\(\\omega_h\\) usando Mplus y R. Comenzaremos con el programa R y el paquete lavaan (Rosseel, 2012). Este paquete tiene una serie de funciones para estimar diferentes tipos de modelos de variables latentes como modelos de medición (AFC) y modelos analíticos (Ecuaciones Estructurales). Una vez que el modelo confirmatorio se estima con el paquete de R lavaan, utilizaremos la función omegaFromSem() del paquete psych para estimar \\(\\omega\\) and \\(\\omega_h\\). Sin embargo, mostraremos cómo podemos calcular manualmente para familiarizarnos con las diferencias concretas en el cálculo de ambos estadísticos y también nos ayudará a entender el proceso de estimación con Mplus. 3.6.3.1 Estimación usando R y lavaan Para ilustrar el calculo de \\(\\omega\\) y \\(\\omega_h\\) continuaremos usando nuestros datos simulados (“Rel_MD_data_1_1.dat”). En la sección previa guardamos nuestros datos en el objeto Rel_MD_1. La primera pregunta que tenemos que hacernos es ¿Cuál es la estructura del modelo de medición?. En otras palabras, tenemos que especificar cuántas dimensiones, cuántos y qué indicadores tenemos por dimensión. En este caso, asumiremos que nuestra teoría nos dice que la estructura de nuestra medida tiene un factor de alto orden (pobreza), tres sub-factores (dimensiones de pobreza) y tres indicadores por dimensión. Con esto en mente, lo que tenemos que decirle a lavaan (library(lavaan)) es cómo luce nuestro modelo (dado que es más fácil calcular \\(\\omega\\) y \\(\\omega_h\\) a partir de la transformación de Schmid &amp; Leiman (1957)) considerando una estructura no jerárquica sino bi-factorial (i.e. el efecto directo del factor y sub-factores sobre los indicadores). Para hacer este paso, crearemos un objeto llamado MD_model. Lo que indicaremos es algo muy sencillo. Primero, diremos que hay un factor de alto orden h que tiene nueve variables de manifiesto/indicadores (x1-x9). Después lo que indicamos es que hay tres dimensiones F1, F2 y F3 donde cada una tiene tres indicadores. Por ejemplo, F1 tiene x7, x8 Y X9 como indicadores. Para propósitos de la estimación, estableceremos que los factores no están correlacionados para ser consistentes con nuestro modelo teórico y la transformación Schmid &amp; Leiman (1957). library(lavaan) MD_model &lt;- &#39; h =~ +x1+x2+x3+x4+x5+x6+x7+x8+x9 F1=~ + x7 + x8 + x9 F2=~ + x4 + x5 + x6 F3=~ + x1 + x2 + x3 h ~~ 0*F1 h ~~ 0*F2 h ~~ 0*F3 F1 ~~ 0*F2 F2 ~~ 0*F3 F1 ~~ 0*F3 &#39; Hasta ahora sólo hemos especificado nuestro modelo, no hemos dado la instrucción a R de que lo estime usando lavaan. Para estimar el modelo confirmatorio usaremos la función semla cual es una función general que comprende cfa y lavaan (ambas pueden usarse). Es muy importante tener en mente que las variables de nuestra medición son categóricas, por tanto tenemos que incluir la opción ordered() y pediremos que lavaan incluya cargas factoriales estandarizadas con el comando std.lv=TRUE. Guardaremos nuestros resultados en el objeto fit. fit &lt;- sem(MD_model, data = Rel_MD_1, ordered=c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;, &quot;x6&quot;,&quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;), std.lv=TRUE) Antes de mostrar la forma automática para estimar \\(\\omega\\) y \\(\\omega_h\\), mostraremos la forma de hacer el cálculo manual. Hay dos parámetros principales que necesitamos para el cálculo: las cargas factoriales de los indicadores al factor general (\\(\\lambda_h\\)), las cargas correspondientes a cada dimensión (\\(\\lambda_j\\)) y el error de cada indicador. Esto se puede extraer del objeto fit de la siguiente manera: lambdas&lt;-as.data.frame(fit@Model@GLIST$lambda) error&lt;-colSums(fit@Model@GLIST$theta) Para poder calcular nuestros estadísticos de confiabilidad necesitamos la suma de las cargas factoriales al cuadrado (\\(\\lambda_h\\)) y (\\(\\lambda_j\\)), así como la suma del error. Posteriormente, calculamos ambos estadísticos \\(\\omega\\) and \\(\\omega_h\\) usando las ecuaciones (3.9) and (3.10). Vemos que fundamentalmente, \\(\\omega_\\) es el descuento de lo que aportan las dimensiones a la explicación de la variabilidad de los indicadores. Así, \\(\\omega_h\\) es una medida de confiabilidad que se enfoca en el residuo de lo que añaden la dimensiones a la variabilidad de los indicadores. Cuando \\(\\omega = \\omega_h\\), evidentemente la aportación de las dimensiones es nula. Vemos que los valores de \\(\\omega\\) y \\(\\omega_h\\) son altos, aunque ligeramente distintos a los valores del modelo exploratorio. Recordemos que estos valores son los que idealmente deben interesarnos puesto que son el valor estimado de confiabilidad para nuestra propuesta teórica. Slambda_2&lt;-sum(lambdas[1])^2 + sum(lambdas[2])^2 + sum(lambdas[3])^2 + sum(lambdas[4])^2 error &lt;- sum(error) omega_t &lt;- Slambda_2 / (Slambda_2+error) omega_h &lt;- sum(lambdas[1])^2 / (Slambda_2+error) omegamanual&lt;-c(omega_h=omega_h,omega_t=omega_t) omegamanual ## omega_h omega_t ## 0.8445022 0.9707344 La función omegaFromSem() del paquete pysch estima confiabilidad de manera automática. Para aplicar esta función lo único que necesitamos es indicar el objeto que contiene las cargas factoriales, en este caso fit. Vamos a guardar los resultados en el objeto omegasem. Los resultados corresponden con lo previamente observado y concluimos que para esos valores la confiabilidad global y dimensional es alta. omegasem&lt;-omegaFromSem(fit) omegasem&lt;-c(omega_h=omegasem$omega, omega_t=omegasem$omega.tot) omegasem ## omega_h omega_t ## 0.8446990 0.9707276 3.6.3.2 Computo de confiabilidad usando Mplus y R El paquete de R mplusAutomation es una excelente alternativa para automatizar la estimación de modelos en Mplus desde R -es posible organizar múltiples estimaciones y evitar perderse con tantas ventanas- (Hallquist &amp; Wiley, 2018). Podemos crear dentro de R una sintaxis que sea legible por Mplus. En esta sintaxis llamada test, indicamos el nombre de las variables, el tipo de variables (categóricas) y qué variables vamos a usar. En la sección ANALYSIS, le pedimos al programa Mplus que use el estimador wlsmv y cuatro núcleos9. A continuación, indicamos que el factor general es h y que hay nueve indicadores. Hacemos lo mismo para las tres dimensiones donde tenemos tres indicadores por dimensión. Nuevamente, indicamos que la correlación entre los factores es cero para hacerlo compatible con la transformación Schmid &amp; Leiman (1957). Al igual que en el caso previo con lavaan este es un modelo bi-factorial. Guardamos esta sintaxis en el objeto test. library(MplusAutomation) test &lt;- mplusObject( TITLE = &quot;Bi-factor model CFA;&quot;, VARIABLE = &quot; NAMES = x1-x11 resources educ_yr occupation class; CATEGORICAL = x1-x9; USEVARIABLES = x1-x9;&quot;, ANALYSIS = &quot;ESTIMATOR = wlsmv; PROCESS = 4;&quot;, MODEL = &quot;f1 by x1-x3; f2 by x4-x6; f3 by x7-x9; h by x1 x2 x3 x4 x4 x5 x6 x7 x8 x9; F1 with F2@0; F2 with F3@0; F3 with F1@0; h with f1@0; h with f2@0; h with f3@0;&quot;, OUTPUT = &quot;std stdyx;&quot;) Ahora que hemos especificado el modelo y lo hemos guardado en el objeto test, podemos pasar esta sintaxis de R para estimarla en Mplus (*.inp)´. La función mplusModeler() va a hacer esta traducción por nosotros. Le diremos a esta función que el objeto test contiene la información del modelo que queremos estimar, que lo que queremos es un archivo de Mplus llamado rel_CFA_2.inp y que utilice los datos Rel_MD_data_1_1.dat para estimar el modelo. La función que se presenta a continuación permite utilizar el modelo directamente usando la opción run10: res &lt;- mplusModeler(test, modelout = &quot;rel_CFA_2.inp&quot;, writeData = &quot;never&quot;, hashfilename = FALSE, dataout=&quot;Rel_MD_data_1_1.dat&quot;, run = 1L) ## ## Running model: rel_CFA_2.inp ## System command: C:\\WINDOWS\\system32\\cmd.exe /c cd &quot;.&quot; &amp;&amp; &quot;Mplus&quot; &quot;rel_CFA_2.inp&quot; ## Reading model: rel_CFA_2.out Una vez que el modelo se haya estimado, podemos importar los resultados a R usando la función readModels(). Ahora podemos explorar los resultados en el siguiente capítulo, por ahora, nos enfocaremos en la estimación de \\(\\omega\\) and \\(\\omega_h\\). Las cargas factoriales del modelo bifactorial se encuentran en una lista bajo el nombre parameters. Podemos ahora pedir las cargas factoriales estandarizadas como hicimos con lavaan. También podemos pedir que nos muestre los errores guardados en el objeto r2. Una vez que tenemos los parámetros de interés, procedemos a estimar de la misma manera los estadísticos de confiabilidad. Podemos apreciar que reproducimos los resultados de lavaan. REL_CFA_2&lt;-readModels(filefilter =&quot;rel_CFA_2&quot;) ## Reading model: C:/OneDrive/Proyectos Investigacion/PM Libro/rel_cfa_2.out lambdas&lt;-REL_CFA_2$parameters$std.standardized[1:18,1:3] error&lt;-REL_CFA_2$parameters$r2[6] lambda_2&lt;-sum(lambdas[10:18,3])^2 + sum(lambdas[1:3,3])^2 + sum(lambdas[4:6,3])^2 + sum(lambdas[7:9,3])^2 error &lt;- sum(error) omega_t &lt;- lambda_2 / (lambda_2+error) omega_h &lt;- sum(lambdas[10:18,3])^2 / (lambda_2+error) omega_t ## [1] 0.9707333 omega_h ## [1] 0.8445348 3.6.4 Confiabilidad por ítem 3.6.4.1 Estimación con R La confiabilidad global es una aproximación sintética a la calidad de un índice en tanto estima el grado de homogeneidad de la escala y su capacidad para producir ordenamientos consistentes de la población de estudio. En la sección @ref(#relestimation) mostramos que la confiabilidad es sensible a la inclusión de ítems con baja correlación y que esto tiene implicaciones negativas en la consistencia de los resultados en distintas mediciones. Esta sección se enfoca en los atributos de los indicadores que producen baja confiabilidad -más allá de correlación, i.e. cómo ítems específicos contribuyen positiva o negativamente a la confiabilidad de los puntajes de una población. La sección 3.4 presenta la teoría de respuesta al ítem (TRI), la cual es una teoría sobre las propiedades de los indicadores. La TRI propone a los parámetros de discriminación y severidad como una manera de conceptualizar atributos clave de los indicadores de interés. La TRI asume que la escala es unidimensional y que los indicadores son variables de manifiesto de un fenómeno subyacente -análogo al análisis factorial-. Sin embargo, gracias al desarrollo paralelo de los análisis factoriales confirmatorios (AFC), la TRI ha incorporado modelos multidimensionales. Aunque no hay restricciones por multidimensionalidad, es importante tener en mente que la TRI puede descansar en el supuesto de que la escala es homogénea -factor de alto orden- y que mientras exista un factor subyacente general, las conclusiones sobre discriminación y severidad no deberían cambiar sustancialmente. En esta sección nos enfocamos en la estimación de modelos basados en la TRI usando R y Mplus. Para ello, primero trabajaremos con los mismos datos que hemos venido utilizando en el capítulo “Rel_MD_1”. Comenzaremos con la estimación en R usando el paquete ltm, el cual permite estimar distintos tipos de modelos -unidimensionales- de TRI. La función ltm() estima modelos TRI de uno, dos y tres parámetros. A continuación, estimamos un modelo de dos parámetros usando los indicadores x1-x9 y añadiendo el parámetro de discriminación -recordemos que el modelo de un parámetro estima severidad/dificultad-. Los resultados muestran los coeficientes de los parámetros de severidad y dificultad. La dificultad representa la severidad (en desviaciones estándar) del factor subyacente. Por ejemplo, el ítem x1 es menos severo que el ítem x3. La segunda columna Dscrmn muestra los valores del parámetro de discriminación. Hay tanto discriminación positiva como negativa, en este caso como la privación esta codificada con 1 y la no privación con 0, esperamos que los coeficientes sean positivos. Todos los ítems tienen valores mayores a \\(&gt;.9\\), lo cual está por encima del umbral sugerido por Guio et al. (2016) and Nájera (2018). library(ltm) rel_irt&lt;-ltm(Rel_MD_1[,c(1:9)] ~ z1) rel_irt ## ## Call: ## ltm(formula = Rel_MD_1[, c(1:9)] ~ z1) ## ## Coefficients: ## Dffclt Dscrmn ## x1 0.023 2.290 ## x2 0.702 2.183 ## x3 1.258 2.198 ## x4 0.053 2.306 ## x5 0.698 2.368 ## x6 1.297 2.154 ## x7 0.160 2.541 ## x8 0.802 2.547 ## x9 1.236 2.477 ## ## Log.Lik: -20132.92 Antes de hace la estimación del mismo modelo con Mplus, mostraremos qué pasa cuando incluimos los ítems que afectan la confiabilidad de los scores. Lo que hacemos es reemplazar los ítems x1 y x2 por los ítems x10 Y X11. Como era de esperarse, los valores de discriminación son inaceptablemente bajos y los valores de severidad son muy altos (\\(\\geq3\\)). Si quisiéramos utilizar estos indicadores para predecir con confianza y cierta probabilidad quién es pobre y quién no lo es usando x10 o x11, encontraríamos que una persona con privación en x10 tiene la misma probabilidad de ser pobre de alguien que no la tiene. Esto, por supuesto, carece de sentido y utilidad en medición de pobreza. head(Rel_MD_1[,c(3:11)]) ## x3 x4 x5 x6 x7 x8 x9 x10 x11 ## 1 1 1 0 0 0 0 0 0 0 ## 2 0 0 0 0 0 0 0 0 0 ## 3 0 1 0 0 0 0 0 0 0 ## 4 0 0 0 0 1 0 0 0 0 ## 5 0 0 0 0 0 0 0 1 1 ## 6 0 0 0 0 0 0 0 0 0 rel_irt_2&lt;-ltm(Rel_MD_1[,c(3:11)] ~ z1) rel_irt_2 ## ## Call: ## ltm(formula = Rel_MD_1[, c(3:11)] ~ z1) ## ## Coefficients: ## Dffclt Dscrmn ## x3 1.426 1.651 ## x4 0.053 2.371 ## x5 0.689 2.488 ## x6 1.279 2.245 ## x7 0.157 2.817 ## x8 0.780 2.840 ## x9 1.193 2.804 ## x10 5.142 0.133 ## x11 4.882 0.135 ## ## Log.Lik: -21740.2 3.6.4.2 Estimación en Mplus vía R En esta sección utilizaremos el paquete de R mplusAutomation (Hallquist &amp; Wiley, 2018). Este paquete de R traduce los scripts de R a archivos *.inp de Mplus. El primer paso consiste en especificar el modelo con la función mplusObject(). En este caso utilizaremos los ítems x1-x9. Especificamos un factor h con varianza 1. Vamos a guardar el modelo en el objeto test. test &lt;- mplusObject( TITLE = &quot;IRT model;&quot;, VARIABLE = &quot; NAMES = x1-x9 resources educ_yr occupation hh_size class; CATEGORICAL = x1-x9; USEVARIABLES = x1-x9;&quot;, ANALYSIS = &quot;ESTIMATOR = ml; PROCESS = 4;&quot;, MODEL = &quot;h by x1* x2-x9; h@1;&quot;) Para estimar el modelo utilizaremos la función mplusModeler(). Lo único que tenemos que hacer indicar el nombre del objeto (en este caso test). El nombre de nuestra sintaxis para este modelo es rel_IRT_1.inp y usaremos los datos Rel_MD_data_1_1.dat. La opción run sirve para indicar a Mplus que ejecute el modelo desde R. res &lt;- mplusModeler(test, modelout = &quot;rel_IRT_1.inp&quot;, writeData = &quot;never&quot;, hashfilename = FALSE, dataout=&quot;Rel_MD_data_1_1.dat&quot;, run = 1L) Después de ejecutar el modelo, podemos leer los resultados en R usando la función readModels(). Pedimos que guarde los resultados en el objeto REL_IRT_1. REL_IRT_1&lt;-readModels(filefilter =&quot;rel_IRT_1&quot;) La función readModels() extrae los resultados producidor por Mplus y los pone en listas. En este caso los resultados con la estimación de los dos parámetros se encuentran en REL_IRT_1\\(parameters\\)irt.parameterization. Después de hacer algunos ajustes, podemos ver que los resultados son similares a los del paquete ltm. rel_irt&lt;-REL_IRT_1$parameters$irt.parameterization rel_irt&lt;-rel_irt[1:18,] rel_irt&lt;-data.frame(a=rel_irt$est[1:9],b=rel_irt$est[10:18]) rel_irt ## a b ## 1 2.290 0.024 ## 2 2.192 0.700 ## 3 2.207 1.254 ## 4 2.312 0.054 ## 5 2.383 0.696 ## 6 2.172 1.291 ## 7 2.548 0.161 ## 8 2.561 0.800 ## 9 2.498 1.231 3.6.5 Confiabilidad por ítem: Evaluación multidimensional La confiabilidad por ítem se puede analizar tanto multidimensional como unidimensionalmente. Lo importante es tener en claro respecto a qué constructo se quieren examinar las propiedades del indicador de severidad y validez. En principio, estamos interesados en la relación de los indicadores con el factor general pero también es de interés revisar las propiedades que tiene el indicador respecto a la dimensión que pretende medir. Un modelo TRI multidimensional es muy similar a un MFC jerárquico con variables categóricas. Una forma de examinar la confiabilidad a nivel de ítem es examinando las cargas factoriales estandarizadas (similar, aunque bajo distinta parametrización, a la discriminación) y la ordenada al origen de cada indicador (similar, aunque bajo distinta parametrización, severidad). Para examinar la confiabilidad por ítem el primer paso es estimar un modelo factorial de alto orden (equivalente al modelo bi-factorial pero en este caso anidado). Después los valores de las cargas factoriales y el \\(R^2\\) de cada indicador (es decir, \\(\\lambda_{hj}^2\\)). \\(R^2\\leq.25\\) es la varianza explicada por el factor latente del indicador, que equivalente a \\(\\lambda_{hj}^2\\) cuando \\(\\lambda_{hj}\\leq.5\\). Estos umbrales son usados en la práctica para marcar cargas factoriales inaceptablemente bajas. Estos valores son equivalentes al umbral que se parámetro de discriminación \\(\\leq.9\\) en TRI. Los resultados para estos datos muestran que las cargas factoriales están por encima de los umbrales críticos para el parámetro de discriminación. MD_model &lt;- &#39; f1 =~ x1 + x2 + x3 f2 =~ x4 + x5 + x6 f3 =~ x7 + x8 + x9 h =~ f1 + f2 + f3 &#39; fit &lt;- sem(MD_model, data = Rel_MD_1, ordered=c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;, &quot;x6&quot;,&quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;)) inspect(fit,what=&quot;std&quot;)$lambda ## f1 f2 f3 h ## x1 0.924 0.000 0.000 0 ## x2 0.888 0.000 0.000 0 ## x3 0.873 0.000 0.000 0 ## x4 0.000 0.929 0.000 0 ## x5 0.000 0.917 0.000 0 ## x6 0.000 0.866 0.000 0 ## x7 0.000 0.000 0.947 0 ## x8 0.000 0.000 0.916 0 ## x9 0.000 0.000 0.894 0 3.7 Ejemplo con datos reales Utilizaremos datos de la medida oficial mexicana de pobreza multidimensional Mex_pobreza_14.dta. Esta base de datos contiene un subconjunto de indicadores de carencia/privación material para medir pobreza multidimensional en México. La medida oficial mexicana tiene dos dominios: ingreso y derechos sociales. El dominio de los derechos sociales tiene cinco dimensiones: servicios esenciales, vivienda, inseguridad alimentaria, seguridad social y educción. Alguna de estas dimensiones son medidas con un par de indicadores como educación y seguridad social. Esto pone limitaciones puesto que no se puede estimar un modelo no identificado. Por tanto, vamos a utilizar una versión reducida del modelo de CONEVAL con tres dimensiones: servicios, vivienda e inseguridad alimentaria. Los datos provienen de una muestra nacional representativa obtenida por muestre complejo. Utilizaremos el paquete de R survey (Lumley, 2016). Este paquete contiene distintas funciones para analizar datos provenientes de muestras complejas. Para producir la prevalencia de privación de diseño para cada uno de los 14 indicadores necesitamos especificar varias cosas. Primero, necesitamos identificar los factores de expansión y las unidades primarias de muestreo (UPMs). Para estos datos es necesario imponer la opción options(scipen=999, survey.lonely.psu=\"adjust\") para prevenir errores dado que en algunas PSUs hay sólo un hogar. Lo que haremos a continuación es especificar el diseño muestral en el objeto des. A este objeto es posible añadir estratos con la opción strata. Después de especificar las variables de diseño, podemos pedir las medias por indicador para obtener la prevalencia de privación por indicador con la función: svymean(). Para mostrar y discutir los resultados, redondeamos los porcentajes para facilitar la lectura -consideramos que es de poca utilidad tratar buscar precisión inexistente mediante el uso de decimales-. Podemos apreciar que los porcentajes de los indicadores de la dimensión de vivienda son muy bajos. Servicios esenciales presenta prevalencias mayores pero la carencia por electricidad es sumamente baja. También vemos que de las tres dimensiones la de alimentación presenta los porcentajes de carencia más altos en promedio. library(haven) Mex_D&lt;-read_dta(&quot;pobreza_14.dta&quot;) cols &lt;- c(&quot;icv_muros&quot;, &quot;icv_techos&quot;, &quot;icv_pisos&quot;, &quot;icv_hac&quot;, &quot;isb_agua&quot;,&quot;isb_dren&quot;, &quot;isb_luz&quot;, &quot;isb_combus&quot;, &quot;ic_sbv&quot;, &quot;ia_1ad&quot;, &quot;ia_2ad&quot;, &quot;ia_3ad&quot;, &quot;ia_4ad&quot;, &quot;ia_5ad&quot;, &quot;ia_6ad&quot;) library(survey) options(scipen=999, survey.lonely.psu=&quot;adjust&quot;) des &lt;- svydesign(data=Mex_D, id=~1, CLUSTER=~psu, weights=~weight) propr &lt;- data.frame(svymean(Mex_D[, cols],des,na.rm=T)) propr &lt;- round(propr*100,1) propr ## mean SE ## icv_muros 1.7 0.1 ## icv_techos 1.6 0.1 ## icv_pisos 3.0 0.1 ## icv_hac 5.6 0.1 ## isb_agua 7.7 0.1 ## isb_dren 7.5 0.1 ## isb_luz 0.8 0.0 ## isb_combus 12.0 0.2 ## ic_sbv 19.6 0.2 ## ia_1ad 33.3 0.3 ## ia_2ad 15.9 0.2 ## ia_3ad 24.9 0.2 ## ia_4ad 14.0 0.2 ## ia_5ad 16.4 0.2 ## ia_6ad 12.3 0.2 3.7.1 Análisis global de confiabilidad Una vez que estamos familiarizados con los 14 indicadores de privación, podemos estimar los estadísticos de confiabilidad. Es posible hacer estimaciones con lavaan.survey() (???). En este caso, estimaremos el modelo en Mplus para incorporar el diseño de la encuesta en cuestión en la estimación de los parámetros. Al igual que en los ejercicio con datos simulados, lo primero que tenemos que hacer es crear el input para Mplus desde R con la función mplusObject() del paquete mplusAutomation (Hallquist &amp; Wiley, 2018). En el objeto test especificamos un modelo bi-factorial con tres dimensiones y un factor general. Esto siguiendo nuestro modelo teórico donde vivienda (f1), servicios esenciales (2) e inseguridad alimentaria (3) y el factor de alto orden es (h). Posteriormente usamos la función mplusModeler() (esto generará el archivo de Mplus rel_CFA_mex.inp). Finalmente leemos los resultados con readModels() y guardamos todo en el objeto REL_CFA_mex. test &lt;- mplusObject( TITLE = &quot;Bi-factor model CFA;&quot;, VARIABLE = &quot; NAMES = proyecto folioviv foliohog icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ic_sbv ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad ia_7men ia_8men ia_9men ia_10men ia_11men ia_12men tv_dep radio_dep fridge_dep washingmach_dep compu_dep inter_dep psu weight rururb tot_integ durables educ_hh; MISSING=.; CATEGORICAL = icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; USEVARIABLES = icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; WEIGHT=weight; cluster = psu;&quot;, ANALYSIS = &quot;TYPE = complex; ESTIMATOR = wlsmv; PROCESS = 4;&quot;, MODEL = &quot;f1 by icv_muros icv_techos icv_pisos icv_hac; f2 by isb_agua isb_dren isb_luz isb_combus; f3 by ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; h by icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; F1 with F2@0; F2 with F3@0; F3 with F1@0; h with f1@0; h with f2@0; h with f3@0;&quot;, OUTPUT = &quot;std stdyx;&quot;) mplusModeler(test, modelout = &quot;rel_CFA_mex.inp&quot;, writeData = &quot;never&quot;, hashfilename = FALSE, dataout=&quot;Mex_pobreza_14.dat&quot;, run = 1L) REL_CFA_mex&lt;-readModels(&quot;rel_CFA_mex.out&quot;) Con los resultados del modelo podemos estimar \\(\\omega\\) y \\(\\omega_h\\)11 Para estimar confiabilidad utilizaremos el script de R utilizado en secciones anteriores. Esto implica obtener las cargas factoriales y los errores de cada indicador. Tomaremos el cuadrado de la sumatoria de las lambdas y la suma del error. Esto es, seguimos las fórmulas de las ecuaciones (3.9) y (3.10). Tanto \\(\\omega\\) y \\(\\omega_h\\) son altos (.97 y .81, respectivamente) y por encima de los valores críticos recomendados (Nájera, 2018). Estos resultados sugieren que la escala es homogénea y multidimensional (\\(\\omega_h&lt;\\omega\\)). lambdas&lt;-REL_CFA_mex$parameters$std.standardized[1:28,1:3] error&lt;-REL_CFA_mex$parameters$r2[6] lambda_2&lt;-sum(lambdas[10:28,3])^2 + sum(lambdas[1:4,3])^2 + sum(lambdas[5:8,3])^2 + sum(lambdas[9:14,3])^2 error &lt;- sum(error) omega_t &lt;- lambda_2 / (lambda_2+error) omega_h &lt;- sum(lambdas[10:28,3])^2 / (lambda_2+error) omega_t ## [1] 0.9730641 omega_h ## [1] 0.8058398 3.7.2 Confiabilidad por ítem La confiabilidad global de la medida mexicana es alta. Ahora podemos analizar la confiabilidad por ítem de manera multidimensional mediante el cálculo de las cargas factoriales de un modelo jerárquico. Lo que tenemos que hacer es reescribir nuestro modelo anterior para representar un modelo donde las dimensiones cargan en un sólo factor. Esto puede hacerse simplemente mediante la especificación de un modelo donde la dimensión general h comprende tres dimensiones (f1, f2 y f3) y cada dimensión tiene distintos indicadores. Para ello especificamos la estructura del modelo usando la función mplusObject(). Esto generará el archivo *.inp de Mplus y después podemos ejecutar el modelo desde R con la función mplusModeler(). test &lt;- mplusObject( TITLE = &quot;CFA higher order model CFA;&quot;, VARIABLE = &quot; NAMES = proyecto folioviv foliohog icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ic_sbv ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad ia_7men ia_8men ia_9men ia_10men ia_11men ia_12men tv_dep radio_dep fridge_dep washingmach_dep compu_dep inter_dep psu weight rururb tot_integ; MISSING=.; CATEGORICAL = icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; USEVARIABLES = icv_muros icv_techos icv_pisos icv_hac isb_agua isb_dren isb_luz isb_combus ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; WEIGHT=weight; cluster = psu;&quot;, ANALYSIS = &quot;TYPE = complex; ESTIMATOR = wlsmv; PROCESS = 4;&quot;, MODEL = &quot;f1 by icv_muros icv_techos icv_pisos icv_hac; f2 by isb_agua isb_dren isb_luz isb_combus; f3 by ia_1ad ia_2ad ia_3ad ia_4ad ia_5ad ia_6ad; h by f1 f2 f3;&quot;, OUTPUT = &quot;std stdyx;&quot;) mplusModeler(test, modelout = &quot;rel_CFA_mex2.inp&quot;, writeData = &quot;never&quot;, hashfilename = FALSE, dataout=&quot;Mex_pobreza_14.dat&quot;, run = 1L) Ahora podemos pedir las cargas factoriales estandarizadas e inspeccionar sus valores usando la función readModels(). Para facilitar la interpretación, podemos graficar las cargas factoriales estandarizadas (Figure 3.1. Vemos que todos los indicadores tienen muy altas cargas factoriales y que están por arriba del umbral sugerido (\\(\\lambda_ij&gt;.5\\)). Esto significa que estos indicadores discriminan bien y que individualmente contribuyen a la confiabilidad de los scores. Podemos ver, sin embargo, que los indicadores de vivienda tienden a tener valores bajos. Esto puede ser una indicación de que estos indicadores están perdiendo poder discriminatorio -esto tal vez por cambios en nivel de vida y que la medida mexicana necesita actualizarse. REL_CFA_mex2&lt;-readModels(&quot;rel_CFA_mex2.out&quot;) modelParams&lt;- REL_CFA_mex2$parameters$std.standardized[1:14,] modelParams &lt;- subset(modelParams, select=c(&quot;paramHeader&quot;, &quot;param&quot;, &quot;est&quot;, &quot;se&quot;)) library(ggplot2) limits &lt;- aes(ymax = est + se, ymin=est - se) ggplot(modelParams, aes(x=param, y=est)) + geom_pointrange(limits) +scale_x_discrete(&quot;&quot;) + geom_hline(yintercept=0, color=&quot;grey50&quot;) + theme_bw() +ylab(&quot;Std Loading&quot;) + coord_flip() Figure 3.1: Esta gráfica muestra las cargas factoriales estandarizadas de los 14 ítems 3.8 Temas avananzados: Clasificación poblacional y pesos El principio de confiabilidad tiene diferentes implicaciones en medición. Una forma de entender los efectos de la confiabilidad en nuestras mediciones es mediante experimentación. Si uno de los intereses principales de la confiabilidad es la clasificación poblacional, podemos observar qué pasa con la consistencia del orden de los individuos en nuestra muestra ante cambios en indicadores y valores globales de confiabilidad. En medición de pobreza hay dos aspectos que ameritan atención. El primero, es la relación entre el score de privación observado y confiabilidad. El segundo, es la relación que tiene la confiabilidad de ítem con los pesos que se asignan a los indicadores. Exploraremos ambos casos vía experimentación a continuación. 3.8.1 Clasificación poblacional y confiabilidad Una de las predicciones de la teoría de la medición es que la confiabilidad lleva a ordenamientos consistentes poblacionales, i.e. la gente pobre tendrá altos valores observados de privación y los no pobres tendrán bajos scores de privación (see Table (3.2). Para ilustrar esta relación vamos a utilizar post-estimación de variables latentes. Por tanto, tenemos que calcular el score observado de privación y el score latente. Primero calcularemos el score observado o severidad observada. Una de las medidas clásicas para medir la severidad de privación es el score de Townsend, que es el conteo de carencias. Considerando los datos Rel_MD_1 mostramos el score de privación a continuación. Nuevamente, abrimos nuestros datos guardados en el archivo “Rel_MD_data_1_1.dat”. library(plyr) Rel_MD_2&lt;-read.table(&quot;Rel_MD_data_2_1.dat&quot;) colnames(Rel_MD_2)&lt;-c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;,&quot;x6&quot;, &quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;,&quot;x10&quot;,&quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;resources&quot;,&quot;educ_yr&quot;,&quot;occupation&quot;,&quot;hh_members&quot;,&quot;class&quot;) str(Rel_MD_2) ## &#39;data.frame&#39;: 5000 obs. of 20 variables: ## $ x1 : num 1 0 1 1 0 1 0 0 0 0 ... ## $ x2 : num 1 0 1 0 0 1 0 0 0 0 ... ## $ x3 : num 1 0 1 0 0 0 0 0 1 0 ... ## $ x4 : num 1 0 1 1 0 1 1 0 1 0 ... ## $ x5 : num 0 0 1 1 0 1 1 0 1 0 ... ## $ x6 : num 0 0 1 0 0 0 1 0 1 0 ... ## $ x7 : num 0 0 1 0 0 1 0 0 1 0 ... ## $ x8 : num 0 0 0 1 0 0 0 0 1 0 ... ## $ x9 : num 0 0 0 0 0 0 0 0 1 0 ... ## $ x10 : num 0 0 0 1 0 0 0 0 0 0 ... ## $ x11 : num 0 1 0 1 0 0 0 0 0 0 ... ## $ x12 : num 0 0 0 0 0 0 1 0 0 0 ... ## $ x13 : num 0 0 0 1 0 0 0 1 1 0 ... ## $ x14 : num 0 1 0 0 0 1 0 1 1 0 ... ## $ x15 : num 1 0 0 0 0 1 0 0 0 0 ... ## $ resources : num 3277 3954 3749 1574 4751 ... ## $ educ_yr : num 6.32 11.04 4.12 6.32 12.33 ... ## $ occupation: num 4.36 3.58 8.33 2.24 2.59 ... ## $ hh_members: num 5.44 0.458 2.787 6.949 2.386 ... ## $ class : int 2 2 2 2 1 2 2 1 1 2 ... Para obtener el score de privación simplemente sumamos los primeros nueve indicadores. En este caso altos scores observados indican alta severidad de privación y pobreza. Rel_MD_2$ds&lt;-rowSums(Rel_MD_2[,c(1:9)]) Podemos graficar la distribución de nuestro score de privación de la manera siguiente (Figura 3.2): require(ggplot2) ggplot(Rel_MD_2, aes(ds)) + geom_histogram() + theme_bw() + labs(x = &quot;Deprivation score&quot;) + scale_x_continuous(breaks = seq(0, 9, by = 1)) Figure 3.2: This is the histogram of the deprivation score. It shows the number of people by the equally weighted deprivation count. El cálculo del score latente requiere post-estimación. Esto significa estimar el valor de pobreza latente (i.e. el del factor) para cada persona en la muestra usando los datos (Rel_MD_1). Primero especificamos el modelo bi-factorial: library(lavaan) MD_model &lt;- &#39; h =~ +x1+x2+x3+x4+x5+x6+x7+x8+x9 F1=~ + x7 + x8 + x9 F2=~ + x4 + x5 + x6 F3=~ + x1 + x2 + x3 h ~~ 0*F1 h ~~ 0*F2 h ~~ 0*F3 F1 ~~ 0*F2 F2 ~~ 0*F3 F1 ~~ 0*F3 &#39; Para estimar el modelo confirmatorio usaremos la función sem() la cual es una función general que comprende cfa y lavaan (ambas pueden usarse). Es muy importante tener en mente que las variables de nuestra medición son categóricas, por tanto tenemos que incluir la opción ordered() y pediremos que lavaan incluya cargas factoriales estandarizadas con el comando std.lv=TRUE. Guardaremos nuestros resultados en el objeto fit. fit &lt;- sem(MD_model, data = Rel_MD_2, ordered=c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;, &quot;x6&quot;,&quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;), std.lv=TRUE) Lo que ahora tenemos que hacer es calcular el factor usando los resultados de nuestro objeto fit mediante la función predict() para obtener estimaciones basados en Máxima Verosimilitud de la variable latente. Después simplemente podemos pegar estos valores con los de nuestra base de datos. La predicción genera cuatro estimaciones para la variable latente: factor general (h) y los valores para cada dimensión. factor_scores&lt;-predict(fit) Rel_MD_2&lt;-cbind(Rel_MD_2,factor_scores) head(Rel_MD_2[,c(22:25)]) ## h F1 F2 F3 ## 1 0.4538218 -0.822549923602 -0.1368005 1.1627338 ## 2 -0.6644685 -0.086343939586 -0.1587308 -0.1357508 ## 3 1.1399555 -0.680186042882 0.7550983 0.6242101 ## 4 0.4574594 -0.000008713397 0.5554758 -0.2391126 ## 5 -0.6644685 -0.086343939586 -0.1587308 -0.1357508 ## 6 0.7277524 -0.281435486545 0.3040441 0.3303090 Para contrastar los valores latentes obtenidos de esta medición con los valores de una medición alternativa que produce scores no confiables, estimaremos otro modelo. Siguiendo el ejemplo previo (Section @ref(#Chapter-3-expoverel)), lo que haremos es reemplazar los indicadores x1 y x2 por los indicadores x10 y x11. Ambos los pondremos como variables de manifiesto del primer factor (f1). Guardaremos los resultados de la estimación en el objeto fit_ur y estimaremos los valores de la variable latente usando nuevamente la función predict(). Finalmente, inspeccionamos los valores. MD_model &lt;- &#39; h =~ +x11+x7+x10+x4+x5+x6+x3+x8+x9 F1=~ + x7 + x8 + x9 F2=~ + x4 + x5 + x6 F3=~ + x11 + x10 + x3 h ~~ 0*F1 h ~~ 0*F2 h ~~ 0*F3 F1 ~~ 0*F2 F2 ~~ 0*F3 F1 ~~ 0*F3 &#39; fit_ur &lt;- sem(MD_model, data = Rel_MD_2, ordered=c(&quot;x11&quot;,&quot;x13&quot;,&quot;x10&quot;,&quot;x4&quot;,&quot;x5&quot;,&quot;x6&quot;,&quot;x3&quot;,&quot;x8&quot;,&quot;x9&quot;), std.lv=TRUE) factor_scores_ur&lt;-predict(fit_ur) colnames(factor_scores_ur)[1:4]&lt;-c(&quot;hur&quot;,&quot;F1ur&quot;,&quot;F2ur&quot;,&quot;F3ur&quot;) Rel_MD_2&lt;-cbind(Rel_MD_2,factor_scores_ur) head(Rel_MD_2[,c(26:29)]) ## hur F1ur F2ur F3ur ## 1 0.5284583 -0.9239858 -0.1932797 0.099658014 ## 2 -0.6194308 -0.3597970 -0.1874615 0.120171332 ## 3 1.0242506 -0.3115984 0.8560178 -0.003350756 ## 4 0.7873244 -0.3003439 0.2605288 0.301053386 ## 5 -0.6622207 -0.3403600 -0.1685598 -0.209509151 ## 6 0.3843159 0.2368446 0.6203767 -0.277058191 Para contrastar la consistencia que arrojan ambas escalas, graficaremos los valores latentes contra los scores observados de privación. La Figura 3.3 muestra que el valor latente de privación son muy similares dentro de cada grupo. Este es el tipo de comportamiento que queremos ver. También observamos que para cada score observado vemos valores latentes muy distintos (no hay traslapes entre las cajas de dispersión), indicando que el score observado es efectivamente una buena manera para ordenar y dividir a la población según nivel de severidad de privación. require(ggplot2) g &lt;- ggplot(Rel_MD_2, aes(as.factor(ds), h)) g + geom_boxplot(varwidth=T) + labs(x=&quot;Deprivation score. Reliable&quot;, y=&quot;Factor score (Latent variable)&quot;) + theme_bw() Figure 3.3: Relationship between the deprivation score (x1-x9) and the latent variable score. We appreciate the narrowness of the box plots, indicating good group separation. En contraste, la Figura 3.4 muestra que aunque hay una relación entre el score observado y el latente, la asociación tiene mucho más ruido. No solo hay mayor variabilidad dentro de cada grupo (privación observada) sino que hay traslapes entre grupos. Si trazáramos una línea horizontal para dividir a la población, tendríamos mayor error en la identificación de grupos. Esto significa que, si usamos algún umbral para distinguir al grupo pobre del no pobre usando el score de privación, vamos a tener una probabilidad más alta de confundir a un grupo con el otro. En este caso la mezcla de grupos no es tan dramática, pero recordemos que el valor de confiabilidad es bastante alto. Rel_MD_2$ds_ur&lt;-rowSums(Rel_MD_2[,(3:11)]) g &lt;- ggplot(Rel_MD_2, aes(as.factor(ds_ur), hur)) g + geom_boxplot(varwidth=T) + labs(x=&quot;Deprivation score. Unreliable&quot;, y=&quot;Factor score (Latent variable)&quot;) + theme_bw() Figure 3.4: Relationship between the deprivation score (x10, x11 and x3-x9) and the latent variable score. There is more variability in this case indicating poor group separation. 3.8.2 Pesos, confiabilidad y clasificación poblacional La primera predicción de la teoría de la confiabilidad es que los ordenamientos de la población son consistentes para valores altos de confiabilidad. Esto tiene una relación muy estrecha con los pesos porque éstos afectan la contribución relativa que cada indicador tiene al score observado de privación. Para entender la relación entre estos tres grandes temas (confiabilidad, pesos y clasificación poblacional) veremos desde otro ángulo la relación entre confiabilidad y scores observados de privación. Una manera de checar esto es estimando la correlación de los scores observados de privación para cada uno de los casos especiales que usamos previamente (omega_exp1-5). ¿Qué es el score de privación? Hemos hablado que el score de privación en medición multidimensional es la suma ponderada (diferencial o no diferencialmente) de las privaciones observadas. Esta es una medida inventada por Townsend de severidad de privación. Entre más alto el score, mayor la severidad de privación material y social y pobreza. El cálculo que haremos a continuación se basa en pesos no diferenciales -como mencionamos, aunque lo vamos a demostrar a más adelante, la confiabilidad es una precondición para buena clasificación y los pesos no-. El score de privación se obtiene con la suma de los indicadores de carencia con la función rowSums. Haremos esto para la medida perfecta que se compone de los indicadores x1-x9. library(plyr) Rel_MD_2&lt;-read.table(&quot;Rel_MD_data_2_1.dat&quot;) colnames(Rel_MD_2)&lt;-c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;,&quot;x6&quot;, &quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;,&quot;x10&quot;,&quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;resources&quot;,&quot;educ_yr&quot;,&quot;occupation&quot;,&quot;hh_members&quot;,&quot;class&quot;) str(Rel_MD_2) ## &#39;data.frame&#39;: 5000 obs. of 20 variables: ## $ x1 : num 1 0 1 1 0 1 0 0 0 0 ... ## $ x2 : num 1 0 1 0 0 1 0 0 0 0 ... ## $ x3 : num 1 0 1 0 0 0 0 0 1 0 ... ## $ x4 : num 1 0 1 1 0 1 1 0 1 0 ... ## $ x5 : num 0 0 1 1 0 1 1 0 1 0 ... ## $ x6 : num 0 0 1 0 0 0 1 0 1 0 ... ## $ x7 : num 0 0 1 0 0 1 0 0 1 0 ... ## $ x8 : num 0 0 0 1 0 0 0 0 1 0 ... ## $ x9 : num 0 0 0 0 0 0 0 0 1 0 ... ## $ x10 : num 0 0 0 1 0 0 0 0 0 0 ... ## $ x11 : num 0 1 0 1 0 0 0 0 0 0 ... ## $ x12 : num 0 0 0 0 0 0 1 0 0 0 ... ## $ x13 : num 0 0 0 1 0 0 0 1 1 0 ... ## $ x14 : num 0 1 0 0 0 1 0 1 1 0 ... ## $ x15 : num 1 0 0 0 0 1 0 0 0 0 ... ## $ resources : num 3277 3954 3749 1574 4751 ... ## $ educ_yr : num 6.32 11.04 4.12 6.32 12.33 ... ## $ occupation: num 4.36 3.58 8.33 2.24 2.59 ... ## $ hh_members: num 5.44 0.458 2.787 6.949 2.386 ... ## $ class : int 2 2 2 2 1 2 2 1 1 2 ... Rel_MD_2$ds&lt;-rowSums(Rel_MD_2[,c(1:9)]) Podemos graficar la distribución de nuestro score de privación de la manera siguiente (Figura 3.5): require(ggplot2) ggplot(Rel_MD_2, aes(ds)) + geom_histogram() + theme_bw() + labs(x = &quot;Deprivation score&quot;) + scale_x_continuous(breaks = seq(0, 9, by = 1)) Figure 3.5: This is the histogram of the deprivation score. It shows the number of people by the equally weighted deprivation count. Vemos que nuestro score de privación se ve desinflado a la derecha y inflado a la izquierda. Esta es normalmente la distribución que siguen este tipo de scores en la mayoría de sociedades donde la privación múltiple es baja. Esto luciría bastante distinto en un país en desarrollo donde la gente privación múltiple es mayor. Ahora tenemos los fundamentos para seguir nuestra exploración de la relación entre confiabilidad y diferentes scores de privación. Para ello, calcularemos los scores de privación correspondientes a cada una de las medidas anteriormente usadas (rowSums(Rel_MD_1[,c(3:9)] para el segundo índice, por ejemplo). Haremos esto para los cinco subconjuntos de que incluyen buenos indicadores y para dos casos que incluyen los ítems x10 y x11. Con estos scores, lo que tenemos es la severidad de privación observada para cada una de las personas en la muestra. Idealmente, esperaríamos que la población con baja severidad siempre tuviera baja severidad independientemente del subconjunto de indicadores utilizados. Una vez que cada persona tiene sus cinco scores de privación, podemos calcular la correlación entre todos estos scores para nuestra muestra. Lo que vemos es que efectivamente la teoría se sostiene. Las medidas con altos valores de \\(\\omega\\) tienen una correlación muy alta. La correlación de las medidas con baja confiabilidad es aún alta, pero se observa una caída (.93 y .87 cuando se empeora la medida). Por simulación, cuando \\(\\omega&lt;.8\\) podemos esperar tener un error de clasificación de \\(&gt;5\\%\\), lo cual es muy preocupado cuando se pone en perspectiva. Si la pobreza es \\(20\\%\\) y el error es \\(&gt;5\\%\\), esto significaría que el \\(25\\%\\) de la población pobre está incorrectamente clasificada (Nájera, 2018). library(psych) omega_expA&lt;-omega(Rel_MD_2[,c(3:9)]) omega_expB&lt;-omega(Rel_MD_2[,c(1,2,4,5,7,8,10)]) omega_expC&lt;-omega(Rel_MD_2[,c(2,3,5,6,8,9,11)]) omega_expD&lt;-omega(Rel_MD_2[,c(1,3,4,6,7,9,15)]) omega_expE&lt;-omega(Rel_MD_2[,c(3:7,10,11)]) omega_expF&lt;-omega(Rel_MD_2[,c(3,4,6,10,11,13,15)]) omega_expG&lt;-omega(Rel_MD_2[,c(2,3,5,6,10,11,15)]) omega_expH&lt;-omega(Rel_MD_2[,c(1,2,6,12,13,14,15)]) omegas_exp&lt;-data.frame(omega_expA=omega_expA$omega.tot, omega_expB=omega_expB$omega.tot, omega_expC=omega_expC$omega.tot, omega_expD=omega_expD$omega.tot, omega_expE=omega_expE$omega.tot, omega_expF=omega_expF$omega.tot, omega_expG=omega_expG$omega.tot, omega_expH=omega_expH$omega.tot) Rel_MD_2$ds_A&lt;-rowSums(Rel_MD_2[,c(3:9)]) Rel_MD_2$ds_B&lt;-rowSums(Rel_MD_2[,c(1,2,4,5,7,8,10)]) Rel_MD_2$ds_C&lt;-rowSums(Rel_MD_2[,c(2,3,5,6,8,9,11)]) Rel_MD_2$ds_D&lt;-rowSums(Rel_MD_2[,c(1,3,4,6,7,9,15)]) Rel_MD_2$ds_E&lt;-rowSums(Rel_MD_2[,c(3:7,10,11)]) Rel_MD_2$ds_F&lt;-rowSums(Rel_MD_2[,c(3,4,6,10,11,13,15)]) Rel_MD_2$ds_G&lt;-rowSums(Rel_MD_2[,c(2,3,5,6,10,11,15)]) Rel_MD_2$ds_H&lt;-rowSums(Rel_MD_2[,c(1,2,6,12,13,14,15)]) ds.m&lt;-(Rel_MD_2[,c(22:29)]) ds.cor&lt;-cor(ds.m) ds.cor ## ds_A ds_B ds_C ds_D ds_E ds_F ds_G ## ds_A 1.0000000 0.9071840 0.9039950 0.9221182 0.8880842 0.6555425 0.7252570 ## ds_B 0.9071840 1.0000000 0.8402092 0.8911441 0.8898064 0.6726461 0.7732807 ## ds_C 0.9039950 0.8402092 1.0000000 0.8343023 0.8597428 0.6951270 0.8511749 ## ds_D 0.9221182 0.8911441 0.8343023 1.0000000 0.8446652 0.7276591 0.7675723 ## ds_E 0.8880842 0.8898064 0.8597428 0.8446652 1.0000000 0.8280108 0.8705587 ## ds_F 0.6555425 0.6726461 0.6951270 0.7276591 0.8280108 1.0000000 0.8636952 ## ds_G 0.7252570 0.7732807 0.8511749 0.7675723 0.8705587 0.8636952 1.0000000 ## ds_H 0.6149739 0.6757374 0.6443922 0.7460731 0.5825212 0.6693941 0.6804597 ## ds_H ## ds_A 0.6149739 ## ds_B 0.6757374 ## ds_C 0.6443922 ## ds_D 0.7460731 ## ds_E 0.5825212 ## ds_F 0.6693941 ## ds_G 0.6804597 ## ds_H 1.0000000 3.8.3 Impacto de la confiabilidad y pesos en la identificación de grupos En esta sección exploraremos el impacto que tiene la baja y alta confiabilidad cuando se utilizan pesos diferenciales. Lo primero que tenemos que hacer es crear una función que estima parcialmente el método de Alkire y Foster. La función estima el score de privación ponderado, la prevalencia de pobreza para un determinado umbral, calcula la intensidad de la pobreza y el valor omega exploratorio. AF&lt;-function(vars,weights,cutoff,data){ data$score &lt;- rowSums(vars* weights) data$poor &lt;- ifelse(data$score &gt; cutoff,1,0) intensity&lt;-aggregate(data$score ~ data$poor, FUN=mean, data=data, na.rm=TRUE) poor &lt;- mean(data$poor,na.rm=TRUE) data omega&lt;-omega(vars) parms&lt;-list(H=prop.table(table(data$poor)), M0=poor*intensity[2,2], omega=omega$omega.tot, DT=data) return(parms) } Ahora creamos una función ws() que produce pesos aleatorios con el fin de aplicar pesos aleatorios a nuestros indicadores y examinar la relación entre confiabilidad y pesos diferenciales. La función requiere simplemente especificar el número de indicadores, la media y desviación estándar. Hacemos un ajuste para que la función no tome valores negativos. A esta función le agregamos otra wstats que nos va a calcular algunos descriptivos de los pesos: mínimo, máximo y coeficiente de variación. Así, tendremos una idea de la variabilidad de los pesos. #Random weights ws&lt;-function(i,range1,range2){ w&lt;-rnorm(i,range1,range2) tw&lt;-rep(1/i,i) ws&lt;-w+tw ws[ws&lt;=0]&lt;-.01 ws&lt;-ws/sum(ws) ws } #Stats of dispersion of the weights wstats&lt;-function(vector,i){ maxdis&lt;-(max(vector)/(1/i))-1 mindis&lt;-(min(vector)/(1/i))-1 cv&lt;-sd(vector)/mean(vector) parms&lt;-data.frame(mindis=mindis*100,maxdis=maxdis*100,CV=cv*100) return(parms) } Para el ejercicio utilizaremos los datos Rel_MD_2. Lo que haremos a continuación es calcular el método de agregación AF a distintas versiones de nuestra medida y aplicaremos distintos sets de pesos. Lo hacemos para siete variantes de la misma medida. Aplicamos nuestra función AF de la siguiente manera: library(plyr) Rel_MD_2&lt;-read.table(&quot;Rel_MD_data_2_1.dat&quot;) colnames(Rel_MD_2)&lt;-c(&quot;x1&quot;,&quot;x2&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;,&quot;x6&quot;, &quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;,&quot;x10&quot;,&quot;x11&quot;, &quot;x12&quot;, &quot;x13&quot;, &quot;x14&quot;, &quot;x15&quot;, &quot;resources&quot;,&quot;educ_yr&quot;,&quot;occupation&quot;,&quot;hh_members&quot;,&quot;class&quot;) str(Rel_MD_2) ## &#39;data.frame&#39;: 5000 obs. of 20 variables: ## $ x1 : num 1 0 1 1 0 1 0 0 0 0 ... ## $ x2 : num 1 0 1 0 0 1 0 0 0 0 ... ## $ x3 : num 1 0 1 0 0 0 0 0 1 0 ... ## $ x4 : num 1 0 1 1 0 1 1 0 1 0 ... ## $ x5 : num 0 0 1 1 0 1 1 0 1 0 ... ## $ x6 : num 0 0 1 0 0 0 1 0 1 0 ... ## $ x7 : num 0 0 1 0 0 1 0 0 1 0 ... ## $ x8 : num 0 0 0 1 0 0 0 0 1 0 ... ## $ x9 : num 0 0 0 0 0 0 0 0 1 0 ... ## $ x10 : num 0 0 0 1 0 0 0 0 0 0 ... ## $ x11 : num 0 1 0 1 0 0 0 0 0 0 ... ## $ x12 : num 0 0 0 0 0 0 1 0 0 0 ... ## $ x13 : num 0 0 0 1 0 0 0 1 1 0 ... ## $ x14 : num 0 1 0 0 0 1 0 1 1 0 ... ## $ x15 : num 1 0 0 0 0 1 0 0 0 0 ... ## $ resources : num 3277 3954 3749 1574 4751 ... ## $ educ_yr : num 6.32 11.04 4.12 6.32 12.33 ... ## $ occupation: num 4.36 3.58 8.33 2.24 2.59 ... ## $ hh_members: num 5.44 0.458 2.787 6.949 2.386 ... ## $ class : int 2 2 2 2 1 2 2 1 1 2 ... AF1&lt;-AF(Rel_MD_2[,c(1:9)],rep(1/9,9),.33,Rel_MD_2) AF2&lt;-AF(Rel_MD_2[,c(3:9)],ws(9,.1,.05),.33,Rel_MD_2) AF3&lt;-AF(Rel_MD_2[,c(1,2,4,5,7,8,10)],ws(9,.1,.05),.33,Rel_MD_2) AF4&lt;-AF(Rel_MD_2[,c(2,3,5,6,8,9,11)],ws(9,.1,.05),.33,Rel_MD_2) AF5&lt;-AF(Rel_MD_2[,c(1,3,4,6,7,9,15)],ws(9,.1,.05),.33,Rel_MD_2) AF6&lt;-AF(Rel_MD_2[,c(3:7,10,11)],ws(9,.1,.05),.33,Rel_MD_2) AF7&lt;-AF(Rel_MD_2[,c(3,4,6,10,11,13,15)],ws(9,.1,.05),.33,Rel_MD_2) AF8&lt;-AF(Rel_MD_2[,c(1,2,6,12,13,14,15)],ws(9,.1,.05),.33,Rel_MD_2) Posteriormente calculamos los estadísticos de los pesos para tener una idea de qué tanta variación tiene este set. wstats(ws(9,.1,.05),9) ## mindis maxdis CV ## 1 -36.78837 36.11696 21.2419 A continuación, inspeccionamos dos tipos de correlación. El primero, es la correlación de la identificación del grupo pobre y no pobre. Es decir, la relación de personas que son siempre clasificadas como pobres a pesar de cambios en los pesos. El segundo tipo de correlación es la asociación entre los scores de privación. Esta correlación debe ser mayor a la primera puesto que estamos clasificando a la población por severidad/ranking y no estatus. respoor&lt;-cbind(AF1$DT$poor,AF2$DT$poor,AF3$DT$poor,AF4$DT$poor,AF5$DT$poor,AF6$DT$poor,AF7$DT$poor,AF8$DT$poor) resscore&lt;-cbind(AF1$DT$score,AF2$DT$score,AF3$DT$score,AF4$DT$score,AF5$DT$score,AF6$DT$score,AF7$DT$score,AF8$DT$poor) cor(respoor) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] ## [1,] 1.0000000 0.6996650 0.8518641 0.5753275 0.7366315 0.6768031 0.4278342 ## [2,] 0.6996650 1.0000000 0.6983723 0.7114592 0.7356076 0.7042638 0.4420508 ## [3,] 0.8518641 0.6983723 1.0000000 0.5826717 0.7043303 0.6893627 0.4189516 ## [4,] 0.5753275 0.7114592 0.5826717 1.0000000 0.6268714 0.6240975 0.4834137 ## [5,] 0.7366315 0.7356076 0.7043303 0.6268714 1.0000000 0.6575073 0.4795138 ## [6,] 0.6768031 0.7042638 0.6893627 0.6240975 0.6575073 1.0000000 0.5577133 ## [7,] 0.4278342 0.4420508 0.4189516 0.4834137 0.4795138 0.5577133 1.0000000 ## [8,] 0.4704555 0.4251972 0.4682452 0.4548130 0.4997914 0.4185620 0.4716692 ## [,8] ## [1,] 0.4704555 ## [2,] 0.4251972 ## [3,] 0.4682452 ## [4,] 0.4548130 ## [5,] 0.4997914 ## [6,] 0.4185620 ## [7,] 0.4716692 ## [8,] 1.0000000 cor(resscore) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] ## [1,] 1.0000000 0.9633220 0.9502744 0.9088917 0.9334140 0.8679407 0.6347491 ## [2,] 0.9633220 1.0000000 0.8994348 0.8903116 0.9042885 0.8769793 0.6249150 ## [3,] 0.9502744 0.8994348 1.0000000 0.8273972 0.8781475 0.8791887 0.6476166 ## [4,] 0.9088917 0.8903116 0.8273972 1.0000000 0.8057255 0.8426331 0.6690676 ## [5,] 0.9334140 0.9042885 0.8781475 0.8057255 1.0000000 0.8311809 0.6977205 ## [6,] 0.8679407 0.8769793 0.8791887 0.8426331 0.8311809 1.0000000 0.7914399 ## [7,] 0.6347491 0.6249150 0.6476166 0.6690676 0.6977205 0.7914399 1.0000000 ## [8,] 0.5678895 0.4930254 0.5370529 0.5206507 0.5844261 0.4814867 0.5273895 ## [,8] ## [1,] 0.5678895 ## [2,] 0.4930254 ## [3,] 0.5370529 ## [4,] 0.5206507 ## [5,] 0.5844261 ## [6,] 0.4814867 ## [7,] 0.5273895 ## [8,] 1.0000000 Para apreciar la relación entre confiabilidad global y el efecto de los pesos podemos solicitar lo siguiente. Observamos que para valores de confiabilidad sustancialmente menores a \\(\\omega=.8\\) la correlación cae dramáticamente: omegas&lt;-rbind(AF1$omega,AF2$omega,AF3$omega,AF4$omega,AF5$omega,AF6$omega,AF7$omega,AF8$omega) relation&lt;-cbind(omegas,cor(resscore)[,1]) 3.8.4 Error promedio simulado con pesos Una limitación de los resultados de la sección anterior es que muestran el efecto de distintos sets de pesos para distintas medidas usando una variante. Recordemos que la función rnorm() elige un set de pesos, i.e. una muestra. Aunque esto es útil, es importante ver que pasa cuando se usan variantes de la distribución posible de pesos dada una media y una desviación estándar. A continuación, haremos un ejercicio similar pero con repeticiones. Lo primero que haremos es mostrar lo que pasa cuando asignamos distintos subconjuntos de pesos a una medida confiable. Esto nos permitirá tener una conclusión más robusta sobre la relación entre confiabilidad y pesos. Lo que haremos es aplicar cuatro subconjuntos de pesos con 100 repeticiones a los scores confiables obtenidos a partir de los indicadores x1-x9 de la base Rel_MD_2. Los subconjuntos van de menor a mayor variabilidad comenzando por el caso de pesos iguales o no diferenciales. reps &lt;- 100 set.seed(0) system.time( AF1&lt;-replicate(reps,AF(Rel_MD_2[,c(1:9)],rep(1/9,9),.33,Rel_MD_2)) ) ## user system elapsed ## 8.81 1.07 10.56 reps &lt;- 100 set.seed(0) system.time( AF2&lt;-replicate(reps,AF(Rel_MD_2[,c(1:9)],ws(9,.1,.025),.33,Rel_MD_2)) ) ## user system elapsed ## 9.10 0.84 10.37 reps &lt;- 100 set.seed(0) system.time( AF3&lt;-replicate(reps,AF(Rel_MD_2[,c(1:9)],ws(9,.1,.05),.33,Rel_MD_2)) ) ## user system elapsed ## 8.86 0.98 10.38 reps &lt;- 100 set.seed(0) system.time( AF4&lt;-replicate(reps,AF(Rel_MD_2[,c(1:9)],ws(9,.1,.075),.33,Rel_MD_2)) ) ## user system elapsed ## 8.86 1.11 10.42 Ahora tenemos cuatro listas con 400 elementos. Lo que queremos saber es la correlación promedio entre el ranking bajo el score observado sin ponderar con el ranking con ponderación. Para ello necesitamos agrupar las listas de la siguiente manera. Por ejemplo, el objeto poorlist4 es una base de datos con los scores y la identificación pobre no pobre (con \\(k=33%\\)) para todas las repeticiones de AF4. poorlist1&lt;-AF1[c(seq(4,300,by=4))] poorlist2&lt;-AF2[c(seq(4,300,by=4))] poorlist3&lt;-AF3[c(seq(4,300,by=4))] poorlist4&lt;-AF4[c(seq(4,300,by=4))] poorlist1&lt;-do.call(rbind, poorlist1) poorlist2&lt;-do.call(rbind, poorlist2) poorlist3&lt;-do.call(rbind, poorlist3) poorlist4&lt;-do.call(rbind, poorlist4) Lo que tenemos que hacer ahora es calcular la correlación para cada uno de los cuatro grandes grupos de pesos. Dpoor&lt;-as.data.frame(cbind(poorlist1$poor,poorlist2$poor,poorlist3$poor,poorlist4$poor)) Dscore&lt;-cbind(poorlist1$score,poorlist2$score,poorlist3$score,poorlist4$poor) cor(Dpoor, method=&quot;spearman&quot;) ## V1 V2 V3 V4 ## V1 1.0000000 0.9195361 0.9115296 0.9016705 ## V2 0.9195361 1.0000000 0.9913500 0.9811446 ## V3 0.9115296 0.9913500 1.0000000 0.9896592 ## V4 0.9016705 0.9811446 0.9896592 1.0000000 cor(Dscore, method=&quot;spearman&quot;) ## [,1] [,2] [,3] [,4] ## [1,] 1.0000000 0.9965751 0.9958312 0.8531356 ## [2,] 0.9965751 1.0000000 0.9998718 0.8600837 ## [3,] 0.9958312 0.9998718 1.0000000 0.8608680 ## [4,] 0.8531356 0.8600837 0.8608680 1.0000000 Vemos que, efectivamente, para el caso de scores con alta confiabilidad, cambios pequeños y moderados en los pesos resultan en pérdidas marginales en el ordenamiento y clasificación de la población. También observamos que la relación entre pesos diferenciales y pesos no diferenciales -moderados- es casi perfecta. Esto, precisamente, es una de las predicciones de la teoría detrás del principio de confiabilidad (Streiner et al., 2015, p. @Najera2018). Para cambios sustantivos en los pesos vemos una pérdida más fuerte. Para entender un poco mejor qué fue lo que ocurrió podemos verificar los valores que toma uno de los casos especiales de pesos con desviación igual a .075. Hay variables que tienen un peso seis veces mayor, lo cual es difícil -aunque no imposible- de ver en la práctica. ws(9,.1,.075) ## [1] 0.09879470 0.10861187 0.12900773 0.12355672 0.20538158 0.10997881 ## [7] 0.09181357 0.05225118 0.08060384 3.8.4.1 Error promedio simulado con pesos: Baja confiabilidad Hemos visto que hay una clara relación entre alta confiabilidad y el grado de sensibilidad a los pesos- alta confiabilidad reduce el efecto de los pesos sobre el ordenamiento de la población. Ahora vamos a revisar la misma relación, pero para el caso de una medida con baja confiabilidad. En este caso usaremos los indicadores x4-x12 y los compararemos con nuestro estándar de oro que es la medida x1-x9. Este segundo set de indicadores resulta en una confiabilidad igual a \\(\\omega=.77\\)- aún alto. reps &lt;- 100 set.seed(0) system.time( AF1&lt;-replicate(reps,AF(Rel_MD_2[,c(1:9)],rep(1/9,9),.33,Rel_MD_2)) ) ## user system elapsed ## 8.98 0.95 10.33 reps &lt;- 100 set.seed(0) system.time( AF2&lt;-replicate(reps,AF(Rel_MD_2[,c(4:12)],ws(9,.1,.025),.33,Rel_MD_2)) ) ## user system elapsed ## 9.20 0.95 10.52 reps &lt;- 100 set.seed(0) system.time( AF3&lt;-replicate(reps,AF(Rel_MD_2[,c(4:12)],ws(9,.1,.05),.33,Rel_MD_2)) ) ## user system elapsed ## 9.19 0.97 10.50 reps &lt;- 100 set.seed(0) system.time( AF4&lt;-replicate(reps,AF(Rel_MD_2[,c(4:12)],ws(9,.1,.075),.33,Rel_MD_2)) ) ## user system elapsed ## 9.12 1.06 10.50 poorlist1&lt;-AF1[c(seq(4,300,by=4))] poorlist2&lt;-AF2[c(seq(4,300,by=4))] poorlist3&lt;-AF3[c(seq(4,300,by=4))] poorlist4&lt;-AF4[c(seq(4,300,by=4))] poorlist1&lt;-do.call(rbind, poorlist1) poorlist2&lt;-do.call(rbind, poorlist2) poorlist3&lt;-do.call(rbind, poorlist3) poorlist4&lt;-do.call(rbind, poorlist4) Dpoor&lt;-as.data.frame(cbind(poorlist1$poor,poorlist2$poor,poorlist3$poor,poorlist4$poor)) Dscore&lt;-cbind(poorlist1$score,poorlist2$score,poorlist3$score,poorlist4$poor) cor(Dpoor, method=&quot;spearman&quot;) ## V1 V2 V3 V4 ## V1 1.0000000 0.7281012 0.7259123 0.7185450 ## V2 0.7281012 1.0000000 0.9885491 0.9739881 ## V3 0.7259123 0.9885491 1.0000000 0.9851401 ## V4 0.7185450 0.9739881 0.9851401 1.0000000 cor(Dscore, method=&quot;spearman&quot;) ## [,1] [,2] [,3] [,4] ## [1,] 1.0000000 0.8565984 0.8548751 0.7584154 ## [2,] 0.8565984 1.0000000 0.9997265 0.8476754 ## [3,] 0.8548751 0.9997265 1.0000000 0.8491734 ## [4,] 0.7584154 0.8476754 0.8491734 1.0000000 Observamos la gran caída que tenemos en la correspondencia entre grupos. Hay una diferencia sustancial entre la identificación pobre y no pobre que obtenemos (de más del 25%) y también una diferencia importante respecto a al ordenamiento de nuestra población bajo el score de privación ideal y el ponderado con baja confiabilidad. 3.8.5 Monotonicidad y confiabilidad por ítem Hemos revisado la relación entre confiabilidad global, ordenamiento población y pesos diferenciales. Ahora vamos a inspeccionar la conexión entre el axioma de monotonicidad de Sen (1976) y la confiabilidad por ítem. Recordemos que el axioma de monotonicidad predice que caídas/aumentos en pobreza deben reflejar cambios en la misma dirección en carencia, i.e. aumento de pobreza debe reflejar un aumento de carencias observadas. Cargas factoriales con bajos valores indican que el indicador probablemente no es una manifestación del constructo en cuestión. Esto es, cambios en pobreza latente no resultan en cambios en privación. La sección 3.4 sugiere que hay una relación entre confiabilidad por ítem y el axioma de monotonicidad. Esta idea se ha explorado recientemente por Nájera (n.d.) y muestra que efectivamente bajas cargas factoriales -aproximadamente \\(\\leq.5\\)- llevan a violaciones del axioma de monotonicidad fuerte, i.e. una reducción en pobreza no refleja una mejora en la matriz de logros. Monotonicidad débil se viola cuando una mejora de pobreza resulta en un incremento de privación. Esto ocurriría cuando las cargas factoriales son negativas, por ejemplo. Para revisar cómo funciona operativamente esta relación entre confiabilidad de ítem y monotonicidad utilizaremos los datos Rel_MD_2 y estimaremos un modelo factorial jerárquico. Reemplazaremos los indicadores x10 y x11 por x1 y x2. MD_model &lt;- &#39; f1 =~ x10 + x11 + x3 f2 =~ x4 + x5 + x6 f3 =~ x7 + x8 + x9 h =~ f1 + f2 + f3 &#39; fit &lt;- sem(MD_model, data = Rel_MD_2, ordered=c(&quot;x10&quot;,&quot;x11&quot;,&quot;x3&quot;,&quot;x4&quot;,&quot;x5&quot;, &quot;x6&quot;,&quot;x7&quot;,&quot;x8&quot;,&quot;x9&quot;)) inspect(fit,what=&quot;std&quot;)$lambda ## f1 f2 f3 h ## x10 0.137 0.000 0.000 0 ## x11 0.077 0.000 0.000 0 ## x3 0.890 0.000 0.000 0 ## x4 0.000 0.936 0.000 0 ## x5 0.000 0.913 0.000 0 ## x6 0.000 0.871 0.000 0 ## x7 0.000 0.000 0.949 0 ## x8 0.000 0.000 0.912 0 ## x9 0.000 0.000 0.890 0 Las cargas factoriales de ambos indicadores son sumamente bajas -es posible también checar las \\(R^2\\) de cada indicador con la función summary(). Observamos de nuevo, como en los análisis de TRI, que los indicadores están muy débilmente relacionados con el factor. Estos ítems deberían excluirse del análisis porque aportan poca información sobre el constructo en cuestión. Esto podría implicar deshacerse de la primera dimensión en la ausencia de indicadores alternativos. 3.9 Comentarios finales En este capítulo revisamos la teoría, implementación e implicaciones para la medición del principio de confiabilidad. En ciencias sociales, tendemos a trabajar con conceptos que difícilmente pueden capturarse con una sola variable. Trabajamos con aproximaciones indirectas a los conceptos de interés. Creemos, entonces, en una teoría que predice que la pobreza resulta en ciertas manifestaciones y que usamos éstas últimas como una forma de aproximarnos a su medición. Este salto de la teoría del concepto a la medición de este ocurre en contextos de muy alta o baja incertidumbre y quisiéramos tener una forma de descifrar el ruido que tiene nuestros resultados. Confiabilidad es un principio clave puesto que ayuda a estimar el grado en el que la señal puede distinguirse del ruido, es decir, nos aproxima a la estimación del error. Al hacer esto, la medición de pobreza se beneficia porque ayuda a producir ordenamientos poblaciones consistentes -de alta a bajas formas de privación material- y robustos para los cuales asignar una línea de pobreza es menos problemático. El cálculo de confiabilidad implica reconocer que cualquier ejercicio de medición multidimensional descansa en una serie de supuestos. La confiabilidad examina el grado en el que nuestros prejuicios introducen ruido y nos señala qué aspectos de la escala necesitan trabajarse de nuevo. Cualquier teoría, en este caso de cómo medir pobreza, demanda el uso de métodos adecuados para su escrutinio. Hemos puesto dos estadísticos clave para analizar confiabilidad: \\(\\omega\\) y \\(\\omega_h\\). Sin embargo, debemos reconocer que alta confiabilidad simplemente nos dice si tenemos ordenamientos consistentes de una población. ¿Orden respecto a qué? Esa es la pregunta. Hasta ahora, no sabemos si los indicadores en cuestión son efectivamente medidas de pobreza. En otras palabras, creemos que la variable latente es pobreza, pero no hemos dado ningún tipo de evidencia que sostenga nuestra expectativa. En el siguiente capítulo respondemos la pregunta ¿Cómo saber si medimos pobreza? Es decir, cómo sabemos si estamos midiendo lo que queremos medir. "],
["referencias.html", "Capítulo 4 Referencias", " Capítulo 4 Referencias "]
]
